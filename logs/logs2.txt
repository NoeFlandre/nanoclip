Training samples 50000
Device : cuda
Total number of trainable parameters : 24742081
image_size : 224
patch_size : 16
vision_width : 192
vision_layers : 12
vision_heads : 3
vision_layer_norm_eps : 1e-06
vocab_size : 49408
text_width : 256
text_layers : 8
text_heads : 4
max_length : 77
text_layer_norm_eps : 1e-06
shared_dim : 512
batch_size : 256
learning_rate : 0.0001
epochs : 10
loss_type : contrastive
Optimizer : AdamW
Batch : 0 / 196 | Time 4483 ms | Train Loss : 5.5464 | Grad Norm : 0.2511 | Learning rate : 5.10e-07
Batch : 1 / 196 | Time 270 ms | Train Loss : 5.5465 | Grad Norm : 0.2324 | Learning rate : 1.02e-06
Batch : 2 / 196 | Time 267 ms | Train Loss : 5.5465 | Grad Norm : 0.2436 | Learning rate : 1.53e-06
Batch : 3 / 196 | Time 270 ms | Train Loss : 5.5458 | Grad Norm : 0.1811 | Learning rate : 2.04e-06
Batch : 4 / 196 | Time 270 ms | Train Loss : 5.5453 | Grad Norm : 0.1343 | Learning rate : 2.55e-06
Batch : 5 / 196 | Time 264 ms | Train Loss : 5.5451 | Grad Norm : 0.0961 | Learning rate : 3.06e-06
Batch : 6 / 196 | Time 264 ms | Train Loss : 5.5452 | Grad Norm : 0.0772 | Learning rate : 3.57e-06
Batch : 7 / 196 | Time 263 ms | Train Loss : 5.5448 | Grad Norm : 0.1119 | Learning rate : 4.08e-06
Batch : 8 / 196 | Time 266 ms | Train Loss : 5.5448 | Grad Norm : 0.1011 | Learning rate : 4.59e-06
Batch : 9 / 196 | Time 259 ms | Train Loss : 5.5448 | Grad Norm : 0.1078 | Learning rate : 5.10e-06
Batch : 10 / 196 | Time 260 ms | Train Loss : 5.5447 | Grad Norm : 0.1558 | Learning rate : 5.61e-06
Batch : 11 / 196 | Time 270 ms | Train Loss : 5.5447 | Grad Norm : 0.1051 | Learning rate : 6.12e-06
Batch : 12 / 196 | Time 269 ms | Train Loss : 5.5450 | Grad Norm : 0.1553 | Learning rate : 6.63e-06
Batch : 13 / 196 | Time 269 ms | Train Loss : 5.5436 | Grad Norm : 0.0967 | Learning rate : 7.14e-06
Batch : 14 / 196 | Time 263 ms | Train Loss : 5.5441 | Grad Norm : 0.0788 | Learning rate : 7.65e-06
Batch : 15 / 196 | Time 265 ms | Train Loss : 5.5430 | Grad Norm : 0.0988 | Learning rate : 8.16e-06
Batch : 16 / 196 | Time 271 ms | Train Loss : 5.5426 | Grad Norm : 0.0895 | Learning rate : 8.67e-06
Batch : 17 / 196 | Time 270 ms | Train Loss : 5.5427 | Grad Norm : 0.0719 | Learning rate : 9.18e-06
Batch : 18 / 196 | Time 267 ms | Train Loss : 5.5417 | Grad Norm : 0.0919 | Learning rate : 9.69e-06
Batch : 19 / 196 | Time 271 ms | Train Loss : 5.5412 | Grad Norm : 0.1254 | Learning rate : 1.02e-05
Batch : 20 / 196 | Time 264 ms | Train Loss : 5.5396 | Grad Norm : 0.1369 | Learning rate : 1.07e-05
Batch : 21 / 196 | Time 265 ms | Train Loss : 5.5399 | Grad Norm : 0.1367 | Learning rate : 1.12e-05
Batch : 22 / 196 | Time 263 ms | Train Loss : 5.5378 | Grad Norm : 0.1768 | Learning rate : 1.17e-05
Batch : 23 / 196 | Time 266 ms | Train Loss : 5.5363 | Grad Norm : 0.2034 | Learning rate : 1.22e-05
Batch : 24 / 196 | Time 265 ms | Train Loss : 5.5315 | Grad Norm : 0.2985 | Learning rate : 1.28e-05
Batch : 25 / 196 | Time 273 ms | Train Loss : 5.5296 | Grad Norm : 0.3211 | Learning rate : 1.33e-05
Batch : 26 / 196 | Time 272 ms | Train Loss : 5.5166 | Grad Norm : 0.5775 | Learning rate : 1.38e-05
Batch : 27 / 196 | Time 267 ms | Train Loss : 5.5123 | Grad Norm : 2.0063 | Learning rate : 1.43e-05
Batch : 28 / 196 | Time 264 ms | Train Loss : 5.5248 | Grad Norm : 7.3430 | Learning rate : 1.48e-05
Batch : 29 / 196 | Time 266 ms | Train Loss : 5.4921 | Grad Norm : 5.7835 | Learning rate : 1.53e-05
Batch : 30 / 196 | Time 267 ms | Train Loss : 5.5242 | Grad Norm : 18.6189 | Learning rate : 1.58e-05
Batch : 31 / 196 | Time 267 ms | Train Loss : 5.5397 | Grad Norm : 22.7185 | Learning rate : 1.63e-05
Batch : 32 / 196 | Time 265 ms | Train Loss : 5.4797 | Grad Norm : 6.4690 | Learning rate : 1.68e-05
Batch : 33 / 196 | Time 267 ms | Train Loss : 5.5703 | Grad Norm : 30.6836 | Learning rate : 1.73e-05
Batch : 34 / 196 | Time 272 ms | Train Loss : 5.6814 | Grad Norm : 39.0824 | Learning rate : 1.79e-05
Batch : 35 / 196 | Time 268 ms | Train Loss : 5.5968 | Grad Norm : 30.5530 | Learning rate : 1.84e-05
Batch : 36 / 196 | Time 268 ms | Train Loss : 5.4672 | Grad Norm : 5.9864 | Learning rate : 1.89e-05
Batch : 37 / 196 | Time 259 ms | Train Loss : 5.6333 | Grad Norm : 41.8698 | Learning rate : 1.94e-05
Batch : 38 / 196 | Time 265 ms | Train Loss : 5.8156 | Grad Norm : 50.1300 | Learning rate : 1.99e-05
Batch : 39 / 196 | Time 264 ms | Train Loss : 5.7691 | Grad Norm : 44.9392 | Learning rate : 2.04e-05
Batch : 40 / 196 | Time 263 ms | Train Loss : 5.5476 | Grad Norm : 24.1756 | Learning rate : 2.09e-05
Batch : 41 / 196 | Time 263 ms | Train Loss : 5.4377 | Grad Norm : 2.9986 | Learning rate : 2.14e-05
Batch : 42 / 196 | Time 281 ms | Train Loss : 5.4796 | Grad Norm : 15.2576 | Learning rate : 2.19e-05
Batch : 43 / 196 | Time 266 ms | Train Loss : 5.4689 | Grad Norm : 14.8606 | Learning rate : 2.24e-05
Batch : 44 / 196 | Time 264 ms | Train Loss : 5.4364 | Grad Norm : 4.6096 | Learning rate : 2.30e-05
Batch : 45 / 196 | Time 265 ms | Train Loss : 5.5247 | Grad Norm : 22.3035 | Learning rate : 2.35e-05
Batch : 46 / 196 | Time 270 ms | Train Loss : 5.6188 | Grad Norm : 36.1196 | Learning rate : 2.40e-05
Batch : 47 / 196 | Time 266 ms | Train Loss : 5.5330 | Grad Norm : 26.2868 | Learning rate : 2.45e-05
Batch : 48 / 196 | Time 269 ms | Train Loss : 5.4011 | Grad Norm : 5.7948 | Learning rate : 2.50e-05
Batch : 49 / 196 | Time 266 ms | Train Loss : 5.5596 | Grad Norm : 32.4720 | Learning rate : 2.55e-05
Batch : 50 / 196 | Time 267 ms | Train Loss : 5.6413 | Grad Norm : 36.2405 | Learning rate : 2.60e-05
Batch : 51 / 196 | Time 264 ms | Train Loss : 5.5440 | Grad Norm : 27.0172 | Learning rate : 2.65e-05
Batch : 52 / 196 | Time 266 ms | Train Loss : 5.4841 | Grad Norm : 8.6712 | Learning rate : 2.70e-05
Batch : 53 / 196 | Time 264 ms | Train Loss : 5.4887 | Grad Norm : 16.9504 | Learning rate : 2.76e-05
Batch : 54 / 196 | Time 272 ms | Train Loss : 5.5286 | Grad Norm : 21.6106 | Learning rate : 2.81e-05
Batch : 55 / 196 | Time 264 ms | Train Loss : 5.4479 | Grad Norm : 19.7735 | Learning rate : 2.86e-05
Batch : 56 / 196 | Time 269 ms | Train Loss : 5.4295 | Grad Norm : 2.2929 | Learning rate : 2.91e-05
Batch : 57 / 196 | Time 270 ms | Train Loss : 5.4693 | Grad Norm : 17.1320 | Learning rate : 2.96e-05
Batch : 58 / 196 | Time 266 ms | Train Loss : 5.5345 | Grad Norm : 23.1575 | Learning rate : 3.01e-05
Batch : 59 / 196 | Time 271 ms | Train Loss : 5.4854 | Grad Norm : 8.5903 | Learning rate : 3.06e-05
Batch : 60 / 196 | Time 263 ms | Train Loss : 5.4869 | Grad Norm : 11.3955 | Learning rate : 3.11e-05
Batch : 61 / 196 | Time 267 ms | Train Loss : 5.4556 | Grad Norm : 13.8629 | Learning rate : 3.16e-05
Batch : 62 / 196 | Time 264 ms | Train Loss : 5.4306 | Grad Norm : 6.3013 | Learning rate : 3.21e-05
Batch : 63 / 196 | Time 266 ms | Train Loss : 5.4165 | Grad Norm : 5.8917 | Learning rate : 3.27e-05
Batch : 64 / 196 | Time 265 ms | Train Loss : 5.4614 | Grad Norm : 6.9405 | Learning rate : 3.32e-05
Batch : 65 / 196 | Time 270 ms | Train Loss : 5.4056 | Grad Norm : 4.5356 | Learning rate : 3.37e-05
Batch : 66 / 196 | Time 266 ms | Train Loss : 5.4219 | Grad Norm : 6.2815 | Learning rate : 3.42e-05
Batch : 67 / 196 | Time 265 ms | Train Loss : 5.4184 | Grad Norm : 7.4322 | Learning rate : 3.47e-05
Batch : 68 / 196 | Time 264 ms | Train Loss : 5.3621 | Grad Norm : 2.9787 | Learning rate : 3.52e-05
Batch : 69 / 196 | Time 268 ms | Train Loss : 5.3273 | Grad Norm : 4.3645 | Learning rate : 3.57e-05
Batch : 70 / 196 | Time 265 ms | Train Loss : 5.3367 | Grad Norm : 3.9078 | Learning rate : 3.62e-05
Batch : 71 / 196 | Time 266 ms | Train Loss : 5.4139 | Grad Norm : 3.9974 | Learning rate : 3.67e-05
Batch : 72 / 196 | Time 267 ms | Train Loss : 5.3033 | Grad Norm : 4.2132 | Learning rate : 3.72e-05
Batch : 73 / 196 | Time 266 ms | Train Loss : 5.4546 | Grad Norm : 17.1724 | Learning rate : 3.78e-05
Batch : 74 / 196 | Time 263 ms | Train Loss : 5.3711 | Grad Norm : 13.7709 | Learning rate : 3.83e-05
Batch : 75 / 196 | Time 265 ms | Train Loss : 5.3483 | Grad Norm : 6.7708 | Learning rate : 3.88e-05
Batch : 76 / 196 | Time 263 ms | Train Loss : 5.3363 | Grad Norm : 5.2047 | Learning rate : 3.93e-05
Batch : 77 / 196 | Time 264 ms | Train Loss : 5.3731 | Grad Norm : 6.0537 | Learning rate : 3.98e-05
Batch : 78 / 196 | Time 265 ms | Train Loss : 5.3893 | Grad Norm : 2.5590 | Learning rate : 4.03e-05
Batch : 79 / 196 | Time 270 ms | Train Loss : 5.3520 | Grad Norm : 7.9101 | Learning rate : 4.08e-05
Batch : 80 / 196 | Time 264 ms | Train Loss : 5.3505 | Grad Norm : 8.0129 | Learning rate : 4.13e-05
Batch : 81 / 196 | Time 265 ms | Train Loss : 5.3400 | Grad Norm : 6.7645 | Learning rate : 4.18e-05
Batch : 82 / 196 | Time 265 ms | Train Loss : 5.3416 | Grad Norm : 4.5886 | Learning rate : 4.23e-05
Batch : 83 / 196 | Time 266 ms | Train Loss : 5.3633 | Grad Norm : 6.9729 | Learning rate : 4.29e-05
Batch : 84 / 196 | Time 273 ms | Train Loss : 5.2772 | Grad Norm : 4.8348 | Learning rate : 4.34e-05
Batch : 85 / 196 | Time 265 ms | Train Loss : 5.2484 | Grad Norm : 8.6428 | Learning rate : 4.39e-05
Batch : 86 / 196 | Time 269 ms | Train Loss : 5.2767 | Grad Norm : 9.5353 | Learning rate : 4.44e-05
Batch : 87 / 196 | Time 263 ms | Train Loss : 5.2831 | Grad Norm : 8.2010 | Learning rate : 4.49e-05
Batch : 88 / 196 | Time 264 ms | Train Loss : 5.3936 | Grad Norm : 11.5669 | Learning rate : 4.54e-05
Batch : 89 / 196 | Time 269 ms | Train Loss : 5.3139 | Grad Norm : 5.8667 | Learning rate : 4.59e-05
Batch : 90 / 196 | Time 257 ms | Train Loss : 5.3054 | Grad Norm : 4.4349 | Learning rate : 4.64e-05
Batch : 91 / 196 | Time 269 ms | Train Loss : 5.3411 | Grad Norm : 11.4540 | Learning rate : 4.69e-05
Batch : 92 / 196 | Time 269 ms | Train Loss : 5.3278 | Grad Norm : 12.1960 | Learning rate : 4.74e-05
Batch : 93 / 196 | Time 264 ms | Train Loss : 5.3258 | Grad Norm : 3.2963 | Learning rate : 4.80e-05
Batch : 94 / 196 | Time 263 ms | Train Loss : 5.2437 | Grad Norm : 12.8063 | Learning rate : 4.85e-05
Batch : 95 / 196 | Time 268 ms | Train Loss : 5.3493 | Grad Norm : 11.8001 | Learning rate : 4.90e-05
Batch : 96 / 196 | Time 265 ms | Train Loss : 5.2960 | Grad Norm : 7.2859 | Learning rate : 4.95e-05
Batch : 97 / 196 | Time 265 ms | Train Loss : 5.2178 | Grad Norm : 5.9998 | Learning rate : 5.00e-05
Batch : 98 / 196 | Time 262 ms | Train Loss : 5.3130 | Grad Norm : 7.6836 | Learning rate : 5.05e-05
Batch : 99 / 196 | Time 263 ms | Train Loss : 5.2034 | Grad Norm : 7.3918 | Learning rate : 5.10e-05
Batch : 100 / 196 | Time 264 ms | Train Loss : 5.2996 | Grad Norm : 11.1520 | Learning rate : 5.15e-05
Batch : 101 / 196 | Time 264 ms | Train Loss : 5.2644 | Grad Norm : 6.7021 | Learning rate : 5.20e-05
Batch : 102 / 196 | Time 261 ms | Train Loss : 5.1893 | Grad Norm : 7.1470 | Learning rate : 5.26e-05
Batch : 103 / 196 | Time 266 ms | Train Loss : 5.2459 | Grad Norm : 5.1519 | Learning rate : 5.31e-05
Batch : 104 / 196 | Time 258 ms | Train Loss : 5.2530 | Grad Norm : 4.6026 | Learning rate : 5.36e-05
Batch : 105 / 196 | Time 264 ms | Train Loss : 5.2288 | Grad Norm : 8.8484 | Learning rate : 5.41e-05
Batch : 106 / 196 | Time 269 ms | Train Loss : 5.3122 | Grad Norm : 8.5396 | Learning rate : 5.46e-05
Batch : 107 / 196 | Time 268 ms | Train Loss : 5.2211 | Grad Norm : 5.7683 | Learning rate : 5.51e-05
Batch : 108 / 196 | Time 278 ms | Train Loss : 5.2822 | Grad Norm : 5.1928 | Learning rate : 5.56e-05
Batch : 109 / 196 | Time 267 ms | Train Loss : 5.2723 | Grad Norm : 4.3236 | Learning rate : 5.61e-05
Batch : 110 / 196 | Time 267 ms | Train Loss : 5.2412 | Grad Norm : 6.7911 | Learning rate : 5.66e-05
Batch : 111 / 196 | Time 265 ms | Train Loss : 5.3152 | Grad Norm : 8.1166 | Learning rate : 5.71e-05
Batch : 112 / 196 | Time 273 ms | Train Loss : 5.2957 | Grad Norm : 3.8881 | Learning rate : 5.77e-05
Batch : 113 / 196 | Time 267 ms | Train Loss : 5.2654 | Grad Norm : 3.1726 | Learning rate : 5.82e-05
Batch : 114 / 196 | Time 274 ms | Train Loss : 5.2294 | Grad Norm : 4.2087 | Learning rate : 5.87e-05
Batch : 115 / 196 | Time 269 ms | Train Loss : 5.2363 | Grad Norm : 9.6234 | Learning rate : 5.92e-05
Batch : 116 / 196 | Time 270 ms | Train Loss : 5.2043 | Grad Norm : 8.7182 | Learning rate : 5.97e-05
Batch : 117 / 196 | Time 275 ms | Train Loss : 5.2054 | Grad Norm : 10.5898 | Learning rate : 6.02e-05
Batch : 118 / 196 | Time 264 ms | Train Loss : 5.2520 | Grad Norm : 15.1777 | Learning rate : 6.07e-05
Batch : 119 / 196 | Time 267 ms | Train Loss : 5.2169 | Grad Norm : 7.9793 | Learning rate : 6.12e-05
Batch : 120 / 196 | Time 264 ms | Train Loss : 5.2266 | Grad Norm : 10.3278 | Learning rate : 6.17e-05
Batch : 121 / 196 | Time 273 ms | Train Loss : 5.2462 | Grad Norm : 10.3536 | Learning rate : 6.22e-05
Batch : 122 / 196 | Time 280 ms | Train Loss : 5.2475 | Grad Norm : 6.1992 | Learning rate : 6.28e-05
Batch : 123 / 196 | Time 266 ms | Train Loss : 5.1893 | Grad Norm : 6.8868 | Learning rate : 6.33e-05
Batch : 124 / 196 | Time 267 ms | Train Loss : 5.2145 | Grad Norm : 3.2087 | Learning rate : 6.38e-05
Batch : 125 / 196 | Time 271 ms | Train Loss : 5.2203 | Grad Norm : 13.4078 | Learning rate : 6.43e-05
Batch : 126 / 196 | Time 270 ms | Train Loss : 5.2628 | Grad Norm : 9.7943 | Learning rate : 6.48e-05
Batch : 127 / 196 | Time 265 ms | Train Loss : 5.1664 | Grad Norm : 6.3044 | Learning rate : 6.53e-05
Batch : 128 / 196 | Time 269 ms | Train Loss : 5.1833 | Grad Norm : 7.3356 | Learning rate : 6.58e-05
Batch : 129 / 196 | Time 268 ms | Train Loss : 5.2389 | Grad Norm : 10.7208 | Learning rate : 6.63e-05
Batch : 130 / 196 | Time 266 ms | Train Loss : 5.1905 | Grad Norm : 9.3975 | Learning rate : 6.68e-05
Batch : 131 / 196 | Time 270 ms | Train Loss : 5.2167 | Grad Norm : 20.4915 | Learning rate : 6.73e-05
Batch : 132 / 196 | Time 266 ms | Train Loss : 5.3308 | Grad Norm : 19.5484 | Learning rate : 6.79e-05
Batch : 133 / 196 | Time 264 ms | Train Loss : 5.1531 | Grad Norm : 6.2726 | Learning rate : 6.84e-05
Batch : 134 / 196 | Time 264 ms | Train Loss : 5.2951 | Grad Norm : 16.5009 | Learning rate : 6.89e-05
Batch : 135 / 196 | Time 267 ms | Train Loss : 5.3377 | Grad Norm : 16.7044 | Learning rate : 6.94e-05
Batch : 136 / 196 | Time 270 ms | Train Loss : 5.2892 | Grad Norm : 8.2631 | Learning rate : 6.99e-05
Batch : 137 / 196 | Time 268 ms | Train Loss : 5.2776 | Grad Norm : 11.2861 | Learning rate : 7.04e-05
Batch : 138 / 196 | Time 266 ms | Train Loss : 5.2942 | Grad Norm : 15.9564 | Learning rate : 7.09e-05
Batch : 139 / 196 | Time 268 ms | Train Loss : 5.2453 | Grad Norm : 6.7438 | Learning rate : 7.14e-05
Batch : 140 / 196 | Time 271 ms | Train Loss : 5.2556 | Grad Norm : 9.8159 | Learning rate : 7.19e-05
Batch : 141 / 196 | Time 265 ms | Train Loss : 5.3165 | Grad Norm : 14.5839 | Learning rate : 7.24e-05
Batch : 142 / 196 | Time 265 ms | Train Loss : 5.2018 | Grad Norm : 10.7104 | Learning rate : 7.30e-05
Batch : 143 / 196 | Time 269 ms | Train Loss : 5.1627 | Grad Norm : 6.4935 | Learning rate : 7.35e-05
Batch : 144 / 196 | Time 271 ms | Train Loss : 5.2420 | Grad Norm : 11.1076 | Learning rate : 7.40e-05
Batch : 145 / 196 | Time 262 ms | Train Loss : 5.1561 | Grad Norm : 6.6619 | Learning rate : 7.45e-05
Batch : 146 / 196 | Time 270 ms | Train Loss : 5.3286 | Grad Norm : 15.0918 | Learning rate : 7.50e-05
Batch : 147 / 196 | Time 266 ms | Train Loss : 5.2816 | Grad Norm : 18.7096 | Learning rate : 7.55e-05
Batch : 148 / 196 | Time 271 ms | Train Loss : 5.1725 | Grad Norm : 6.8760 | Learning rate : 7.60e-05
Batch : 149 / 196 | Time 266 ms | Train Loss : 5.2469 | Grad Norm : 23.8861 | Learning rate : 7.65e-05
Batch : 150 / 196 | Time 275 ms | Train Loss : 5.3578 | Grad Norm : 22.3898 | Learning rate : 7.70e-05
Batch : 151 / 196 | Time 267 ms | Train Loss : 5.2756 | Grad Norm : 15.0356 | Learning rate : 7.76e-05
Batch : 152 / 196 | Time 271 ms | Train Loss : 5.1676 | Grad Norm : 4.7189 | Learning rate : 7.81e-05
Batch : 153 / 196 | Time 265 ms | Train Loss : 5.2819 | Grad Norm : 14.0251 | Learning rate : 7.86e-05
Batch : 154 / 196 | Time 270 ms | Train Loss : 5.2051 | Grad Norm : 13.6801 | Learning rate : 7.91e-05
Batch : 155 / 196 | Time 266 ms | Train Loss : 5.1541 | Grad Norm : 9.7810 | Learning rate : 7.96e-05
Batch : 156 / 196 | Time 271 ms | Train Loss : 5.1716 | Grad Norm : 5.8046 | Learning rate : 8.01e-05
Batch : 157 / 196 | Time 273 ms | Train Loss : 5.1150 | Grad Norm : 14.1067 | Learning rate : 8.06e-05
Batch : 158 / 196 | Time 267 ms | Train Loss : 5.1716 | Grad Norm : 10.1945 | Learning rate : 8.11e-05
Batch : 159 / 196 | Time 272 ms | Train Loss : 5.1560 | Grad Norm : 8.9474 | Learning rate : 8.16e-05
Batch : 160 / 196 | Time 265 ms | Train Loss : 5.0586 | Grad Norm : 8.6126 | Learning rate : 8.21e-05
Batch : 161 / 196 | Time 270 ms | Train Loss : 5.1123 | Grad Norm : 5.0441 | Learning rate : 8.27e-05
Batch : 162 / 196 | Time 265 ms | Train Loss : 5.1082 | Grad Norm : 7.0468 | Learning rate : 8.32e-05
Batch : 163 / 196 | Time 270 ms | Train Loss : 5.1279 | Grad Norm : 7.9242 | Learning rate : 8.37e-05
Batch : 164 / 196 | Time 268 ms | Train Loss : 5.1335 | Grad Norm : 5.2288 | Learning rate : 8.42e-05
Batch : 165 / 196 | Time 265 ms | Train Loss : 5.1216 | Grad Norm : 3.1027 | Learning rate : 8.47e-05
Batch : 166 / 196 | Time 269 ms | Train Loss : 5.1010 | Grad Norm : 9.8273 | Learning rate : 8.52e-05
Batch : 167 / 196 | Time 276 ms | Train Loss : 5.0610 | Grad Norm : 9.5133 | Learning rate : 8.57e-05
Batch : 168 / 196 | Time 270 ms | Train Loss : 5.2301 | Grad Norm : 9.8977 | Learning rate : 8.62e-05
Batch : 169 / 196 | Time 266 ms | Train Loss : 5.1324 | Grad Norm : 13.8463 | Learning rate : 8.67e-05
Batch : 170 / 196 | Time 264 ms | Train Loss : 5.1251 | Grad Norm : 5.1238 | Learning rate : 8.72e-05
Batch : 171 / 196 | Time 285 ms | Train Loss : 5.1841 | Grad Norm : 16.2967 | Learning rate : 8.78e-05
Batch : 172 / 196 | Time 278 ms | Train Loss : 5.1938 | Grad Norm : 16.3890 | Learning rate : 8.83e-05
Batch : 173 / 196 | Time 263 ms | Train Loss : 5.0423 | Grad Norm : 4.5522 | Learning rate : 8.88e-05
Batch : 174 / 196 | Time 266 ms | Train Loss : 5.1051 | Grad Norm : 13.2103 | Learning rate : 8.93e-05
Batch : 175 / 196 | Time 259 ms | Train Loss : 5.0301 | Grad Norm : 4.2342 | Learning rate : 8.98e-05
Batch : 176 / 196 | Time 267 ms | Train Loss : 5.1082 | Grad Norm : 3.3467 | Learning rate : 9.03e-05
Batch : 177 / 196 | Time 267 ms | Train Loss : 5.1128 | Grad Norm : 3.8515 | Learning rate : 9.08e-05
Batch : 178 / 196 | Time 269 ms | Train Loss : 5.1612 | Grad Norm : 9.2227 | Learning rate : 9.13e-05
Batch : 179 / 196 | Time 265 ms | Train Loss : 5.0315 | Grad Norm : 3.8363 | Learning rate : 9.18e-05
Batch : 180 / 196 | Time 267 ms | Train Loss : 5.1615 | Grad Norm : 14.8808 | Learning rate : 9.23e-05
Batch : 181 / 196 | Time 266 ms | Train Loss : 5.0565 | Grad Norm : 4.1754 | Learning rate : 9.29e-05
Batch : 182 / 196 | Time 274 ms | Train Loss : 5.0692 | Grad Norm : 12.3284 | Learning rate : 9.34e-05
Batch : 183 / 196 | Time 266 ms | Train Loss : 5.0678 | Grad Norm : 13.2826 | Learning rate : 9.39e-05
Batch : 184 / 196 | Time 267 ms | Train Loss : 5.0779 | Grad Norm : 4.7783 | Learning rate : 9.44e-05
Batch : 185 / 196 | Time 266 ms | Train Loss : 4.9398 | Grad Norm : 7.6612 | Learning rate : 9.49e-05
Batch : 186 / 196 | Time 264 ms | Train Loss : 5.0962 | Grad Norm : 11.9310 | Learning rate : 9.54e-05
Batch : 187 / 196 | Time 273 ms | Train Loss : 5.0719 | Grad Norm : 8.2582 | Learning rate : 9.59e-05
Batch : 188 / 196 | Time 266 ms | Train Loss : 5.0828 | Grad Norm : 21.7720 | Learning rate : 9.64e-05
Batch : 189 / 196 | Time 266 ms | Train Loss : 5.0475 | Grad Norm : 13.6899 | Learning rate : 9.69e-05
Batch : 190 / 196 | Time 268 ms | Train Loss : 5.1264 | Grad Norm : 15.3326 | Learning rate : 9.74e-05
Batch : 191 / 196 | Time 265 ms | Train Loss : 5.1145 | Grad Norm : 12.9903 | Learning rate : 9.80e-05
Batch : 192 / 196 | Time 264 ms | Train Loss : 4.9183 | Grad Norm : 9.0346 | Learning rate : 9.85e-05
Batch : 193 / 196 | Time 269 ms | Train Loss : 5.0506 | Grad Norm : 7.3553 | Learning rate : 9.90e-05
Batch : 194 / 196 | Time 265 ms | Train Loss : 4.9765 | Grad Norm : 10.0826 | Learning rate : 9.95e-05
Batch : 195 / 196 | Time 3746 ms | Train Loss : 3.7609 | Grad Norm : 9.4277 | Learning rate : 1.00e-04
Epoch : 0 | Training Loss : 3.7609| Accuracy on test set : 0.2731
 Batch : 0 / 196 | Time 298 ms | Train Loss : 4.9952 | Grad Norm : 13.7081 | Learning rate : 1.00e-04
Batch : 1 / 196 | Time 266 ms | Train Loss : 4.9720 | Grad Norm : 8.2877 | Learning rate : 1.00e-04
Batch : 2 / 196 | Time 264 ms | Train Loss : 5.0681 | Grad Norm : 23.9645 | Learning rate : 1.00e-04
Batch : 3 / 196 | Time 266 ms | Train Loss : 5.0179 | Grad Norm : 24.8435 | Learning rate : 1.00e-04
Batch : 4 / 196 | Time 266 ms | Train Loss : 4.9542 | Grad Norm : 20.3522 | Learning rate : 1.00e-04
Batch : 5 / 196 | Time 267 ms | Train Loss : 5.0323 | Grad Norm : 17.8493 | Learning rate : 1.00e-04
Batch : 6 / 196 | Time 268 ms | Train Loss : 4.9331 | Grad Norm : 15.2671 | Learning rate : 1.00e-04
Batch : 7 / 196 | Time 269 ms | Train Loss : 4.9331 | Grad Norm : 8.5591 | Learning rate : 1.00e-04
Batch : 8 / 196 | Time 266 ms | Train Loss : 4.9255 | Grad Norm : 14.3874 | Learning rate : 1.00e-04
Batch : 9 / 196 | Time 269 ms | Train Loss : 5.0289 | Grad Norm : 12.5082 | Learning rate : 1.00e-04
Batch : 10 / 196 | Time 267 ms | Train Loss : 5.0809 | Grad Norm : 23.4158 | Learning rate : 1.00e-04
Batch : 11 / 196 | Time 265 ms | Train Loss : 4.9646 | Grad Norm : 15.8229 | Learning rate : 1.00e-04
Batch : 12 / 196 | Time 265 ms | Train Loss : 4.9681 | Grad Norm : 15.2490 | Learning rate : 1.00e-04
Batch : 13 / 196 | Time 267 ms | Train Loss : 5.0203 | Grad Norm : 14.0129 | Learning rate : 1.00e-04
Batch : 14 / 196 | Time 266 ms | Train Loss : 4.9972 | Grad Norm : 9.3600 | Learning rate : 1.00e-04
Batch : 15 / 196 | Time 267 ms | Train Loss : 4.9517 | Grad Norm : 9.8251 | Learning rate : 1.00e-04
Batch : 16 / 196 | Time 264 ms | Train Loss : 4.9009 | Grad Norm : 13.7519 | Learning rate : 1.00e-04
Batch : 17 / 196 | Time 264 ms | Train Loss : 4.9514 | Grad Norm : 8.7058 | Learning rate : 1.00e-04
Batch : 18 / 196 | Time 264 ms | Train Loss : 4.9432 | Grad Norm : 3.5553 | Learning rate : 1.00e-04
Batch : 19 / 196 | Time 267 ms | Train Loss : 4.9104 | Grad Norm : 14.2466 | Learning rate : 1.00e-04
Batch : 20 / 196 | Time 263 ms | Train Loss : 4.9654 | Grad Norm : 10.0395 | Learning rate : 1.00e-04
Batch : 21 / 196 | Time 265 ms | Train Loss : 4.8485 | Grad Norm : 11.7027 | Learning rate : 1.00e-04
Batch : 22 / 196 | Time 271 ms | Train Loss : 4.9352 | Grad Norm : 31.9036 | Learning rate : 1.00e-04
Batch : 23 / 196 | Time 264 ms | Train Loss : 5.0105 | Grad Norm : 26.2018 | Learning rate : 1.00e-04
Batch : 24 / 196 | Time 264 ms | Train Loss : 5.0210 | Grad Norm : 5.6924 | Learning rate : 1.00e-04
Batch : 25 / 196 | Time 272 ms | Train Loss : 4.9955 | Grad Norm : 19.4952 | Learning rate : 9.99e-05
Batch : 26 / 196 | Time 268 ms | Train Loss : 5.0800 | Grad Norm : 19.7254 | Learning rate : 9.99e-05
Batch : 27 / 196 | Time 266 ms | Train Loss : 5.0403 | Grad Norm : 11.1232 | Learning rate : 9.99e-05
Batch : 28 / 196 | Time 265 ms | Train Loss : 5.0196 | Grad Norm : 11.5219 | Learning rate : 9.99e-05
Batch : 29 / 196 | Time 268 ms | Train Loss : 5.0108 | Grad Norm : 13.3959 | Learning rate : 9.99e-05
Batch : 30 / 196 | Time 267 ms | Train Loss : 5.0235 | Grad Norm : 13.5308 | Learning rate : 9.99e-05
Batch : 31 / 196 | Time 264 ms | Train Loss : 4.9995 | Grad Norm : 5.7296 | Learning rate : 9.99e-05
Batch : 32 / 196 | Time 268 ms | Train Loss : 4.9226 | Grad Norm : 10.5927 | Learning rate : 9.99e-05
Batch : 33 / 196 | Time 265 ms | Train Loss : 5.0799 | Grad Norm : 25.1480 | Learning rate : 9.99e-05
Batch : 34 / 196 | Time 264 ms | Train Loss : 4.9880 | Grad Norm : 23.1127 | Learning rate : 9.99e-05
Batch : 35 / 196 | Time 272 ms | Train Loss : 5.0128 | Grad Norm : 8.1264 | Learning rate : 9.99e-05
Batch : 36 / 196 | Time 264 ms | Train Loss : 4.9587 | Grad Norm : 29.9434 | Learning rate : 9.99e-05
Batch : 37 / 196 | Time 268 ms | Train Loss : 5.2091 | Grad Norm : 35.7778 | Learning rate : 9.99e-05
Batch : 38 / 196 | Time 270 ms | Train Loss : 5.0875 | Grad Norm : 10.4794 | Learning rate : 9.99e-05
Batch : 39 / 196 | Time 269 ms | Train Loss : 4.9733 | Grad Norm : 12.9914 | Learning rate : 9.99e-05
Batch : 40 / 196 | Time 265 ms | Train Loss : 4.9409 | Grad Norm : 19.7891 | Learning rate : 9.99e-05
Batch : 41 / 196 | Time 266 ms | Train Loss : 5.0020 | Grad Norm : 7.8027 | Learning rate : 9.99e-05
Batch : 42 / 196 | Time 259 ms | Train Loss : 5.0981 | Grad Norm : 9.2265 | Learning rate : 9.99e-05
Batch : 43 / 196 | Time 271 ms | Train Loss : 4.9795 | Grad Norm : 14.4465 | Learning rate : 9.98e-05
Batch : 44 / 196 | Time 266 ms | Train Loss : 4.9123 | Grad Norm : 3.5313 | Learning rate : 9.98e-05
Batch : 45 / 196 | Time 270 ms | Train Loss : 5.0008 | Grad Norm : 12.1275 | Learning rate : 9.98e-05
Batch : 46 / 196 | Time 265 ms | Train Loss : 4.9212 | Grad Norm : 10.9544 | Learning rate : 9.98e-05
Batch : 47 / 196 | Time 268 ms | Train Loss : 5.0020 | Grad Norm : 13.8095 | Learning rate : 9.98e-05
Batch : 48 / 196 | Time 264 ms | Train Loss : 4.9838 | Grad Norm : 10.2923 | Learning rate : 9.98e-05
Batch : 49 / 196 | Time 267 ms | Train Loss : 4.9399 | Grad Norm : 14.4810 | Learning rate : 9.98e-05
Batch : 50 / 196 | Time 264 ms | Train Loss : 4.8819 | Grad Norm : 9.6236 | Learning rate : 9.98e-05
Batch : 51 / 196 | Time 265 ms | Train Loss : 4.9643 | Grad Norm : 5.9894 | Learning rate : 9.98e-05
Batch : 52 / 196 | Time 273 ms | Train Loss : 4.9395 | Grad Norm : 8.9380 | Learning rate : 9.98e-05
Batch : 53 / 196 | Time 265 ms | Train Loss : 4.9115 | Grad Norm : 7.0067 | Learning rate : 9.98e-05
Batch : 54 / 196 | Time 264 ms | Train Loss : 4.9865 | Grad Norm : 7.1298 | Learning rate : 9.98e-05
Batch : 55 / 196 | Time 267 ms | Train Loss : 4.8933 | Grad Norm : 8.6625 | Learning rate : 9.98e-05
Batch : 56 / 196 | Time 262 ms | Train Loss : 4.9400 | Grad Norm : 6.4194 | Learning rate : 9.97e-05
Batch : 57 / 196 | Time 264 ms | Train Loss : 4.9256 | Grad Norm : 5.0738 | Learning rate : 9.97e-05
Batch : 58 / 196 | Time 265 ms | Train Loss : 4.9285 | Grad Norm : 5.7194 | Learning rate : 9.97e-05
Batch : 59 / 196 | Time 263 ms | Train Loss : 4.9744 | Grad Norm : 7.2655 | Learning rate : 9.97e-05
Batch : 60 / 196 | Time 265 ms | Train Loss : 4.8860 | Grad Norm : 9.4176 | Learning rate : 9.97e-05
Batch : 61 / 196 | Time 266 ms | Train Loss : 4.9457 | Grad Norm : 6.6099 | Learning rate : 9.97e-05
Batch : 62 / 196 | Time 265 ms | Train Loss : 4.8526 | Grad Norm : 8.9903 | Learning rate : 9.97e-05
Batch : 63 / 196 | Time 268 ms | Train Loss : 4.9339 | Grad Norm : 10.1919 | Learning rate : 9.97e-05
Batch : 64 / 196 | Time 266 ms | Train Loss : 4.9459 | Grad Norm : 9.5717 | Learning rate : 9.97e-05
Batch : 65 / 196 | Time 265 ms | Train Loss : 4.8708 | Grad Norm : 8.1267 | Learning rate : 9.97e-05
Batch : 66 / 196 | Time 264 ms | Train Loss : 4.8895 | Grad Norm : 5.6398 | Learning rate : 9.96e-05
Batch : 67 / 196 | Time 263 ms | Train Loss : 4.8255 | Grad Norm : 14.6603 | Learning rate : 9.96e-05
Batch : 68 / 196 | Time 263 ms | Train Loss : 4.8634 | Grad Norm : 10.6234 | Learning rate : 9.96e-05
Batch : 69 / 196 | Time 274 ms | Train Loss : 4.9684 | Grad Norm : 12.8542 | Learning rate : 9.96e-05
Batch : 70 / 196 | Time 265 ms | Train Loss : 4.8352 | Grad Norm : 10.4884 | Learning rate : 9.96e-05
Batch : 71 / 196 | Time 268 ms | Train Loss : 4.8804 | Grad Norm : 15.2002 | Learning rate : 9.96e-05
Batch : 72 / 196 | Time 264 ms | Train Loss : 4.9058 | Grad Norm : 15.4655 | Learning rate : 9.96e-05
Batch : 73 / 196 | Time 265 ms | Train Loss : 4.9471 | Grad Norm : 12.8561 | Learning rate : 9.96e-05
Batch : 74 / 196 | Time 265 ms | Train Loss : 4.9473 | Grad Norm : 13.1407 | Learning rate : 9.96e-05
Batch : 75 / 196 | Time 268 ms | Train Loss : 4.9159 | Grad Norm : 5.5948 | Learning rate : 9.95e-05
Batch : 76 / 196 | Time 263 ms | Train Loss : 4.9060 | Grad Norm : 6.1401 | Learning rate : 9.95e-05
Batch : 77 / 196 | Time 264 ms | Train Loss : 4.9321 | Grad Norm : 5.0216 | Learning rate : 9.95e-05
Batch : 78 / 196 | Time 264 ms | Train Loss : 4.9238 | Grad Norm : 9.1511 | Learning rate : 9.95e-05
Batch : 79 / 196 | Time 273 ms | Train Loss : 4.8638 | Grad Norm : 12.1067 | Learning rate : 9.95e-05
Batch : 80 / 196 | Time 267 ms | Train Loss : 4.9018 | Grad Norm : 6.9096 | Learning rate : 9.95e-05
Batch : 81 / 196 | Time 273 ms | Train Loss : 4.9198 | Grad Norm : 6.3739 | Learning rate : 9.95e-05
Batch : 82 / 196 | Time 264 ms | Train Loss : 4.8947 | Grad Norm : 10.7089 | Learning rate : 9.95e-05
Batch : 83 / 196 | Time 266 ms | Train Loss : 4.9510 | Grad Norm : 11.8743 | Learning rate : 9.94e-05
Batch : 84 / 196 | Time 269 ms | Train Loss : 4.8897 | Grad Norm : 4.3184 | Learning rate : 9.94e-05
Batch : 85 / 196 | Time 268 ms | Train Loss : 4.8350 | Grad Norm : 9.7402 | Learning rate : 9.94e-05
Batch : 86 / 196 | Time 265 ms | Train Loss : 4.7683 | Grad Norm : 7.9577 | Learning rate : 9.94e-05
Batch : 87 / 196 | Time 273 ms | Train Loss : 4.8948 | Grad Norm : 12.5595 | Learning rate : 9.94e-05
Batch : 88 / 196 | Time 271 ms | Train Loss : 4.9004 | Grad Norm : 6.6077 | Learning rate : 9.94e-05
Batch : 89 / 196 | Time 264 ms | Train Loss : 4.8124 | Grad Norm : 11.4278 | Learning rate : 9.94e-05
Batch : 90 / 196 | Time 264 ms | Train Loss : 4.8521 | Grad Norm : 18.4777 | Learning rate : 9.93e-05
Batch : 91 / 196 | Time 264 ms | Train Loss : 4.8135 | Grad Norm : 13.8218 | Learning rate : 9.93e-05
Batch : 92 / 196 | Time 263 ms | Train Loss : 4.9086 | Grad Norm : 17.1208 | Learning rate : 9.93e-05
Batch : 93 / 196 | Time 264 ms | Train Loss : 4.9573 | Grad Norm : 22.2841 | Learning rate : 9.93e-05
Batch : 94 / 196 | Time 263 ms | Train Loss : 4.9014 | Grad Norm : 18.2339 | Learning rate : 9.93e-05
Batch : 95 / 196 | Time 263 ms | Train Loss : 4.9288 | Grad Norm : 13.1948 | Learning rate : 9.93e-05
Batch : 96 / 196 | Time 264 ms | Train Loss : 4.9031 | Grad Norm : 21.2767 | Learning rate : 9.93e-05
Batch : 97 / 196 | Time 263 ms | Train Loss : 4.8335 | Grad Norm : 14.4954 | Learning rate : 9.92e-05
Batch : 98 / 196 | Time 269 ms | Train Loss : 4.8480 | Grad Norm : 12.6763 | Learning rate : 9.92e-05
Batch : 99 / 196 | Time 266 ms | Train Loss : 4.8676 | Grad Norm : 7.9062 | Learning rate : 9.92e-05
Batch : 100 / 196 | Time 265 ms | Train Loss : 4.9053 | Grad Norm : 7.2746 | Learning rate : 9.92e-05
Batch : 101 / 196 | Time 265 ms | Train Loss : 4.8204 | Grad Norm : 12.6537 | Learning rate : 9.92e-05
Batch : 102 / 196 | Time 268 ms | Train Loss : 4.7830 | Grad Norm : 8.1536 | Learning rate : 9.92e-05
Batch : 103 / 196 | Time 265 ms | Train Loss : 4.9342 | Grad Norm : 9.8846 | Learning rate : 9.91e-05
Batch : 104 / 196 | Time 269 ms | Train Loss : 4.9423 | Grad Norm : 13.9889 | Learning rate : 9.91e-05
Batch : 105 / 196 | Time 264 ms | Train Loss : 4.8644 | Grad Norm : 7.9870 | Learning rate : 9.91e-05
Batch : 106 / 196 | Time 273 ms | Train Loss : 4.8727 | Grad Norm : 13.9959 | Learning rate : 9.91e-05
Batch : 107 / 196 | Time 260 ms | Train Loss : 4.9585 | Grad Norm : 24.4947 | Learning rate : 9.91e-05
Batch : 108 / 196 | Time 266 ms | Train Loss : 4.9395 | Grad Norm : 14.0988 | Learning rate : 9.91e-05
Batch : 109 / 196 | Time 271 ms | Train Loss : 4.8687 | Grad Norm : 16.9342 | Learning rate : 9.90e-05
Batch : 110 / 196 | Time 265 ms | Train Loss : 4.9708 | Grad Norm : 16.1083 | Learning rate : 9.90e-05
Batch : 111 / 196 | Time 271 ms | Train Loss : 4.9217 | Grad Norm : 7.1417 | Learning rate : 9.90e-05
Batch : 112 / 196 | Time 271 ms | Train Loss : 4.8280 | Grad Norm : 21.7217 | Learning rate : 9.90e-05
Batch : 113 / 196 | Time 260 ms | Train Loss : 4.9173 | Grad Norm : 19.3679 | Learning rate : 9.90e-05
Batch : 114 / 196 | Time 262 ms | Train Loss : 4.8690 | Grad Norm : 9.1821 | Learning rate : 9.90e-05
Batch : 115 / 196 | Time 268 ms | Train Loss : 4.9406 | Grad Norm : 9.0555 | Learning rate : 9.89e-05
Batch : 116 / 196 | Time 263 ms | Train Loss : 4.8440 | Grad Norm : 4.9563 | Learning rate : 9.89e-05
Batch : 117 / 196 | Time 264 ms | Train Loss : 4.8460 | Grad Norm : 10.8016 | Learning rate : 9.89e-05
Batch : 118 / 196 | Time 271 ms | Train Loss : 4.7715 | Grad Norm : 13.2684 | Learning rate : 9.89e-05
Batch : 119 / 196 | Time 266 ms | Train Loss : 4.9304 | Grad Norm : 8.8588 | Learning rate : 9.89e-05
Batch : 120 / 196 | Time 268 ms | Train Loss : 4.8931 | Grad Norm : 8.1235 | Learning rate : 9.88e-05
Batch : 121 / 196 | Time 263 ms | Train Loss : 4.7932 | Grad Norm : 12.1422 | Learning rate : 9.88e-05
Batch : 122 / 196 | Time 269 ms | Train Loss : 4.8684 | Grad Norm : 7.5426 | Learning rate : 9.88e-05
Batch : 123 / 196 | Time 264 ms | Train Loss : 4.8726 | Grad Norm : 7.9078 | Learning rate : 9.88e-05
Batch : 124 / 196 | Time 263 ms | Train Loss : 4.7652 | Grad Norm : 6.0849 | Learning rate : 9.88e-05
Batch : 125 / 196 | Time 269 ms | Train Loss : 4.7018 | Grad Norm : 14.6103 | Learning rate : 9.87e-05
Batch : 126 / 196 | Time 265 ms | Train Loss : 4.9378 | Grad Norm : 18.9070 | Learning rate : 9.87e-05
Batch : 127 / 196 | Time 263 ms | Train Loss : 4.8289 | Grad Norm : 19.0447 | Learning rate : 9.87e-05
Batch : 128 / 196 | Time 263 ms | Train Loss : 4.9194 | Grad Norm : 12.6621 | Learning rate : 9.87e-05
Batch : 129 / 196 | Time 265 ms | Train Loss : 4.8392 | Grad Norm : 7.8325 | Learning rate : 9.87e-05
Batch : 130 / 196 | Time 262 ms | Train Loss : 4.9274 | Grad Norm : 18.6065 | Learning rate : 9.86e-05
Batch : 131 / 196 | Time 270 ms | Train Loss : 4.8305 | Grad Norm : 17.7141 | Learning rate : 9.86e-05
Batch : 132 / 196 | Time 267 ms | Train Loss : 4.8688 | Grad Norm : 16.7056 | Learning rate : 9.86e-05
Batch : 133 / 196 | Time 269 ms | Train Loss : 4.9304 | Grad Norm : 19.3704 | Learning rate : 9.86e-05
Batch : 134 / 196 | Time 266 ms | Train Loss : 4.8953 | Grad Norm : 7.3781 | Learning rate : 9.86e-05
Batch : 135 / 196 | Time 266 ms | Train Loss : 4.8588 | Grad Norm : 7.1578 | Learning rate : 9.85e-05
Batch : 136 / 196 | Time 264 ms | Train Loss : 4.8643 | Grad Norm : 7.3541 | Learning rate : 9.85e-05
Batch : 137 / 196 | Time 266 ms | Train Loss : 4.8233 | Grad Norm : 5.5054 | Learning rate : 9.85e-05
Batch : 138 / 196 | Time 265 ms | Train Loss : 4.8127 | Grad Norm : 15.5096 | Learning rate : 9.85e-05
Batch : 139 / 196 | Time 265 ms | Train Loss : 4.8769 | Grad Norm : 7.1936 | Learning rate : 9.85e-05
Batch : 140 / 196 | Time 268 ms | Train Loss : 4.8070 | Grad Norm : 13.7060 | Learning rate : 9.84e-05
Batch : 141 / 196 | Time 265 ms | Train Loss : 4.8222 | Grad Norm : 8.4167 | Learning rate : 9.84e-05
Batch : 142 / 196 | Time 269 ms | Train Loss : 4.8306 | Grad Norm : 6.5547 | Learning rate : 9.84e-05
Batch : 143 / 196 | Time 268 ms | Train Loss : 4.7744 | Grad Norm : 15.9002 | Learning rate : 9.84e-05
Batch : 144 / 196 | Time 265 ms | Train Loss : 4.8528 | Grad Norm : 9.9569 | Learning rate : 9.83e-05
Batch : 145 / 196 | Time 267 ms | Train Loss : 4.7787 | Grad Norm : 14.2733 | Learning rate : 9.83e-05
Batch : 146 / 196 | Time 265 ms | Train Loss : 4.7789 | Grad Norm : 5.6308 | Learning rate : 9.83e-05
Batch : 147 / 196 | Time 266 ms | Train Loss : 4.9901 | Grad Norm : 12.0812 | Learning rate : 9.83e-05
Batch : 148 / 196 | Time 264 ms | Train Loss : 4.7737 | Grad Norm : 11.0343 | Learning rate : 9.82e-05
Batch : 149 / 196 | Time 264 ms | Train Loss : 4.7787 | Grad Norm : 6.4291 | Learning rate : 9.82e-05
Batch : 150 / 196 | Time 262 ms | Train Loss : 4.8763 | Grad Norm : 12.3142 | Learning rate : 9.82e-05
Batch : 151 / 196 | Time 263 ms | Train Loss : 4.7803 | Grad Norm : 8.6487 | Learning rate : 9.82e-05
Batch : 152 / 196 | Time 266 ms | Train Loss : 4.8159 | Grad Norm : 10.1258 | Learning rate : 9.82e-05
Batch : 153 / 196 | Time 269 ms | Train Loss : 4.7820 | Grad Norm : 7.0918 | Learning rate : 9.81e-05
Batch : 154 / 196 | Time 270 ms | Train Loss : 4.8561 | Grad Norm : 8.6624 | Learning rate : 9.81e-05
Batch : 155 / 196 | Time 266 ms | Train Loss : 4.7710 | Grad Norm : 8.9883 | Learning rate : 9.81e-05
Batch : 156 / 196 | Time 264 ms | Train Loss : 4.7601 | Grad Norm : 6.6004 | Learning rate : 9.81e-05
Batch : 157 / 196 | Time 264 ms | Train Loss : 4.7633 | Grad Norm : 19.9595 | Learning rate : 9.80e-05
Batch : 158 / 196 | Time 264 ms | Train Loss : 4.9047 | Grad Norm : 10.1350 | Learning rate : 9.80e-05
Batch : 159 / 196 | Time 262 ms | Train Loss : 4.6059 | Grad Norm : 8.3013 | Learning rate : 9.80e-05
Batch : 160 / 196 | Time 262 ms | Train Loss : 4.8806 | Grad Norm : 12.3955 | Learning rate : 9.80e-05
Batch : 161 / 196 | Time 263 ms | Train Loss : 4.8393 | Grad Norm : 8.3873 | Learning rate : 9.79e-05
Batch : 162 / 196 | Time 265 ms | Train Loss : 4.8538 | Grad Norm : 6.6626 | Learning rate : 9.79e-05
Batch : 163 / 196 | Time 265 ms | Train Loss : 4.7285 | Grad Norm : 6.5953 | Learning rate : 9.79e-05
Batch : 164 / 196 | Time 258 ms | Train Loss : 4.6974 | Grad Norm : 10.3081 | Learning rate : 9.79e-05
Batch : 165 / 196 | Time 266 ms | Train Loss : 4.8434 | Grad Norm : 8.1072 | Learning rate : 9.78e-05
Batch : 166 / 196 | Time 262 ms | Train Loss : 4.7189 | Grad Norm : 7.4812 | Learning rate : 9.78e-05
Batch : 167 / 196 | Time 262 ms | Train Loss : 4.7910 | Grad Norm : 13.0920 | Learning rate : 9.78e-05
Batch : 168 / 196 | Time 264 ms | Train Loss : 4.8376 | Grad Norm : 15.7826 | Learning rate : 9.78e-05
Batch : 169 / 196 | Time 263 ms | Train Loss : 4.7475 | Grad Norm : 15.8761 | Learning rate : 9.77e-05
Batch : 170 / 196 | Time 264 ms | Train Loss : 4.7462 | Grad Norm : 10.1556 | Learning rate : 9.77e-05
Batch : 171 / 196 | Time 263 ms | Train Loss : 4.8550 | Grad Norm : 8.7799 | Learning rate : 9.77e-05
Batch : 172 / 196 | Time 263 ms | Train Loss : 4.8521 | Grad Norm : 17.0005 | Learning rate : 9.76e-05
Batch : 173 / 196 | Time 262 ms | Train Loss : 4.7363 | Grad Norm : 11.8217 | Learning rate : 9.76e-05
Batch : 174 / 196 | Time 263 ms | Train Loss : 4.6702 | Grad Norm : 9.2614 | Learning rate : 9.76e-05
Batch : 175 / 196 | Time 265 ms | Train Loss : 4.7263 | Grad Norm : 10.4188 | Learning rate : 9.76e-05
Batch : 176 / 196 | Time 262 ms | Train Loss : 4.7678 | Grad Norm : 11.1050 | Learning rate : 9.75e-05
Batch : 177 / 196 | Time 263 ms | Train Loss : 4.8659 | Grad Norm : 25.8973 | Learning rate : 9.75e-05
Batch : 178 / 196 | Time 263 ms | Train Loss : 4.8596 | Grad Norm : 24.3274 | Learning rate : 9.75e-05
Batch : 179 / 196 | Time 266 ms | Train Loss : 4.8135 | Grad Norm : 10.6809 | Learning rate : 9.75e-05
Batch : 180 / 196 | Time 266 ms | Train Loss : 4.8793 | Grad Norm : 23.6220 | Learning rate : 9.74e-05
Batch : 181 / 196 | Time 269 ms | Train Loss : 4.7945 | Grad Norm : 26.0330 | Learning rate : 9.74e-05
Batch : 182 / 196 | Time 259 ms | Train Loss : 4.7677 | Grad Norm : 11.5902 | Learning rate : 9.74e-05
Batch : 183 / 196 | Time 268 ms | Train Loss : 4.8677 | Grad Norm : 14.4921 | Learning rate : 9.73e-05
Batch : 184 / 196 | Time 266 ms | Train Loss : 4.8441 | Grad Norm : 21.2805 | Learning rate : 9.73e-05
Batch : 185 / 196 | Time 265 ms | Train Loss : 4.8247 | Grad Norm : 13.3177 | Learning rate : 9.73e-05
Batch : 186 / 196 | Time 264 ms | Train Loss : 4.7352 | Grad Norm : 13.3886 | Learning rate : 9.73e-05
Batch : 187 / 196 | Time 265 ms | Train Loss : 4.7534 | Grad Norm : 12.5461 | Learning rate : 9.72e-05
Batch : 188 / 196 | Time 265 ms | Train Loss : 4.7955 | Grad Norm : 17.1766 | Learning rate : 9.72e-05
Batch : 189 / 196 | Time 265 ms | Train Loss : 4.7493 | Grad Norm : 11.3500 | Learning rate : 9.72e-05
Batch : 190 / 196 | Time 263 ms | Train Loss : 4.7866 | Grad Norm : 14.6936 | Learning rate : 9.71e-05
Batch : 191 / 196 | Time 266 ms | Train Loss : 4.7604 | Grad Norm : 7.2364 | Learning rate : 9.71e-05
Batch : 192 / 196 | Time 269 ms | Train Loss : 4.7261 | Grad Norm : 16.2226 | Learning rate : 9.71e-05
Batch : 193 / 196 | Time 265 ms | Train Loss : 4.7981 | Grad Norm : 16.2198 | Learning rate : 9.70e-05
Batch : 194 / 196 | Time 273 ms | Train Loss : 4.7635 | Grad Norm : 10.3004 | Learning rate : 9.70e-05
Batch : 195 / 196 | Time 114 ms | Train Loss : 3.5333 | Grad Norm : 15.9052 | Learning rate : 9.70e-05
Epoch : 1 | Training Loss : 3.5333| Accuracy on test set : 0.3816
 Batch : 0 / 196 | Time 288 ms | Train Loss : 4.8088 | Grad Norm : 7.5943 | Learning rate : 9.70e-05
Batch : 1 / 196 | Time 274 ms | Train Loss : 4.6257 | Grad Norm : 9.5947 | Learning rate : 9.69e-05
Batch : 2 / 196 | Time 266 ms | Train Loss : 4.7405 | Grad Norm : 5.3702 | Learning rate : 9.69e-05
Batch : 3 / 196 | Time 268 ms | Train Loss : 4.7043 | Grad Norm : 10.1677 | Learning rate : 9.69e-05
Batch : 4 / 196 | Time 267 ms | Train Loss : 4.6929 | Grad Norm : 12.6031 | Learning rate : 9.68e-05
Batch : 5 / 196 | Time 264 ms | Train Loss : 4.7294 | Grad Norm : 9.2023 | Learning rate : 9.68e-05
Batch : 6 / 196 | Time 263 ms | Train Loss : 4.7824 | Grad Norm : 15.0652 | Learning rate : 9.68e-05
Batch : 7 / 196 | Time 267 ms | Train Loss : 4.8327 | Grad Norm : 12.4926 | Learning rate : 9.67e-05
Batch : 8 / 196 | Time 272 ms | Train Loss : 4.7867 | Grad Norm : 12.6965 | Learning rate : 9.67e-05
Batch : 9 / 196 | Time 268 ms | Train Loss : 4.7577 | Grad Norm : 13.1468 | Learning rate : 9.67e-05
Batch : 10 / 196 | Time 270 ms | Train Loss : 4.7926 | Grad Norm : 10.0431 | Learning rate : 9.66e-05
Batch : 11 / 196 | Time 265 ms | Train Loss : 4.8035 | Grad Norm : 15.5007 | Learning rate : 9.66e-05
Batch : 12 / 196 | Time 266 ms | Train Loss : 4.7360 | Grad Norm : 6.7749 | Learning rate : 9.66e-05
Batch : 13 / 196 | Time 263 ms | Train Loss : 4.9352 | Grad Norm : 13.9090 | Learning rate : 9.65e-05
Batch : 14 / 196 | Time 264 ms | Train Loss : 4.7682 | Grad Norm : 8.0456 | Learning rate : 9.65e-05
Batch : 15 / 196 | Time 265 ms | Train Loss : 4.8481 | Grad Norm : 14.8031 | Learning rate : 9.65e-05
Batch : 16 / 196 | Time 273 ms | Train Loss : 4.7290 | Grad Norm : 9.4342 | Learning rate : 9.64e-05
Batch : 17 / 196 | Time 264 ms | Train Loss : 4.8259 | Grad Norm : 9.6631 | Learning rate : 9.64e-05
Batch : 18 / 196 | Time 264 ms | Train Loss : 4.7814 | Grad Norm : 7.0989 | Learning rate : 9.64e-05
Batch : 19 / 196 | Time 266 ms | Train Loss : 4.8416 | Grad Norm : 22.3084 | Learning rate : 9.63e-05
Batch : 20 / 196 | Time 265 ms | Train Loss : 4.7763 | Grad Norm : 22.9080 | Learning rate : 9.63e-05
Batch : 21 / 196 | Time 265 ms | Train Loss : 4.7203 | Grad Norm : 11.4754 | Learning rate : 9.63e-05
Batch : 22 / 196 | Time 264 ms | Train Loss : 4.8367 | Grad Norm : 21.0086 | Learning rate : 9.62e-05
Batch : 23 / 196 | Time 261 ms | Train Loss : 4.7180 | Grad Norm : 14.4487 | Learning rate : 9.62e-05
Batch : 24 / 196 | Time 272 ms | Train Loss : 4.7998 | Grad Norm : 13.1826 | Learning rate : 9.62e-05
Batch : 25 / 196 | Time 265 ms | Train Loss : 4.6507 | Grad Norm : 15.4654 | Learning rate : 9.61e-05
Batch : 26 / 196 | Time 267 ms | Train Loss : 4.8257 | Grad Norm : 12.5691 | Learning rate : 9.61e-05
Batch : 27 / 196 | Time 271 ms | Train Loss : 4.8354 | Grad Norm : 16.5664 | Learning rate : 9.61e-05
Batch : 28 / 196 | Time 264 ms | Train Loss : 4.7467 | Grad Norm : 7.0737 | Learning rate : 9.60e-05
Batch : 29 / 196 | Time 265 ms | Train Loss : 4.7772 | Grad Norm : 23.2277 | Learning rate : 9.60e-05
Batch : 30 / 196 | Time 268 ms | Train Loss : 4.7771 | Grad Norm : 25.1131 | Learning rate : 9.60e-05
Batch : 31 / 196 | Time 269 ms | Train Loss : 4.7476 | Grad Norm : 10.2246 | Learning rate : 9.59e-05
Batch : 32 / 196 | Time 263 ms | Train Loss : 4.7312 | Grad Norm : 15.3454 | Learning rate : 9.59e-05
Batch : 33 / 196 | Time 263 ms | Train Loss : 4.7706 | Grad Norm : 9.6804 | Learning rate : 9.59e-05
Batch : 34 / 196 | Time 263 ms | Train Loss : 4.8133 | Grad Norm : 21.4631 | Learning rate : 9.58e-05
Batch : 35 / 196 | Time 263 ms | Train Loss : 4.6273 | Grad Norm : 16.4777 | Learning rate : 9.58e-05
Batch : 36 / 196 | Time 268 ms | Train Loss : 4.7025 | Grad Norm : 10.7167 | Learning rate : 9.58e-05
Batch : 37 / 196 | Time 267 ms | Train Loss : 4.8375 | Grad Norm : 15.4487 | Learning rate : 9.57e-05
Batch : 38 / 196 | Time 270 ms | Train Loss : 4.6698 | Grad Norm : 10.5361 | Learning rate : 9.57e-05
Batch : 39 / 196 | Time 267 ms | Train Loss : 4.6907 | Grad Norm : 19.4323 | Learning rate : 9.56e-05
Batch : 40 / 196 | Time 264 ms | Train Loss : 4.7438 | Grad Norm : 17.5448 | Learning rate : 9.56e-05
Batch : 41 / 196 | Time 269 ms | Train Loss : 4.6777 | Grad Norm : 10.6821 | Learning rate : 9.56e-05
Batch : 42 / 196 | Time 268 ms | Train Loss : 4.6808 | Grad Norm : 16.0876 | Learning rate : 9.55e-05
Batch : 43 / 196 | Time 264 ms | Train Loss : 4.8385 | Grad Norm : 17.3366 | Learning rate : 9.55e-05
Batch : 44 / 196 | Time 268 ms | Train Loss : 4.6719 | Grad Norm : 7.5448 | Learning rate : 9.55e-05
Batch : 45 / 196 | Time 270 ms | Train Loss : 4.7661 | Grad Norm : 13.1402 | Learning rate : 9.54e-05
Batch : 46 / 196 | Time 264 ms | Train Loss : 4.7358 | Grad Norm : 13.5945 | Learning rate : 9.54e-05
Batch : 47 / 196 | Time 264 ms | Train Loss : 4.8156 | Grad Norm : 10.6416 | Learning rate : 9.54e-05
Batch : 48 / 196 | Time 265 ms | Train Loss : 4.6708 | Grad Norm : 14.5214 | Learning rate : 9.53e-05
Batch : 49 / 196 | Time 264 ms | Train Loss : 4.6637 | Grad Norm : 6.2674 | Learning rate : 9.53e-05
Batch : 50 / 196 | Time 267 ms | Train Loss : 4.6841 | Grad Norm : 6.5262 | Learning rate : 9.52e-05
Batch : 51 / 196 | Time 266 ms | Train Loss : 4.7262 | Grad Norm : 10.7447 | Learning rate : 9.52e-05
Batch : 52 / 196 | Time 270 ms | Train Loss : 4.6425 | Grad Norm : 13.5958 | Learning rate : 9.52e-05
Batch : 53 / 196 | Time 270 ms | Train Loss : 4.6744 | Grad Norm : 10.2198 | Learning rate : 9.51e-05
Batch : 54 / 196 | Time 265 ms | Train Loss : 4.7793 | Grad Norm : 10.7945 | Learning rate : 9.51e-05
Batch : 55 / 196 | Time 267 ms | Train Loss : 4.6527 | Grad Norm : 15.2543 | Learning rate : 9.50e-05
Batch : 56 / 196 | Time 267 ms | Train Loss : 4.7141 | Grad Norm : 17.2005 | Learning rate : 9.50e-05
Batch : 57 / 196 | Time 265 ms | Train Loss : 4.7159 | Grad Norm : 11.2697 | Learning rate : 9.50e-05
Batch : 58 / 196 | Time 267 ms | Train Loss : 4.7912 | Grad Norm : 16.0975 | Learning rate : 9.49e-05
Batch : 59 / 196 | Time 267 ms | Train Loss : 4.6508 | Grad Norm : 8.7004 | Learning rate : 9.49e-05
Batch : 60 / 196 | Time 268 ms | Train Loss : 4.7672 | Grad Norm : 19.0722 | Learning rate : 9.49e-05
Batch : 61 / 196 | Time 266 ms | Train Loss : 4.7256 | Grad Norm : 12.9018 | Learning rate : 9.48e-05
Batch : 62 / 196 | Time 264 ms | Train Loss : 4.7533 | Grad Norm : 11.9593 | Learning rate : 9.48e-05
Batch : 63 / 196 | Time 263 ms | Train Loss : 4.7339 | Grad Norm : 12.0293 | Learning rate : 9.47e-05
Batch : 64 / 196 | Time 268 ms | Train Loss : 4.7192 | Grad Norm : 8.6381 | Learning rate : 9.47e-05
Batch : 65 / 196 | Time 265 ms | Train Loss : 4.6380 | Grad Norm : 8.0817 | Learning rate : 9.47e-05
Batch : 66 / 196 | Time 268 ms | Train Loss : 4.6602 | Grad Norm : 27.3088 | Learning rate : 9.46e-05
Batch : 67 / 196 | Time 271 ms | Train Loss : 4.6387 | Grad Norm : 16.9431 | Learning rate : 9.46e-05
Batch : 68 / 196 | Time 269 ms | Train Loss : 4.6450 | Grad Norm : 11.5446 | Learning rate : 9.45e-05
Batch : 69 / 196 | Time 264 ms | Train Loss : 4.6307 | Grad Norm : 11.0548 | Learning rate : 9.45e-05
Batch : 70 / 196 | Time 265 ms | Train Loss : 4.7658 | Grad Norm : 11.8565 | Learning rate : 9.45e-05
Batch : 71 / 196 | Time 263 ms | Train Loss : 4.8072 | Grad Norm : 14.9588 | Learning rate : 9.44e-05
Batch : 72 / 196 | Time 263 ms | Train Loss : 4.7103 | Grad Norm : 14.1288 | Learning rate : 9.44e-05
Batch : 73 / 196 | Time 264 ms | Train Loss : 4.6782 | Grad Norm : 15.1210 | Learning rate : 9.43e-05
Batch : 74 / 196 | Time 265 ms | Train Loss : 4.6938 | Grad Norm : 16.9366 | Learning rate : 9.43e-05
Batch : 75 / 196 | Time 261 ms | Train Loss : 4.5908 | Grad Norm : 8.7047 | Learning rate : 9.42e-05
Batch : 76 / 196 | Time 269 ms | Train Loss : 4.7862 | Grad Norm : 26.1765 | Learning rate : 9.42e-05
Batch : 77 / 196 | Time 264 ms | Train Loss : 4.6411 | Grad Norm : 13.3893 | Learning rate : 9.42e-05
Batch : 78 / 196 | Time 268 ms | Train Loss : 4.6943 | Grad Norm : 22.6600 | Learning rate : 9.41e-05
Batch : 79 / 196 | Time 264 ms | Train Loss : 4.6733 | Grad Norm : 22.7126 | Learning rate : 9.41e-05
Batch : 80 / 196 | Time 263 ms | Train Loss : 4.6152 | Grad Norm : 8.7500 | Learning rate : 9.40e-05
Batch : 81 / 196 | Time 263 ms | Train Loss : 4.7622 | Grad Norm : 27.7920 | Learning rate : 9.40e-05
Batch : 82 / 196 | Time 267 ms | Train Loss : 4.7568 | Grad Norm : 35.2053 | Learning rate : 9.40e-05
Batch : 83 / 196 | Time 264 ms | Train Loss : 4.7400 | Grad Norm : 8.4105 | Learning rate : 9.39e-05
Batch : 84 / 196 | Time 264 ms | Train Loss : 4.6447 | Grad Norm : 31.0398 | Learning rate : 9.39e-05
Batch : 85 / 196 | Time 267 ms | Train Loss : 4.6529 | Grad Norm : 26.9951 | Learning rate : 9.38e-05
Batch : 86 / 196 | Time 271 ms | Train Loss : 4.7819 | Grad Norm : 12.2346 | Learning rate : 9.38e-05
Batch : 87 / 196 | Time 268 ms | Train Loss : 4.7605 | Grad Norm : 21.5679 | Learning rate : 9.37e-05
Batch : 88 / 196 | Time 264 ms | Train Loss : 4.7302 | Grad Norm : 25.2276 | Learning rate : 9.37e-05
Batch : 89 / 196 | Time 263 ms | Train Loss : 4.7374 | Grad Norm : 15.3585 | Learning rate : 9.37e-05
Batch : 90 / 196 | Time 269 ms | Train Loss : 4.6409 | Grad Norm : 11.3191 | Learning rate : 9.36e-05
Batch : 91 / 196 | Time 262 ms | Train Loss : 4.7434 | Grad Norm : 13.0324 | Learning rate : 9.36e-05
Batch : 92 / 196 | Time 263 ms | Train Loss : 4.6947 | Grad Norm : 13.5098 | Learning rate : 9.35e-05
Batch : 93 / 196 | Time 265 ms | Train Loss : 4.5861 | Grad Norm : 11.4167 | Learning rate : 9.35e-05
Batch : 94 / 196 | Time 262 ms | Train Loss : 4.8158 | Grad Norm : 15.4112 | Learning rate : 9.34e-05
Batch : 95 / 196 | Time 270 ms | Train Loss : 4.6962 | Grad Norm : 14.4537 | Learning rate : 9.34e-05
Batch : 96 / 196 | Time 264 ms | Train Loss : 4.7746 | Grad Norm : 7.2656 | Learning rate : 9.33e-05
Batch : 97 / 196 | Time 266 ms | Train Loss : 4.6723 | Grad Norm : 13.4809 | Learning rate : 9.33e-05
Batch : 98 / 196 | Time 269 ms | Train Loss : 4.7686 | Grad Norm : 16.7360 | Learning rate : 9.33e-05
Batch : 99 / 196 | Time 263 ms | Train Loss : 4.7088 | Grad Norm : 12.1910 | Learning rate : 9.32e-05
Batch : 100 / 196 | Time 264 ms | Train Loss : 4.6972 | Grad Norm : 6.6642 | Learning rate : 9.32e-05
Batch : 101 / 196 | Time 264 ms | Train Loss : 4.7915 | Grad Norm : 15.7789 | Learning rate : 9.31e-05
Batch : 102 / 196 | Time 264 ms | Train Loss : 4.6818 | Grad Norm : 17.4942 | Learning rate : 9.31e-05
Batch : 103 / 196 | Time 266 ms | Train Loss : 4.6896 | Grad Norm : 12.3025 | Learning rate : 9.30e-05
Batch : 104 / 196 | Time 264 ms | Train Loss : 4.6681 | Grad Norm : 10.5474 | Learning rate : 9.30e-05
Batch : 105 / 196 | Time 269 ms | Train Loss : 4.6682 | Grad Norm : 13.6041 | Learning rate : 9.29e-05
Batch : 106 / 196 | Time 266 ms | Train Loss : 4.7376 | Grad Norm : 12.0377 | Learning rate : 9.29e-05
Batch : 107 / 196 | Time 263 ms | Train Loss : 4.6814 | Grad Norm : 8.8413 | Learning rate : 9.28e-05
Batch : 108 / 196 | Time 264 ms | Train Loss : 4.6740 | Grad Norm : 13.8832 | Learning rate : 9.28e-05
Batch : 109 / 196 | Time 263 ms | Train Loss : 4.6823 | Grad Norm : 7.6309 | Learning rate : 9.28e-05
Batch : 110 / 196 | Time 266 ms | Train Loss : 4.6113 | Grad Norm : 12.5047 | Learning rate : 9.27e-05
Batch : 111 / 196 | Time 265 ms | Train Loss : 4.6497 | Grad Norm : 7.0578 | Learning rate : 9.27e-05
Batch : 112 / 196 | Time 270 ms | Train Loss : 4.5957 | Grad Norm : 8.0753 | Learning rate : 9.26e-05
Batch : 113 / 196 | Time 264 ms | Train Loss : 4.7153 | Grad Norm : 17.3047 | Learning rate : 9.26e-05
Batch : 114 / 196 | Time 263 ms | Train Loss : 4.6876 | Grad Norm : 12.2929 | Learning rate : 9.25e-05
Batch : 115 / 196 | Time 265 ms | Train Loss : 4.6753 | Grad Norm : 11.0437 | Learning rate : 9.25e-05
Batch : 116 / 196 | Time 265 ms | Train Loss : 4.6720 | Grad Norm : 9.5100 | Learning rate : 9.24e-05
Batch : 117 / 196 | Time 264 ms | Train Loss : 4.8049 | Grad Norm : 16.6933 | Learning rate : 9.24e-05
Batch : 118 / 196 | Time 262 ms | Train Loss : 4.6818 | Grad Norm : 17.2525 | Learning rate : 9.23e-05
Batch : 119 / 196 | Time 265 ms | Train Loss : 4.5788 | Grad Norm : 12.1254 | Learning rate : 9.23e-05
Batch : 120 / 196 | Time 259 ms | Train Loss : 4.7206 | Grad Norm : 21.0133 | Learning rate : 9.22e-05
Batch : 121 / 196 | Time 274 ms | Train Loss : 4.6376 | Grad Norm : 28.2774 | Learning rate : 9.22e-05
Batch : 122 / 196 | Time 265 ms | Train Loss : 4.6670 | Grad Norm : 13.9331 | Learning rate : 9.21e-05
Batch : 123 / 196 | Time 267 ms | Train Loss : 4.7248 | Grad Norm : 12.7382 | Learning rate : 9.21e-05
Batch : 124 / 196 | Time 266 ms | Train Loss : 4.7088 | Grad Norm : 11.9536 | Learning rate : 9.20e-05
Batch : 125 / 196 | Time 262 ms | Train Loss : 4.6804 | Grad Norm : 6.2983 | Learning rate : 9.20e-05
Batch : 126 / 196 | Time 269 ms | Train Loss : 4.6887 | Grad Norm : 14.1034 | Learning rate : 9.20e-05
Batch : 127 / 196 | Time 265 ms | Train Loss : 4.6341 | Grad Norm : 13.9241 | Learning rate : 9.19e-05
Batch : 128 / 196 | Time 263 ms | Train Loss : 4.6364 | Grad Norm : 8.6733 | Learning rate : 9.19e-05
Batch : 129 / 196 | Time 273 ms | Train Loss : 4.7386 | Grad Norm : 10.0774 | Learning rate : 9.18e-05
Batch : 130 / 196 | Time 263 ms | Train Loss : 4.7201 | Grad Norm : 19.0261 | Learning rate : 9.18e-05
Batch : 131 / 196 | Time 267 ms | Train Loss : 4.6334 | Grad Norm : 12.7493 | Learning rate : 9.17e-05
Batch : 132 / 196 | Time 265 ms | Train Loss : 4.6949 | Grad Norm : 9.2813 | Learning rate : 9.17e-05
Batch : 133 / 196 | Time 266 ms | Train Loss : 4.6904 | Grad Norm : 9.1182 | Learning rate : 9.16e-05
Batch : 134 / 196 | Time 266 ms | Train Loss : 4.5871 | Grad Norm : 10.5945 | Learning rate : 9.16e-05
Batch : 135 / 196 | Time 267 ms | Train Loss : 4.6200 | Grad Norm : 14.6120 | Learning rate : 9.15e-05
Batch : 136 / 196 | Time 265 ms | Train Loss : 4.7805 | Grad Norm : 13.6985 | Learning rate : 9.15e-05
Batch : 137 / 196 | Time 270 ms | Train Loss : 4.6057 | Grad Norm : 8.6848 | Learning rate : 9.14e-05
Batch : 138 / 196 | Time 263 ms | Train Loss : 4.6545 | Grad Norm : 13.1813 | Learning rate : 9.14e-05
Batch : 139 / 196 | Time 263 ms | Train Loss : 4.6324 | Grad Norm : 10.4354 | Learning rate : 9.13e-05
Batch : 140 / 196 | Time 265 ms | Train Loss : 4.7174 | Grad Norm : 10.2441 | Learning rate : 9.13e-05
Batch : 141 / 196 | Time 264 ms | Train Loss : 4.5548 | Grad Norm : 8.0527 | Learning rate : 9.12e-05
Batch : 142 / 196 | Time 268 ms | Train Loss : 4.6056 | Grad Norm : 11.5766 | Learning rate : 9.12e-05
Batch : 143 / 196 | Time 265 ms | Train Loss : 4.6304 | Grad Norm : 9.3936 | Learning rate : 9.11e-05
Batch : 144 / 196 | Time 264 ms | Train Loss : 4.6392 | Grad Norm : 8.6432 | Learning rate : 9.11e-05
Batch : 145 / 196 | Time 263 ms | Train Loss : 4.6095 | Grad Norm : 11.7756 | Learning rate : 9.10e-05
Batch : 146 / 196 | Time 264 ms | Train Loss : 4.7600 | Grad Norm : 11.3966 | Learning rate : 9.10e-05
Batch : 147 / 196 | Time 264 ms | Train Loss : 4.6709 | Grad Norm : 5.7359 | Learning rate : 9.09e-05
Batch : 148 / 196 | Time 265 ms | Train Loss : 4.7534 | Grad Norm : 15.5635 | Learning rate : 9.09e-05
Batch : 149 / 196 | Time 271 ms | Train Loss : 4.7389 | Grad Norm : 8.8670 | Learning rate : 9.08e-05
Batch : 150 / 196 | Time 269 ms | Train Loss : 4.5778 | Grad Norm : 14.8418 | Learning rate : 9.08e-05
Batch : 151 / 196 | Time 265 ms | Train Loss : 4.6226 | Grad Norm : 10.6526 | Learning rate : 9.07e-05
Batch : 152 / 196 | Time 265 ms | Train Loss : 4.5904 | Grad Norm : 8.4492 | Learning rate : 9.06e-05
Batch : 153 / 196 | Time 264 ms | Train Loss : 4.7247 | Grad Norm : 11.5010 | Learning rate : 9.06e-05
Batch : 154 / 196 | Time 266 ms | Train Loss : 4.7005 | Grad Norm : 14.7588 | Learning rate : 9.05e-05
Batch : 155 / 196 | Time 263 ms | Train Loss : 4.6561 | Grad Norm : 15.0926 | Learning rate : 9.05e-05
Batch : 156 / 196 | Time 263 ms | Train Loss : 4.6967 | Grad Norm : 11.4814 | Learning rate : 9.04e-05
Batch : 157 / 196 | Time 265 ms | Train Loss : 4.5949 | Grad Norm : 9.4770 | Learning rate : 9.04e-05
Batch : 158 / 196 | Time 265 ms | Train Loss : 4.6555 | Grad Norm : 7.0151 | Learning rate : 9.03e-05
Batch : 159 / 196 | Time 272 ms | Train Loss : 4.6615 | Grad Norm : 11.3816 | Learning rate : 9.03e-05
Batch : 160 / 196 | Time 264 ms | Train Loss : 4.6036 | Grad Norm : 7.8909 | Learning rate : 9.02e-05
Batch : 161 / 196 | Time 264 ms | Train Loss : 4.8116 | Grad Norm : 21.0757 | Learning rate : 9.02e-05
Batch : 162 / 196 | Time 265 ms | Train Loss : 4.7046 | Grad Norm : 21.7739 | Learning rate : 9.01e-05
Batch : 163 / 196 | Time 268 ms | Train Loss : 4.6172 | Grad Norm : 10.8581 | Learning rate : 9.01e-05
Batch : 164 / 196 | Time 267 ms | Train Loss : 4.6754 | Grad Norm : 13.9964 | Learning rate : 9.00e-05
Batch : 165 / 196 | Time 265 ms | Train Loss : 4.6215 | Grad Norm : 11.8024 | Learning rate : 9.00e-05
Batch : 166 / 196 | Time 265 ms | Train Loss : 4.5946 | Grad Norm : 13.7283 | Learning rate : 8.99e-05
Batch : 167 / 196 | Time 268 ms | Train Loss : 4.5341 | Grad Norm : 13.4180 | Learning rate : 8.99e-05
Batch : 168 / 196 | Time 270 ms | Train Loss : 4.5858 | Grad Norm : 11.3606 | Learning rate : 8.98e-05
Batch : 169 / 196 | Time 264 ms | Train Loss : 4.5119 | Grad Norm : 13.5828 | Learning rate : 8.97e-05
Batch : 170 / 196 | Time 267 ms | Train Loss : 4.6329 | Grad Norm : 13.8823 | Learning rate : 8.97e-05
Batch : 171 / 196 | Time 262 ms | Train Loss : 4.5879 | Grad Norm : 9.3215 | Learning rate : 8.96e-05
Batch : 172 / 196 | Time 264 ms | Train Loss : 4.6737 | Grad Norm : 13.6668 | Learning rate : 8.96e-05
Batch : 173 / 196 | Time 266 ms | Train Loss : 4.6008 | Grad Norm : 9.3149 | Learning rate : 8.95e-05
Batch : 174 / 196 | Time 264 ms | Train Loss : 4.5175 | Grad Norm : 15.7422 | Learning rate : 8.95e-05
Batch : 175 / 196 | Time 265 ms | Train Loss : 4.5872 | Grad Norm : 10.5628 | Learning rate : 8.94e-05
Batch : 176 / 196 | Time 264 ms | Train Loss : 4.5549 | Grad Norm : 11.7715 | Learning rate : 8.94e-05
Batch : 177 / 196 | Time 265 ms | Train Loss : 4.6787 | Grad Norm : 12.4490 | Learning rate : 8.93e-05
Batch : 178 / 196 | Time 264 ms | Train Loss : 4.7238 | Grad Norm : 8.9832 | Learning rate : 8.93e-05
Batch : 179 / 196 | Time 262 ms | Train Loss : 4.6264 | Grad Norm : 15.5074 | Learning rate : 8.92e-05
Batch : 180 / 196 | Time 265 ms | Train Loss : 4.6712 | Grad Norm : 12.6413 | Learning rate : 8.91e-05
Batch : 181 / 196 | Time 263 ms | Train Loss : 4.6201 | Grad Norm : 8.1258 | Learning rate : 8.91e-05
Batch : 182 / 196 | Time 263 ms | Train Loss : 4.6209 | Grad Norm : 13.4000 | Learning rate : 8.90e-05
Batch : 183 / 196 | Time 265 ms | Train Loss : 4.6559 | Grad Norm : 10.1370 | Learning rate : 8.90e-05
Batch : 184 / 196 | Time 264 ms | Train Loss : 4.6767 | Grad Norm : 11.4167 | Learning rate : 8.89e-05
Batch : 185 / 196 | Time 265 ms | Train Loss : 4.6144 | Grad Norm : 13.7056 | Learning rate : 8.89e-05
Batch : 186 / 196 | Time 264 ms | Train Loss : 4.6563 | Grad Norm : 10.2621 | Learning rate : 8.88e-05
Batch : 187 / 196 | Time 264 ms | Train Loss : 4.6549 | Grad Norm : 13.3678 | Learning rate : 8.88e-05
Batch : 188 / 196 | Time 265 ms | Train Loss : 4.5666 | Grad Norm : 10.8179 | Learning rate : 8.87e-05
Batch : 189 / 196 | Time 265 ms | Train Loss : 4.5503 | Grad Norm : 8.5253 | Learning rate : 8.86e-05
Batch : 190 / 196 | Time 264 ms | Train Loss : 4.4852 | Grad Norm : 11.0273 | Learning rate : 8.86e-05
Batch : 191 / 196 | Time 264 ms | Train Loss : 4.6362 | Grad Norm : 17.7111 | Learning rate : 8.85e-05
Batch : 192 / 196 | Time 263 ms | Train Loss : 4.5729 | Grad Norm : 10.0119 | Learning rate : 8.85e-05
Batch : 193 / 196 | Time 263 ms | Train Loss : 4.6203 | Grad Norm : 16.1850 | Learning rate : 8.84e-05
Batch : 194 / 196 | Time 266 ms | Train Loss : 4.5848 | Grad Norm : 12.9549 | Learning rate : 8.84e-05
Batch : 195 / 196 | Time 111 ms | Train Loss : 3.2041 | Grad Norm : 17.8431 | Learning rate : 8.83e-05
Epoch : 2 | Training Loss : 3.2041| Accuracy on test set : 0.4176
 Batch : 0 / 196 | Time 275 ms | Train Loss : 4.6426 | Grad Norm : 11.9491 | Learning rate : 8.82e-05
Batch : 1 / 196 | Time 267 ms | Train Loss : 4.5686 | Grad Norm : 16.0752 | Learning rate : 8.82e-05
Batch : 2 / 196 | Time 266 ms | Train Loss : 4.6149 | Grad Norm : 17.5949 | Learning rate : 8.81e-05
Batch : 3 / 196 | Time 264 ms | Train Loss : 4.6227 | Grad Norm : 17.2249 | Learning rate : 8.81e-05
Batch : 4 / 196 | Time 264 ms | Train Loss : 4.6224 | Grad Norm : 16.4038 | Learning rate : 8.80e-05
Batch : 5 / 196 | Time 266 ms | Train Loss : 4.5392 | Grad Norm : 12.3245 | Learning rate : 8.80e-05
Batch : 6 / 196 | Time 265 ms | Train Loss : 4.5618 | Grad Norm : 15.8400 | Learning rate : 8.79e-05
Batch : 7 / 196 | Time 263 ms | Train Loss : 4.5444 | Grad Norm : 17.1459 | Learning rate : 8.78e-05
Batch : 8 / 196 | Time 264 ms | Train Loss : 4.7042 | Grad Norm : 15.4694 | Learning rate : 8.78e-05
Batch : 9 / 196 | Time 271 ms | Train Loss : 4.7866 | Grad Norm : 13.5464 | Learning rate : 8.77e-05
Batch : 10 / 196 | Time 265 ms | Train Loss : 4.5861 | Grad Norm : 12.7482 | Learning rate : 8.77e-05
Batch : 11 / 196 | Time 268 ms | Train Loss : 4.5835 | Grad Norm : 10.7563 | Learning rate : 8.76e-05
Batch : 12 / 196 | Time 267 ms | Train Loss : 4.4979 | Grad Norm : 12.3932 | Learning rate : 8.75e-05
Batch : 13 / 196 | Time 265 ms | Train Loss : 4.6611 | Grad Norm : 8.6879 | Learning rate : 8.75e-05
Batch : 14 / 196 | Time 265 ms | Train Loss : 4.5461 | Grad Norm : 11.8440 | Learning rate : 8.74e-05
Batch : 15 / 196 | Time 264 ms | Train Loss : 4.5952 | Grad Norm : 11.6895 | Learning rate : 8.74e-05
Batch : 16 / 196 | Time 264 ms | Train Loss : 4.6069 | Grad Norm : 10.2974 | Learning rate : 8.73e-05
Batch : 17 / 196 | Time 265 ms | Train Loss : 4.6229 | Grad Norm : 8.2319 | Learning rate : 8.73e-05
Batch : 18 / 196 | Time 267 ms | Train Loss : 4.6468 | Grad Norm : 8.9571 | Learning rate : 8.72e-05
Batch : 19 / 196 | Time 267 ms | Train Loss : 4.4984 | Grad Norm : 14.8417 | Learning rate : 8.71e-05
Batch : 20 / 196 | Time 267 ms | Train Loss : 4.6168 | Grad Norm : 14.5622 | Learning rate : 8.71e-05
Batch : 21 / 196 | Time 258 ms | Train Loss : 4.6281 | Grad Norm : 14.0521 | Learning rate : 8.70e-05
Batch : 22 / 196 | Time 265 ms | Train Loss : 4.6889 | Grad Norm : 21.7218 | Learning rate : 8.70e-05
Batch : 23 / 196 | Time 268 ms | Train Loss : 4.6459 | Grad Norm : 15.0124 | Learning rate : 8.69e-05
Batch : 24 / 196 | Time 265 ms | Train Loss : 4.5668 | Grad Norm : 16.4048 | Learning rate : 8.68e-05
Batch : 25 / 196 | Time 266 ms | Train Loss : 4.6261 | Grad Norm : 15.7410 | Learning rate : 8.68e-05
Batch : 26 / 196 | Time 267 ms | Train Loss : 4.5325 | Grad Norm : 14.1284 | Learning rate : 8.67e-05
Batch : 27 / 196 | Time 265 ms | Train Loss : 4.5766 | Grad Norm : 9.8925 | Learning rate : 8.67e-05
Batch : 28 / 196 | Time 264 ms | Train Loss : 4.6675 | Grad Norm : 12.0532 | Learning rate : 8.66e-05
Batch : 29 / 196 | Time 263 ms | Train Loss : 4.4149 | Grad Norm : 10.2907 | Learning rate : 8.65e-05
Batch : 30 / 196 | Time 268 ms | Train Loss : 4.6015 | Grad Norm : 16.8139 | Learning rate : 8.65e-05
Batch : 31 / 196 | Time 269 ms | Train Loss : 4.7098 | Grad Norm : 15.8782 | Learning rate : 8.64e-05
Batch : 32 / 196 | Time 266 ms | Train Loss : 4.5651 | Grad Norm : 12.3326 | Learning rate : 8.63e-05
Batch : 33 / 196 | Time 264 ms | Train Loss : 4.5943 | Grad Norm : 20.9198 | Learning rate : 8.63e-05
Batch : 34 / 196 | Time 266 ms | Train Loss : 4.6667 | Grad Norm : 7.1432 | Learning rate : 8.62e-05
Batch : 35 / 196 | Time 265 ms | Train Loss : 4.5788 | Grad Norm : 14.0456 | Learning rate : 8.62e-05
Batch : 36 / 196 | Time 265 ms | Train Loss : 4.5810 | Grad Norm : 14.3432 | Learning rate : 8.61e-05
Batch : 37 / 196 | Time 264 ms | Train Loss : 4.5378 | Grad Norm : 10.1442 | Learning rate : 8.60e-05
Batch : 38 / 196 | Time 267 ms | Train Loss : 4.4962 | Grad Norm : 14.5034 | Learning rate : 8.60e-05
Batch : 39 / 196 | Time 266 ms | Train Loss : 4.6870 | Grad Norm : 21.7750 | Learning rate : 8.59e-05
Batch : 40 / 196 | Time 266 ms | Train Loss : 4.5636 | Grad Norm : 11.0643 | Learning rate : 8.59e-05
Batch : 41 / 196 | Time 263 ms | Train Loss : 4.6029 | Grad Norm : 11.7203 | Learning rate : 8.58e-05
Batch : 42 / 196 | Time 265 ms | Train Loss : 4.5395 | Grad Norm : 13.9635 | Learning rate : 8.57e-05
Batch : 43 / 196 | Time 264 ms | Train Loss : 4.5449 | Grad Norm : 13.9069 | Learning rate : 8.57e-05
Batch : 44 / 196 | Time 269 ms | Train Loss : 4.5276 | Grad Norm : 8.1122 | Learning rate : 8.56e-05
Batch : 45 / 196 | Time 267 ms | Train Loss : 4.6347 | Grad Norm : 22.3978 | Learning rate : 8.55e-05
Batch : 46 / 196 | Time 268 ms | Train Loss : 4.6520 | Grad Norm : 28.7269 | Learning rate : 8.55e-05
Batch : 47 / 196 | Time 266 ms | Train Loss : 4.5065 | Grad Norm : 20.5956 | Learning rate : 8.54e-05
Batch : 48 / 196 | Time 265 ms | Train Loss : 4.5656 | Grad Norm : 18.0548 | Learning rate : 8.54e-05
Batch : 49 / 196 | Time 266 ms | Train Loss : 4.6664 | Grad Norm : 10.7158 | Learning rate : 8.53e-05
Batch : 50 / 196 | Time 267 ms | Train Loss : 4.6172 | Grad Norm : 8.3324 | Learning rate : 8.52e-05
Batch : 51 / 196 | Time 265 ms | Train Loss : 4.5653 | Grad Norm : 12.8154 | Learning rate : 8.52e-05
Batch : 52 / 196 | Time 269 ms | Train Loss : 4.5784 | Grad Norm : 14.0252 | Learning rate : 8.51e-05
Batch : 53 / 196 | Time 266 ms | Train Loss : 4.6249 | Grad Norm : 7.6614 | Learning rate : 8.50e-05
Batch : 54 / 196 | Time 272 ms | Train Loss : 4.5746 | Grad Norm : 12.5306 | Learning rate : 8.50e-05
Batch : 55 / 196 | Time 267 ms | Train Loss : 4.7214 | Grad Norm : 15.8411 | Learning rate : 8.49e-05
Batch : 56 / 196 | Time 266 ms | Train Loss : 4.4219 | Grad Norm : 8.7995 | Learning rate : 8.48e-05
Batch : 57 / 196 | Time 266 ms | Train Loss : 4.6074 | Grad Norm : 20.6358 | Learning rate : 8.48e-05
Batch : 58 / 196 | Time 260 ms | Train Loss : 4.5764 | Grad Norm : 21.8955 | Learning rate : 8.47e-05
Batch : 59 / 196 | Time 265 ms | Train Loss : 4.5908 | Grad Norm : 12.9953 | Learning rate : 8.47e-05
Batch : 60 / 196 | Time 266 ms | Train Loss : 4.5356 | Grad Norm : 12.6733 | Learning rate : 8.46e-05
Batch : 61 / 196 | Time 277 ms | Train Loss : 4.5305 | Grad Norm : 10.8902 | Learning rate : 8.45e-05
Batch : 62 / 196 | Time 264 ms | Train Loss : 4.7089 | Grad Norm : 23.5409 | Learning rate : 8.45e-05
Batch : 63 / 196 | Time 267 ms | Train Loss : 4.4875 | Grad Norm : 12.0286 | Learning rate : 8.44e-05
Batch : 64 / 196 | Time 264 ms | Train Loss : 4.5432 | Grad Norm : 21.4510 | Learning rate : 8.43e-05
Batch : 65 / 196 | Time 269 ms | Train Loss : 4.5980 | Grad Norm : 22.8225 | Learning rate : 8.43e-05
Batch : 66 / 196 | Time 269 ms | Train Loss : 4.6273 | Grad Norm : 8.9630 | Learning rate : 8.42e-05
Batch : 67 / 196 | Time 271 ms | Train Loss : 4.4958 | Grad Norm : 19.2792 | Learning rate : 8.41e-05
Batch : 68 / 196 | Time 268 ms | Train Loss : 4.5846 | Grad Norm : 14.6537 | Learning rate : 8.41e-05
Batch : 69 / 196 | Time 266 ms | Train Loss : 4.6266 | Grad Norm : 9.5801 | Learning rate : 8.40e-05
Batch : 70 / 196 | Time 266 ms | Train Loss : 4.5793 | Grad Norm : 11.5753 | Learning rate : 8.39e-05
Batch : 71 / 196 | Time 267 ms | Train Loss : 4.5464 | Grad Norm : 9.9465 | Learning rate : 8.39e-05
Batch : 72 / 196 | Time 265 ms | Train Loss : 4.6872 | Grad Norm : 12.0853 | Learning rate : 8.38e-05
Batch : 73 / 196 | Time 266 ms | Train Loss : 4.7522 | Grad Norm : 16.6912 | Learning rate : 8.37e-05
Batch : 74 / 196 | Time 266 ms | Train Loss : 4.5779 | Grad Norm : 10.4246 | Learning rate : 8.37e-05
Batch : 75 / 196 | Time 271 ms | Train Loss : 4.4806 | Grad Norm : 11.8630 | Learning rate : 8.36e-05
Batch : 76 / 196 | Time 270 ms | Train Loss : 4.6522 | Grad Norm : 17.2301 | Learning rate : 8.35e-05
Batch : 77 / 196 | Time 265 ms | Train Loss : 4.6800 | Grad Norm : 12.1969 | Learning rate : 8.35e-05
Batch : 78 / 196 | Time 264 ms | Train Loss : 4.5873 | Grad Norm : 14.3656 | Learning rate : 8.34e-05
Batch : 79 / 196 | Time 267 ms | Train Loss : 4.5742 | Grad Norm : 9.2566 | Learning rate : 8.34e-05
Batch : 80 / 196 | Time 267 ms | Train Loss : 4.6424 | Grad Norm : 17.5946 | Learning rate : 8.33e-05
Batch : 81 / 196 | Time 266 ms | Train Loss : 4.6215 | Grad Norm : 13.7411 | Learning rate : 8.32e-05
Batch : 82 / 196 | Time 273 ms | Train Loss : 4.6176 | Grad Norm : 15.7043 | Learning rate : 8.32e-05
Batch : 83 / 196 | Time 268 ms | Train Loss : 4.5596 | Grad Norm : 8.4831 | Learning rate : 8.31e-05
Batch : 84 / 196 | Time 264 ms | Train Loss : 4.4633 | Grad Norm : 11.3819 | Learning rate : 8.30e-05
Batch : 85 / 196 | Time 266 ms | Train Loss : 4.6705 | Grad Norm : 10.9325 | Learning rate : 8.30e-05
Batch : 86 / 196 | Time 265 ms | Train Loss : 4.6280 | Grad Norm : 19.2621 | Learning rate : 8.29e-05
Batch : 87 / 196 | Time 265 ms | Train Loss : 4.5901 | Grad Norm : 12.4343 | Learning rate : 8.28e-05
Batch : 88 / 196 | Time 269 ms | Train Loss : 4.6098 | Grad Norm : 10.8820 | Learning rate : 8.27e-05
Batch : 89 / 196 | Time 264 ms | Train Loss : 4.5411 | Grad Norm : 14.2056 | Learning rate : 8.27e-05
Batch : 90 / 196 | Time 267 ms | Train Loss : 4.4894 | Grad Norm : 11.7174 | Learning rate : 8.26e-05
Batch : 91 / 196 | Time 264 ms | Train Loss : 4.5816 | Grad Norm : 16.9138 | Learning rate : 8.25e-05
Batch : 92 / 196 | Time 265 ms | Train Loss : 4.6036 | Grad Norm : 14.6268 | Learning rate : 8.25e-05
Batch : 93 / 196 | Time 265 ms | Train Loss : 4.6846 | Grad Norm : 20.6322 | Learning rate : 8.24e-05
Batch : 94 / 196 | Time 263 ms | Train Loss : 4.5900 | Grad Norm : 14.1522 | Learning rate : 8.23e-05
Batch : 95 / 196 | Time 266 ms | Train Loss : 4.5038 | Grad Norm : 22.4488 | Learning rate : 8.23e-05
Batch : 96 / 196 | Time 273 ms | Train Loss : 4.5097 | Grad Norm : 9.4516 | Learning rate : 8.22e-05
Batch : 97 / 196 | Time 264 ms | Train Loss : 4.6469 | Grad Norm : 14.5890 | Learning rate : 8.21e-05
Batch : 98 / 196 | Time 261 ms | Train Loss : 4.6272 | Grad Norm : 21.7094 | Learning rate : 8.21e-05
Batch : 99 / 196 | Time 265 ms | Train Loss : 4.5190 | Grad Norm : 20.6910 | Learning rate : 8.20e-05
Batch : 100 / 196 | Time 267 ms | Train Loss : 4.5578 | Grad Norm : 15.7724 | Learning rate : 8.19e-05
Batch : 101 / 196 | Time 266 ms | Train Loss : 4.5812 | Grad Norm : 12.9037 | Learning rate : 8.19e-05
Batch : 102 / 196 | Time 264 ms | Train Loss : 4.5558 | Grad Norm : 11.6654 | Learning rate : 8.18e-05
Batch : 103 / 196 | Time 266 ms | Train Loss : 4.6405 | Grad Norm : 15.6274 | Learning rate : 8.17e-05
Batch : 104 / 196 | Time 266 ms | Train Loss : 4.5067 | Grad Norm : 16.2594 | Learning rate : 8.17e-05
Batch : 105 / 196 | Time 269 ms | Train Loss : 4.5461 | Grad Norm : 13.6429 | Learning rate : 8.16e-05
Batch : 106 / 196 | Time 259 ms | Train Loss : 4.6377 | Grad Norm : 10.9449 | Learning rate : 8.15e-05
Batch : 107 / 196 | Time 268 ms | Train Loss : 4.5977 | Grad Norm : 12.7920 | Learning rate : 8.15e-05
Batch : 108 / 196 | Time 264 ms | Train Loss : 4.5699 | Grad Norm : 7.7202 | Learning rate : 8.14e-05
Batch : 109 / 196 | Time 265 ms | Train Loss : 4.5884 | Grad Norm : 14.6328 | Learning rate : 8.13e-05
Batch : 110 / 196 | Time 259 ms | Train Loss : 4.5211 | Grad Norm : 13.6406 | Learning rate : 8.12e-05
Batch : 111 / 196 | Time 262 ms | Train Loss : 4.4917 | Grad Norm : 13.2431 | Learning rate : 8.12e-05
Batch : 112 / 196 | Time 267 ms | Train Loss : 4.5444 | Grad Norm : 17.2304 | Learning rate : 8.11e-05
Batch : 113 / 196 | Time 267 ms | Train Loss : 4.5400 | Grad Norm : 11.7941 | Learning rate : 8.10e-05
Batch : 114 / 196 | Time 273 ms | Train Loss : 4.5760 | Grad Norm : 21.5397 | Learning rate : 8.10e-05
Batch : 115 / 196 | Time 263 ms | Train Loss : 4.5404 | Grad Norm : 20.1961 | Learning rate : 8.09e-05
Batch : 116 / 196 | Time 265 ms | Train Loss : 4.5932 | Grad Norm : 8.7111 | Learning rate : 8.08e-05
Batch : 117 / 196 | Time 263 ms | Train Loss : 4.5588 | Grad Norm : 13.9681 | Learning rate : 8.08e-05
Batch : 118 / 196 | Time 265 ms | Train Loss : 4.5015 | Grad Norm : 14.3566 | Learning rate : 8.07e-05
Batch : 119 / 196 | Time 258 ms | Train Loss : 4.4820 | Grad Norm : 11.5887 | Learning rate : 8.06e-05
Batch : 120 / 196 | Time 267 ms | Train Loss : 4.4637 | Grad Norm : 13.8203 | Learning rate : 8.05e-05
Batch : 121 / 196 | Time 265 ms | Train Loss : 4.4672 | Grad Norm : 10.9910 | Learning rate : 8.05e-05
Batch : 122 / 196 | Time 265 ms | Train Loss : 4.4422 | Grad Norm : 15.1148 | Learning rate : 8.04e-05
Batch : 123 / 196 | Time 260 ms | Train Loss : 4.5727 | Grad Norm : 18.7957 | Learning rate : 8.03e-05
Batch : 124 / 196 | Time 266 ms | Train Loss : 4.5320 | Grad Norm : 13.7039 | Learning rate : 8.03e-05
Batch : 125 / 196 | Time 264 ms | Train Loss : 4.4892 | Grad Norm : 12.3420 | Learning rate : 8.02e-05
Batch : 126 / 196 | Time 265 ms | Train Loss : 4.6037 | Grad Norm : 7.2134 | Learning rate : 8.01e-05
Batch : 127 / 196 | Time 265 ms | Train Loss : 4.4232 | Grad Norm : 12.0570 | Learning rate : 8.00e-05
Batch : 128 / 196 | Time 264 ms | Train Loss : 4.4982 | Grad Norm : 11.0427 | Learning rate : 8.00e-05
Batch : 129 / 196 | Time 259 ms | Train Loss : 4.5232 | Grad Norm : 16.9599 | Learning rate : 7.99e-05
Batch : 130 / 196 | Time 261 ms | Train Loss : 4.6147 | Grad Norm : 12.2425 | Learning rate : 7.98e-05
Batch : 131 / 196 | Time 264 ms | Train Loss : 4.5073 | Grad Norm : 11.0288 | Learning rate : 7.98e-05
Batch : 132 / 196 | Time 269 ms | Train Loss : 4.5348 | Grad Norm : 12.1462 | Learning rate : 7.97e-05
Batch : 133 / 196 | Time 263 ms | Train Loss : 4.4952 | Grad Norm : 9.4999 | Learning rate : 7.96e-05
Batch : 134 / 196 | Time 263 ms | Train Loss : 4.5060 | Grad Norm : 17.3160 | Learning rate : 7.95e-05
Batch : 135 / 196 | Time 265 ms | Train Loss : 4.6018 | Grad Norm : 18.5478 | Learning rate : 7.95e-05
Batch : 136 / 196 | Time 268 ms | Train Loss : 4.5087 | Grad Norm : 10.6044 | Learning rate : 7.94e-05
Batch : 137 / 196 | Time 266 ms | Train Loss : 4.5926 | Grad Norm : 15.6654 | Learning rate : 7.93e-05
Batch : 138 / 196 | Time 264 ms | Train Loss : 4.4990 | Grad Norm : 18.3785 | Learning rate : 7.93e-05
Batch : 139 / 196 | Time 266 ms | Train Loss : 4.5647 | Grad Norm : 12.6726 | Learning rate : 7.92e-05
Batch : 140 / 196 | Time 264 ms | Train Loss : 4.5204 | Grad Norm : 14.3588 | Learning rate : 7.91e-05
Batch : 141 / 196 | Time 271 ms | Train Loss : 4.4698 | Grad Norm : 10.2223 | Learning rate : 7.90e-05
Batch : 142 / 196 | Time 269 ms | Train Loss : 4.6165 | Grad Norm : 8.7863 | Learning rate : 7.90e-05
Batch : 143 / 196 | Time 264 ms | Train Loss : 4.5821 | Grad Norm : 10.3557 | Learning rate : 7.89e-05
Batch : 144 / 196 | Time 266 ms | Train Loss : 4.4901 | Grad Norm : 12.1769 | Learning rate : 7.88e-05
Batch : 145 / 196 | Time 265 ms | Train Loss : 4.5799 | Grad Norm : 9.8613 | Learning rate : 7.88e-05
Batch : 146 / 196 | Time 268 ms | Train Loss : 4.5258 | Grad Norm : 21.2927 | Learning rate : 7.87e-05
Batch : 147 / 196 | Time 266 ms | Train Loss : 4.5970 | Grad Norm : 16.9172 | Learning rate : 7.86e-05
Batch : 148 / 196 | Time 265 ms | Train Loss : 4.4504 | Grad Norm : 12.8899 | Learning rate : 7.85e-05
Batch : 149 / 196 | Time 265 ms | Train Loss : 4.5548 | Grad Norm : 13.1883 | Learning rate : 7.85e-05
Batch : 150 / 196 | Time 265 ms | Train Loss : 4.5079 | Grad Norm : 18.4057 | Learning rate : 7.84e-05
Batch : 151 / 196 | Time 265 ms | Train Loss : 4.5367 | Grad Norm : 21.0358 | Learning rate : 7.83e-05
Batch : 152 / 196 | Time 264 ms | Train Loss : 4.5975 | Grad Norm : 6.0465 | Learning rate : 7.82e-05
Batch : 153 / 196 | Time 264 ms | Train Loss : 4.5080 | Grad Norm : 14.6118 | Learning rate : 7.82e-05
Batch : 154 / 196 | Time 280 ms | Train Loss : 4.5177 | Grad Norm : 12.9793 | Learning rate : 7.81e-05
Batch : 155 / 196 | Time 264 ms | Train Loss : 4.5846 | Grad Norm : 9.5982 | Learning rate : 7.80e-05
Batch : 156 / 196 | Time 264 ms | Train Loss : 4.6477 | Grad Norm : 12.8353 | Learning rate : 7.79e-05
Batch : 157 / 196 | Time 266 ms | Train Loss : 4.5136 | Grad Norm : 10.1773 | Learning rate : 7.79e-05
Batch : 158 / 196 | Time 264 ms | Train Loss : 4.6180 | Grad Norm : 11.3903 | Learning rate : 7.78e-05
Batch : 159 / 196 | Time 268 ms | Train Loss : 4.5334 | Grad Norm : 14.3826 | Learning rate : 7.77e-05
Batch : 160 / 196 | Time 265 ms | Train Loss : 4.4960 | Grad Norm : 14.8891 | Learning rate : 7.76e-05
Batch : 161 / 196 | Time 265 ms | Train Loss : 4.5102 | Grad Norm : 12.9621 | Learning rate : 7.76e-05
Batch : 162 / 196 | Time 268 ms | Train Loss : 4.4714 | Grad Norm : 11.4185 | Learning rate : 7.75e-05
Batch : 163 / 196 | Time 264 ms | Train Loss : 4.6077 | Grad Norm : 16.8335 | Learning rate : 7.74e-05
Batch : 164 / 196 | Time 264 ms | Train Loss : 4.5323 | Grad Norm : 15.2459 | Learning rate : 7.74e-05
Batch : 165 / 196 | Time 264 ms | Train Loss : 4.5359 | Grad Norm : 11.0593 | Learning rate : 7.73e-05
Batch : 166 / 196 | Time 265 ms | Train Loss : 4.5260 | Grad Norm : 14.0501 | Learning rate : 7.72e-05
Batch : 167 / 196 | Time 270 ms | Train Loss : 4.4856 | Grad Norm : 12.9673 | Learning rate : 7.71e-05
Batch : 168 / 196 | Time 264 ms | Train Loss : 4.6057 | Grad Norm : 10.2911 | Learning rate : 7.71e-05
Batch : 169 / 196 | Time 272 ms | Train Loss : 4.5494 | Grad Norm : 8.1023 | Learning rate : 7.70e-05
Batch : 170 / 196 | Time 265 ms | Train Loss : 4.6935 | Grad Norm : 20.0197 | Learning rate : 7.69e-05
Batch : 171 / 196 | Time 264 ms | Train Loss : 4.5148 | Grad Norm : 11.6921 | Learning rate : 7.68e-05
Batch : 172 / 196 | Time 264 ms | Train Loss : 4.5113 | Grad Norm : 12.2039 | Learning rate : 7.68e-05
Batch : 173 / 196 | Time 264 ms | Train Loss : 4.5349 | Grad Norm : 14.8965 | Learning rate : 7.67e-05
Batch : 174 / 196 | Time 266 ms | Train Loss : 4.5213 | Grad Norm : 13.2168 | Learning rate : 7.66e-05
Batch : 175 / 196 | Time 264 ms | Train Loss : 4.5736 | Grad Norm : 17.4054 | Learning rate : 7.65e-05
Batch : 176 / 196 | Time 268 ms | Train Loss : 4.4866 | Grad Norm : 16.0970 | Learning rate : 7.65e-05
Batch : 177 / 196 | Time 272 ms | Train Loss : 4.5656 | Grad Norm : 18.5939 | Learning rate : 7.64e-05
Batch : 178 / 196 | Time 268 ms | Train Loss : 4.6104 | Grad Norm : 32.9760 | Learning rate : 7.63e-05
Batch : 179 / 196 | Time 265 ms | Train Loss : 4.4908 | Grad Norm : 15.6219 | Learning rate : 7.62e-05
Batch : 180 / 196 | Time 263 ms | Train Loss : 4.6332 | Grad Norm : 21.6339 | Learning rate : 7.61e-05
Batch : 181 / 196 | Time 264 ms | Train Loss : 4.5467 | Grad Norm : 19.2852 | Learning rate : 7.61e-05
Batch : 182 / 196 | Time 272 ms | Train Loss : 4.5081 | Grad Norm : 8.7445 | Learning rate : 7.60e-05
Batch : 183 / 196 | Time 265 ms | Train Loss : 4.5545 | Grad Norm : 20.3240 | Learning rate : 7.59e-05
Batch : 184 / 196 | Time 266 ms | Train Loss : 4.4607 | Grad Norm : 14.1698 | Learning rate : 7.58e-05
Batch : 185 / 196 | Time 275 ms | Train Loss : 4.6074 | Grad Norm : 13.3632 | Learning rate : 7.58e-05
Batch : 186 / 196 | Time 264 ms | Train Loss : 4.6787 | Grad Norm : 24.1152 | Learning rate : 7.57e-05
Batch : 187 / 196 | Time 266 ms | Train Loss : 4.5216 | Grad Norm : 19.8652 | Learning rate : 7.56e-05
Batch : 188 / 196 | Time 265 ms | Train Loss : 4.6170 | Grad Norm : 13.6659 | Learning rate : 7.55e-05
Batch : 189 / 196 | Time 264 ms | Train Loss : 4.5449 | Grad Norm : 16.0215 | Learning rate : 7.55e-05
Batch : 190 / 196 | Time 265 ms | Train Loss : 4.5527 | Grad Norm : 19.8824 | Learning rate : 7.54e-05
Batch : 191 / 196 | Time 263 ms | Train Loss : 4.3881 | Grad Norm : 10.4727 | Learning rate : 7.53e-05
Batch : 192 / 196 | Time 263 ms | Train Loss : 4.5878 | Grad Norm : 18.2401 | Learning rate : 7.52e-05
Batch : 193 / 196 | Time 265 ms | Train Loss : 4.6234 | Grad Norm : 18.1416 | Learning rate : 7.52e-05
Batch : 194 / 196 | Time 270 ms | Train Loss : 4.5567 | Grad Norm : 9.8067 | Learning rate : 7.51e-05
Batch : 195 / 196 | Time 115 ms | Train Loss : 3.4216 | Grad Norm : 13.6146 | Learning rate : 7.50e-05
Epoch : 3 | Training Loss : 3.4216| Accuracy on test set : 0.4509
 Batch : 0 / 196 | Time 274 ms | Train Loss : 4.6379 | Grad Norm : 20.2889 | Learning rate : 7.49e-05
Batch : 1 / 196 | Time 266 ms | Train Loss : 4.5828 | Grad Norm : 21.0483 | Learning rate : 7.48e-05
Batch : 2 / 196 | Time 270 ms | Train Loss : 4.5209 | Grad Norm : 14.2615 | Learning rate : 7.48e-05
Batch : 3 / 196 | Time 265 ms | Train Loss : 4.4432 | Grad Norm : 16.4799 | Learning rate : 7.47e-05
Batch : 4 / 196 | Time 265 ms | Train Loss : 4.4420 | Grad Norm : 14.9182 | Learning rate : 7.46e-05
Batch : 5 / 196 | Time 265 ms | Train Loss : 4.4300 | Grad Norm : 15.8034 | Learning rate : 7.45e-05
Batch : 6 / 196 | Time 263 ms | Train Loss : 4.4657 | Grad Norm : 8.8308 | Learning rate : 7.45e-05
Batch : 7 / 196 | Time 269 ms | Train Loss : 4.5362 | Grad Norm : 12.6490 | Learning rate : 7.44e-05
Batch : 8 / 196 | Time 265 ms | Train Loss : 4.4691 | Grad Norm : 10.1473 | Learning rate : 7.43e-05
Batch : 9 / 196 | Time 266 ms | Train Loss : 4.4820 | Grad Norm : 14.0385 | Learning rate : 7.42e-05
Batch : 10 / 196 | Time 265 ms | Train Loss : 4.5076 | Grad Norm : 11.5919 | Learning rate : 7.41e-05
Batch : 11 / 196 | Time 267 ms | Train Loss : 4.4698 | Grad Norm : 13.1049 | Learning rate : 7.41e-05
Batch : 12 / 196 | Time 264 ms | Train Loss : 4.5042 | Grad Norm : 11.6444 | Learning rate : 7.40e-05
Batch : 13 / 196 | Time 268 ms | Train Loss : 4.5634 | Grad Norm : 15.4705 | Learning rate : 7.39e-05
Batch : 14 / 196 | Time 269 ms | Train Loss : 4.4851 | Grad Norm : 14.5630 | Learning rate : 7.38e-05
Batch : 15 / 196 | Time 266 ms | Train Loss : 4.5603 | Grad Norm : 9.9521 | Learning rate : 7.38e-05
Batch : 16 / 196 | Time 268 ms | Train Loss : 4.5183 | Grad Norm : 11.0358 | Learning rate : 7.37e-05
Batch : 17 / 196 | Time 269 ms | Train Loss : 4.5079 | Grad Norm : 12.1624 | Learning rate : 7.36e-05
Batch : 18 / 196 | Time 268 ms | Train Loss : 4.4968 | Grad Norm : 9.0468 | Learning rate : 7.35e-05
Batch : 19 / 196 | Time 267 ms | Train Loss : 4.3810 | Grad Norm : 12.5037 | Learning rate : 7.34e-05
Batch : 20 / 196 | Time 275 ms | Train Loss : 4.6887 | Grad Norm : 8.8242 | Learning rate : 7.34e-05
Batch : 21 / 196 | Time 273 ms | Train Loss : 4.5983 | Grad Norm : 8.3843 | Learning rate : 7.33e-05
Batch : 22 / 196 | Time 267 ms | Train Loss : 4.4796 | Grad Norm : 12.2361 | Learning rate : 7.32e-05
Batch : 23 / 196 | Time 265 ms | Train Loss : 4.4809 | Grad Norm : 8.0353 | Learning rate : 7.31e-05
Batch : 24 / 196 | Time 264 ms | Train Loss : 4.4454 | Grad Norm : 8.7535 | Learning rate : 7.30e-05
Batch : 25 / 196 | Time 265 ms | Train Loss : 4.5258 | Grad Norm : 10.9584 | Learning rate : 7.30e-05
Batch : 26 / 196 | Time 266 ms | Train Loss : 4.5656 | Grad Norm : 15.2204 | Learning rate : 7.29e-05
Batch : 27 / 196 | Time 266 ms | Train Loss : 4.4525 | Grad Norm : 13.5788 | Learning rate : 7.28e-05
Batch : 28 / 196 | Time 267 ms | Train Loss : 4.5758 | Grad Norm : 10.6560 | Learning rate : 7.27e-05
Batch : 29 / 196 | Time 268 ms | Train Loss : 4.4740 | Grad Norm : 11.7575 | Learning rate : 7.27e-05
Batch : 30 / 196 | Time 266 ms | Train Loss : 4.5895 | Grad Norm : 12.4606 | Learning rate : 7.26e-05
Batch : 31 / 196 | Time 268 ms | Train Loss : 4.4518 | Grad Norm : 9.6741 | Learning rate : 7.25e-05
Batch : 32 / 196 | Time 264 ms | Train Loss : 4.5465 | Grad Norm : 13.3741 | Learning rate : 7.24e-05
Batch : 33 / 196 | Time 264 ms | Train Loss : 4.5420 | Grad Norm : 14.4656 | Learning rate : 7.23e-05
Batch : 34 / 196 | Time 265 ms | Train Loss : 4.3813 | Grad Norm : 12.3650 | Learning rate : 7.23e-05
Batch : 35 / 196 | Time 267 ms | Train Loss : 4.4270 | Grad Norm : 11.2494 | Learning rate : 7.22e-05
Batch : 36 / 196 | Time 267 ms | Train Loss : 4.4659 | Grad Norm : 11.3661 | Learning rate : 7.21e-05
Batch : 37 / 196 | Time 266 ms | Train Loss : 4.5189 | Grad Norm : 16.9017 | Learning rate : 7.20e-05
Batch : 38 / 196 | Time 271 ms | Train Loss : 4.5556 | Grad Norm : 13.2579 | Learning rate : 7.19e-05
Batch : 39 / 196 | Time 267 ms | Train Loss : 4.3977 | Grad Norm : 13.4301 | Learning rate : 7.19e-05
Batch : 40 / 196 | Time 265 ms | Train Loss : 4.4225 | Grad Norm : 14.2604 | Learning rate : 7.18e-05
Batch : 41 / 196 | Time 266 ms | Train Loss : 4.4970 | Grad Norm : 13.1666 | Learning rate : 7.17e-05
Batch : 42 / 196 | Time 267 ms | Train Loss : 4.5487 | Grad Norm : 15.9106 | Learning rate : 7.16e-05
Batch : 43 / 196 | Time 267 ms | Train Loss : 4.4383 | Grad Norm : 12.8394 | Learning rate : 7.15e-05
Batch : 44 / 196 | Time 264 ms | Train Loss : 4.4726 | Grad Norm : 10.5376 | Learning rate : 7.15e-05
Batch : 45 / 196 | Time 276 ms | Train Loss : 4.5542 | Grad Norm : 20.2678 | Learning rate : 7.14e-05
Batch : 46 / 196 | Time 264 ms | Train Loss : 4.5370 | Grad Norm : 16.4807 | Learning rate : 7.13e-05
Batch : 47 / 196 | Time 266 ms | Train Loss : 4.4907 | Grad Norm : 11.7238 | Learning rate : 7.12e-05
Batch : 48 / 196 | Time 266 ms | Train Loss : 4.5157 | Grad Norm : 17.6962 | Learning rate : 7.11e-05
Batch : 49 / 196 | Time 264 ms | Train Loss : 4.5936 | Grad Norm : 22.8400 | Learning rate : 7.11e-05
Batch : 50 / 196 | Time 270 ms | Train Loss : 4.4578 | Grad Norm : 10.9143 | Learning rate : 7.10e-05
Batch : 51 / 196 | Time 265 ms | Train Loss : 4.4889 | Grad Norm : 14.5383 | Learning rate : 7.09e-05
Batch : 52 / 196 | Time 265 ms | Train Loss : 4.5707 | Grad Norm : 16.6047 | Learning rate : 7.08e-05
Batch : 53 / 196 | Time 266 ms | Train Loss : 4.4587 | Grad Norm : 13.9917 | Learning rate : 7.07e-05
Batch : 54 / 196 | Time 269 ms | Train Loss : 4.5038 | Grad Norm : 10.1850 | Learning rate : 7.06e-05
Batch : 55 / 196 | Time 265 ms | Train Loss : 4.4626 | Grad Norm : 19.6256 | Learning rate : 7.06e-05
Batch : 56 / 196 | Time 268 ms | Train Loss : 4.4170 | Grad Norm : 10.0799 | Learning rate : 7.05e-05
Batch : 57 / 196 | Time 266 ms | Train Loss : 4.4199 | Grad Norm : 14.7030 | Learning rate : 7.04e-05
Batch : 58 / 196 | Time 270 ms | Train Loss : 4.4175 | Grad Norm : 14.5973 | Learning rate : 7.03e-05
Batch : 59 / 196 | Time 266 ms | Train Loss : 4.4146 | Grad Norm : 11.0843 | Learning rate : 7.02e-05
Batch : 60 / 196 | Time 266 ms | Train Loss : 4.5759 | Grad Norm : 25.5144 | Learning rate : 7.02e-05
Batch : 61 / 196 | Time 272 ms | Train Loss : 4.5669 | Grad Norm : 24.8556 | Learning rate : 7.01e-05
Batch : 62 / 196 | Time 274 ms | Train Loss : 4.5884 | Grad Norm : 18.5752 | Learning rate : 7.00e-05
Batch : 63 / 196 | Time 278 ms | Train Loss : 4.4765 | Grad Norm : 9.6697 | Learning rate : 6.99e-05
Batch : 64 / 196 | Time 266 ms | Train Loss : 4.5047 | Grad Norm : 17.5209 | Learning rate : 6.98e-05
Batch : 65 / 196 | Time 272 ms | Train Loss : 4.5131 | Grad Norm : 19.4449 | Learning rate : 6.97e-05
Batch : 66 / 196 | Time 274 ms | Train Loss : 4.4667 | Grad Norm : 12.0690 | Learning rate : 6.97e-05
Batch : 67 / 196 | Time 267 ms | Train Loss : 4.4541 | Grad Norm : 10.1488 | Learning rate : 6.96e-05
Batch : 68 / 196 | Time 266 ms | Train Loss : 4.4463 | Grad Norm : 12.0770 | Learning rate : 6.95e-05
Batch : 69 / 196 | Time 269 ms | Train Loss : 4.4772 | Grad Norm : 10.4891 | Learning rate : 6.94e-05
Batch : 70 / 196 | Time 263 ms | Train Loss : 4.4771 | Grad Norm : 14.2380 | Learning rate : 6.93e-05
Batch : 71 / 196 | Time 270 ms | Train Loss : 4.4554 | Grad Norm : 10.0862 | Learning rate : 6.93e-05
Batch : 72 / 196 | Time 266 ms | Train Loss : 4.5012 | Grad Norm : 11.4844 | Learning rate : 6.92e-05
Batch : 73 / 196 | Time 267 ms | Train Loss : 4.4050 | Grad Norm : 19.5714 | Learning rate : 6.91e-05
Batch : 74 / 196 | Time 264 ms | Train Loss : 4.4132 | Grad Norm : 15.7015 | Learning rate : 6.90e-05
Batch : 75 / 196 | Time 266 ms | Train Loss : 4.4271 | Grad Norm : 13.8587 | Learning rate : 6.89e-05
Batch : 76 / 196 | Time 267 ms | Train Loss : 4.5466 | Grad Norm : 14.1390 | Learning rate : 6.88e-05
Batch : 77 / 196 | Time 266 ms | Train Loss : 4.5861 | Grad Norm : 17.7344 | Learning rate : 6.88e-05
Batch : 78 / 196 | Time 271 ms | Train Loss : 4.4862 | Grad Norm : 18.3172 | Learning rate : 6.87e-05
Batch : 79 / 196 | Time 268 ms | Train Loss : 4.5073 | Grad Norm : 18.6875 | Learning rate : 6.86e-05
Batch : 80 / 196 | Time 265 ms | Train Loss : 4.4936 | Grad Norm : 11.3766 | Learning rate : 6.85e-05
Batch : 81 / 196 | Time 264 ms | Train Loss : 4.5084 | Grad Norm : 12.6153 | Learning rate : 6.84e-05
Batch : 82 / 196 | Time 266 ms | Train Loss : 4.3716 | Grad Norm : 14.0085 | Learning rate : 6.83e-05
Batch : 83 / 196 | Time 273 ms | Train Loss : 4.6097 | Grad Norm : 13.9503 | Learning rate : 6.83e-05
Batch : 84 / 196 | Time 265 ms | Train Loss : 4.4240 | Grad Norm : 10.7035 | Learning rate : 6.82e-05
Batch : 85 / 196 | Time 271 ms | Train Loss : 4.5562 | Grad Norm : 11.4062 | Learning rate : 6.81e-05
Batch : 86 / 196 | Time 268 ms | Train Loss : 4.4280 | Grad Norm : 9.4506 | Learning rate : 6.80e-05
Batch : 87 / 196 | Time 264 ms | Train Loss : 4.5078 | Grad Norm : 10.9052 | Learning rate : 6.79e-05
Batch : 88 / 196 | Time 269 ms | Train Loss : 4.4350 | Grad Norm : 12.7497 | Learning rate : 6.79e-05
Batch : 89 / 196 | Time 268 ms | Train Loss : 4.4045 | Grad Norm : 11.5871 | Learning rate : 6.78e-05
Batch : 90 / 196 | Time 266 ms | Train Loss : 4.5606 | Grad Norm : 15.6509 | Learning rate : 6.77e-05
Batch : 91 / 196 | Time 264 ms | Train Loss : 4.4850 | Grad Norm : 12.9074 | Learning rate : 6.76e-05
Batch : 92 / 196 | Time 264 ms | Train Loss : 4.5538 | Grad Norm : 9.6048 | Learning rate : 6.75e-05
Batch : 93 / 196 | Time 268 ms | Train Loss : 4.4695 | Grad Norm : 15.4119 | Learning rate : 6.74e-05
Batch : 94 / 196 | Time 267 ms | Train Loss : 4.4387 | Grad Norm : 9.2374 | Learning rate : 6.74e-05
Batch : 95 / 196 | Time 265 ms | Train Loss : 4.5939 | Grad Norm : 11.6051 | Learning rate : 6.73e-05
Batch : 96 / 196 | Time 265 ms | Train Loss : 4.4439 | Grad Norm : 8.4916 | Learning rate : 6.72e-05
Batch : 97 / 196 | Time 264 ms | Train Loss : 4.4473 | Grad Norm : 12.5781 | Learning rate : 6.71e-05
Batch : 98 / 196 | Time 263 ms | Train Loss : 4.4456 | Grad Norm : 18.6777 | Learning rate : 6.70e-05
Batch : 99 / 196 | Time 264 ms | Train Loss : 4.5483 | Grad Norm : 19.8316 | Learning rate : 6.69e-05
Batch : 100 / 196 | Time 264 ms | Train Loss : 4.5295 | Grad Norm : 12.9479 | Learning rate : 6.68e-05
Batch : 101 / 196 | Time 268 ms | Train Loss : 4.4802 | Grad Norm : 23.1233 | Learning rate : 6.68e-05
Batch : 102 / 196 | Time 262 ms | Train Loss : 4.5603 | Grad Norm : 18.9059 | Learning rate : 6.67e-05
Batch : 103 / 196 | Time 273 ms | Train Loss : 4.5579 | Grad Norm : 9.3817 | Learning rate : 6.66e-05
Batch : 104 / 196 | Time 268 ms | Train Loss : 4.4668 | Grad Norm : 12.7589 | Learning rate : 6.65e-05
Batch : 105 / 196 | Time 264 ms | Train Loss : 4.4653 | Grad Norm : 13.9480 | Learning rate : 6.64e-05
Batch : 106 / 196 | Time 266 ms | Train Loss : 4.4270 | Grad Norm : 12.1443 | Learning rate : 6.63e-05
Batch : 107 / 196 | Time 266 ms | Train Loss : 4.5031 | Grad Norm : 15.6024 | Learning rate : 6.63e-05
Batch : 108 / 196 | Time 269 ms | Train Loss : 4.5250 | Grad Norm : 16.3403 | Learning rate : 6.62e-05
Batch : 109 / 196 | Time 266 ms | Train Loss : 4.3846 | Grad Norm : 13.7153 | Learning rate : 6.61e-05
Batch : 110 / 196 | Time 270 ms | Train Loss : 4.4893 | Grad Norm : 14.4032 | Learning rate : 6.60e-05
Batch : 111 / 196 | Time 272 ms | Train Loss : 4.5264 | Grad Norm : 15.7941 | Learning rate : 6.59e-05
Batch : 112 / 196 | Time 264 ms | Train Loss : 4.5944 | Grad Norm : 20.7172 | Learning rate : 6.58e-05
Batch : 113 / 196 | Time 272 ms | Train Loss : 4.5259 | Grad Norm : 14.7032 | Learning rate : 6.58e-05
Batch : 114 / 196 | Time 273 ms | Train Loss : 4.3893 | Grad Norm : 14.4914 | Learning rate : 6.57e-05
Batch : 115 / 196 | Time 264 ms | Train Loss : 4.4657 | Grad Norm : 12.5818 | Learning rate : 6.56e-05
Batch : 116 / 196 | Time 268 ms | Train Loss : 4.3773 | Grad Norm : 14.2804 | Learning rate : 6.55e-05
Batch : 117 / 196 | Time 264 ms | Train Loss : 4.5428 | Grad Norm : 11.4178 | Learning rate : 6.54e-05
Batch : 118 / 196 | Time 265 ms | Train Loss : 4.4393 | Grad Norm : 11.7344 | Learning rate : 6.53e-05
Batch : 119 / 196 | Time 263 ms | Train Loss : 4.4816 | Grad Norm : 13.8927 | Learning rate : 6.52e-05
Batch : 120 / 196 | Time 265 ms | Train Loss : 4.5433 | Grad Norm : 18.1260 | Learning rate : 6.52e-05
Batch : 121 / 196 | Time 267 ms | Train Loss : 4.3790 | Grad Norm : 17.1298 | Learning rate : 6.51e-05
Batch : 122 / 196 | Time 269 ms | Train Loss : 4.3628 | Grad Norm : 9.1849 | Learning rate : 6.50e-05
Batch : 123 / 196 | Time 265 ms | Train Loss : 4.4973 | Grad Norm : 12.9744 | Learning rate : 6.49e-05
Batch : 124 / 196 | Time 263 ms | Train Loss : 4.5511 | Grad Norm : 12.5952 | Learning rate : 6.48e-05
Batch : 125 / 196 | Time 265 ms | Train Loss : 4.5416 | Grad Norm : 11.7370 | Learning rate : 6.47e-05
Batch : 126 / 196 | Time 269 ms | Train Loss : 4.4920 | Grad Norm : 12.7396 | Learning rate : 6.47e-05
Batch : 127 / 196 | Time 266 ms | Train Loss : 4.4331 | Grad Norm : 10.1991 | Learning rate : 6.46e-05
Batch : 128 / 196 | Time 272 ms | Train Loss : 4.3862 | Grad Norm : 13.8065 | Learning rate : 6.45e-05
Batch : 129 / 196 | Time 266 ms | Train Loss : 4.4087 | Grad Norm : 15.4058 | Learning rate : 6.44e-05
Batch : 130 / 196 | Time 272 ms | Train Loss : 4.3619 | Grad Norm : 10.1229 | Learning rate : 6.43e-05
Batch : 131 / 196 | Time 267 ms | Train Loss : 4.4821 | Grad Norm : 11.9757 | Learning rate : 6.42e-05
Batch : 132 / 196 | Time 265 ms | Train Loss : 4.4800 | Grad Norm : 21.2824 | Learning rate : 6.41e-05
Batch : 133 / 196 | Time 266 ms | Train Loss : 4.5584 | Grad Norm : 19.0225 | Learning rate : 6.41e-05
Batch : 134 / 196 | Time 268 ms | Train Loss : 4.4831 | Grad Norm : 23.7108 | Learning rate : 6.40e-05
Batch : 135 / 196 | Time 264 ms | Train Loss : 4.3393 | Grad Norm : 18.0272 | Learning rate : 6.39e-05
Batch : 136 / 196 | Time 270 ms | Train Loss : 4.4707 | Grad Norm : 9.5838 | Learning rate : 6.38e-05
Batch : 137 / 196 | Time 271 ms | Train Loss : 4.4878 | Grad Norm : 9.9117 | Learning rate : 6.37e-05
Batch : 138 / 196 | Time 266 ms | Train Loss : 4.5459 | Grad Norm : 21.3586 | Learning rate : 6.36e-05
Batch : 139 / 196 | Time 264 ms | Train Loss : 4.4305 | Grad Norm : 17.4031 | Learning rate : 6.35e-05
Batch : 140 / 196 | Time 266 ms | Train Loss : 4.4699 | Grad Norm : 14.9536 | Learning rate : 6.35e-05
Batch : 141 / 196 | Time 265 ms | Train Loss : 4.3807 | Grad Norm : 13.8790 | Learning rate : 6.34e-05
Batch : 142 / 196 | Time 263 ms | Train Loss : 4.4398 | Grad Norm : 14.1703 | Learning rate : 6.33e-05
Batch : 143 / 196 | Time 270 ms | Train Loss : 4.3453 | Grad Norm : 12.1245 | Learning rate : 6.32e-05
Batch : 144 / 196 | Time 269 ms | Train Loss : 4.3253 | Grad Norm : 23.7705 | Learning rate : 6.31e-05
Batch : 145 / 196 | Time 269 ms | Train Loss : 4.5395 | Grad Norm : 14.9992 | Learning rate : 6.30e-05
Batch : 146 / 196 | Time 265 ms | Train Loss : 4.4225 | Grad Norm : 21.9308 | Learning rate : 6.29e-05
Batch : 147 / 196 | Time 265 ms | Train Loss : 4.4925 | Grad Norm : 24.5776 | Learning rate : 6.29e-05
Batch : 148 / 196 | Time 272 ms | Train Loss : 4.4864 | Grad Norm : 12.8127 | Learning rate : 6.28e-05
Batch : 149 / 196 | Time 268 ms | Train Loss : 4.4764 | Grad Norm : 18.7904 | Learning rate : 6.27e-05
Batch : 150 / 196 | Time 264 ms | Train Loss : 4.5052 | Grad Norm : 17.0458 | Learning rate : 6.26e-05
Batch : 151 / 196 | Time 273 ms | Train Loss : 4.4803 | Grad Norm : 19.8222 | Learning rate : 6.25e-05
Batch : 152 / 196 | Time 265 ms | Train Loss : 4.5294 | Grad Norm : 14.1309 | Learning rate : 6.24e-05
Batch : 153 / 196 | Time 260 ms | Train Loss : 4.5010 | Grad Norm : 12.6851 | Learning rate : 6.23e-05
Batch : 154 / 196 | Time 266 ms | Train Loss : 4.4699 | Grad Norm : 20.0272 | Learning rate : 6.23e-05
Batch : 155 / 196 | Time 266 ms | Train Loss : 4.4871 | Grad Norm : 11.9057 | Learning rate : 6.22e-05
Batch : 156 / 196 | Time 264 ms | Train Loss : 4.4136 | Grad Norm : 10.6381 | Learning rate : 6.21e-05
Batch : 157 / 196 | Time 265 ms | Train Loss : 4.4600 | Grad Norm : 15.2933 | Learning rate : 6.20e-05
Batch : 158 / 196 | Time 263 ms | Train Loss : 4.4423 | Grad Norm : 12.1897 | Learning rate : 6.19e-05
Batch : 159 / 196 | Time 264 ms | Train Loss : 4.4883 | Grad Norm : 15.6528 | Learning rate : 6.18e-05
Batch : 160 / 196 | Time 266 ms | Train Loss : 4.4610 | Grad Norm : 21.1747 | Learning rate : 6.17e-05
Batch : 161 / 196 | Time 268 ms | Train Loss : 4.5328 | Grad Norm : 16.8459 | Learning rate : 6.16e-05
Batch : 162 / 196 | Time 269 ms | Train Loss : 4.4197 | Grad Norm : 14.0553 | Learning rate : 6.16e-05
Batch : 163 / 196 | Time 264 ms | Train Loss : 4.4261 | Grad Norm : 13.1016 | Learning rate : 6.15e-05
Batch : 164 / 196 | Time 267 ms | Train Loss : 4.3559 | Grad Norm : 8.8246 | Learning rate : 6.14e-05
Batch : 165 / 196 | Time 266 ms | Train Loss : 4.4148 | Grad Norm : 20.5676 | Learning rate : 6.13e-05
Batch : 166 / 196 | Time 269 ms | Train Loss : 4.5015 | Grad Norm : 22.1579 | Learning rate : 6.12e-05
Batch : 167 / 196 | Time 266 ms | Train Loss : 4.4870 | Grad Norm : 7.4629 | Learning rate : 6.11e-05
Batch : 168 / 196 | Time 265 ms | Train Loss : 4.4455 | Grad Norm : 13.3922 | Learning rate : 6.10e-05
Batch : 169 / 196 | Time 273 ms | Train Loss : 4.4596 | Grad Norm : 22.7969 | Learning rate : 6.10e-05
Batch : 170 / 196 | Time 272 ms | Train Loss : 4.4832 | Grad Norm : 17.2686 | Learning rate : 6.09e-05
Batch : 171 / 196 | Time 265 ms | Train Loss : 4.4295 | Grad Norm : 9.5527 | Learning rate : 6.08e-05
Batch : 172 / 196 | Time 264 ms | Train Loss : 4.3768 | Grad Norm : 15.0797 | Learning rate : 6.07e-05
Batch : 173 / 196 | Time 263 ms | Train Loss : 4.4386 | Grad Norm : 11.8032 | Learning rate : 6.06e-05
Batch : 174 / 196 | Time 270 ms | Train Loss : 4.3536 | Grad Norm : 11.5344 | Learning rate : 6.05e-05
Batch : 175 / 196 | Time 265 ms | Train Loss : 4.3640 | Grad Norm : 13.7233 | Learning rate : 6.04e-05
Batch : 176 / 196 | Time 267 ms | Train Loss : 4.3517 | Grad Norm : 15.0191 | Learning rate : 6.03e-05
Batch : 177 / 196 | Time 264 ms | Train Loss : 4.4014 | Grad Norm : 12.8858 | Learning rate : 6.03e-05
Batch : 178 / 196 | Time 265 ms | Train Loss : 4.4593 | Grad Norm : 14.7424 | Learning rate : 6.02e-05
Batch : 179 / 196 | Time 259 ms | Train Loss : 4.6248 | Grad Norm : 12.2913 | Learning rate : 6.01e-05
Batch : 180 / 196 | Time 266 ms | Train Loss : 4.4287 | Grad Norm : 17.7272 | Learning rate : 6.00e-05
Batch : 181 / 196 | Time 267 ms | Train Loss : 4.3834 | Grad Norm : 15.8973 | Learning rate : 5.99e-05
Batch : 182 / 196 | Time 270 ms | Train Loss : 4.4830 | Grad Norm : 9.5707 | Learning rate : 5.98e-05
Batch : 183 / 196 | Time 273 ms | Train Loss : 4.4723 | Grad Norm : 14.1799 | Learning rate : 5.97e-05
Batch : 184 / 196 | Time 267 ms | Train Loss : 4.4943 | Grad Norm : 16.2586 | Learning rate : 5.96e-05
Batch : 185 / 196 | Time 267 ms | Train Loss : 4.4096 | Grad Norm : 13.4705 | Learning rate : 5.96e-05
Batch : 186 / 196 | Time 264 ms | Train Loss : 4.4269 | Grad Norm : 13.0018 | Learning rate : 5.95e-05
Batch : 187 / 196 | Time 260 ms | Train Loss : 4.5466 | Grad Norm : 12.5529 | Learning rate : 5.94e-05
Batch : 188 / 196 | Time 265 ms | Train Loss : 4.4852 | Grad Norm : 10.7675 | Learning rate : 5.93e-05
Batch : 189 / 196 | Time 269 ms | Train Loss : 4.4205 | Grad Norm : 22.4579 | Learning rate : 5.92e-05
Batch : 190 / 196 | Time 262 ms | Train Loss : 4.4963 | Grad Norm : 15.0868 | Learning rate : 5.91e-05
Batch : 191 / 196 | Time 263 ms | Train Loss : 4.5219 | Grad Norm : 12.7438 | Learning rate : 5.90e-05
Batch : 192 / 196 | Time 266 ms | Train Loss : 4.5388 | Grad Norm : 20.4286 | Learning rate : 5.89e-05
Batch : 193 / 196 | Time 271 ms | Train Loss : 4.4539 | Grad Norm : 13.7209 | Learning rate : 5.89e-05
Batch : 194 / 196 | Time 272 ms | Train Loss : 4.4434 | Grad Norm : 14.2455 | Learning rate : 5.88e-05
Batch : 195 / 196 | Time 109 ms | Train Loss : 3.4492 | Grad Norm : 20.1468 | Learning rate : 5.87e-05
Epoch : 4 | Training Loss : 3.4492| Accuracy on test set : 0.4759
 Batch : 0 / 196 | Time 272 ms | Train Loss : 4.5266 | Grad Norm : 23.8745 | Learning rate : 5.86e-05
Batch : 1 / 196 | Time 270 ms | Train Loss : 4.6118 | Grad Norm : 24.9140 | Learning rate : 5.85e-05
Batch : 2 / 196 | Time 266 ms | Train Loss : 4.3940 | Grad Norm : 14.5647 | Learning rate : 5.84e-05
Batch : 3 / 196 | Time 267 ms | Train Loss : 4.4560 | Grad Norm : 14.0893 | Learning rate : 5.83e-05
Batch : 4 / 196 | Time 268 ms | Train Loss : 4.3965 | Grad Norm : 19.0131 | Learning rate : 5.82e-05
Batch : 5 / 196 | Time 271 ms | Train Loss : 4.3655 | Grad Norm : 13.4384 | Learning rate : 5.82e-05
Batch : 6 / 196 | Time 265 ms | Train Loss : 4.4106 | Grad Norm : 13.0425 | Learning rate : 5.81e-05
Batch : 7 / 196 | Time 265 ms | Train Loss : 4.3569 | Grad Norm : 14.9572 | Learning rate : 5.80e-05
Batch : 8 / 196 | Time 264 ms | Train Loss : 4.4653 | Grad Norm : 15.6255 | Learning rate : 5.79e-05
Batch : 9 / 196 | Time 263 ms | Train Loss : 4.2913 | Grad Norm : 16.4062 | Learning rate : 5.78e-05
Batch : 10 / 196 | Time 268 ms | Train Loss : 4.3509 | Grad Norm : 14.1215 | Learning rate : 5.77e-05
Batch : 11 / 196 | Time 266 ms | Train Loss : 4.4011 | Grad Norm : 19.5652 | Learning rate : 5.76e-05
Batch : 12 / 196 | Time 271 ms | Train Loss : 4.4865 | Grad Norm : 14.1821 | Learning rate : 5.75e-05
Batch : 13 / 196 | Time 265 ms | Train Loss : 4.4309 | Grad Norm : 10.3579 | Learning rate : 5.75e-05
Batch : 14 / 196 | Time 267 ms | Train Loss : 4.4762 | Grad Norm : 20.8412 | Learning rate : 5.74e-05
Batch : 15 / 196 | Time 264 ms | Train Loss : 4.4241 | Grad Norm : 19.7421 | Learning rate : 5.73e-05
Batch : 16 / 196 | Time 264 ms | Train Loss : 4.4913 | Grad Norm : 12.5135 | Learning rate : 5.72e-05
Batch : 17 / 196 | Time 272 ms | Train Loss : 4.3455 | Grad Norm : 13.3228 | Learning rate : 5.71e-05
Batch : 18 / 196 | Time 267 ms | Train Loss : 4.3829 | Grad Norm : 11.0356 | Learning rate : 5.70e-05
Batch : 19 / 196 | Time 271 ms | Train Loss : 4.2704 | Grad Norm : 11.4016 | Learning rate : 5.69e-05
Batch : 20 / 196 | Time 274 ms | Train Loss : 4.4590 | Grad Norm : 13.7580 | Learning rate : 5.68e-05
Batch : 21 / 196 | Time 263 ms | Train Loss : 4.4071 | Grad Norm : 17.3333 | Learning rate : 5.67e-05
Batch : 22 / 196 | Time 264 ms | Train Loss : 4.4167 | Grad Norm : 19.1824 | Learning rate : 5.67e-05
Batch : 23 / 196 | Time 264 ms | Train Loss : 4.3339 | Grad Norm : 9.9403 | Learning rate : 5.66e-05
Batch : 24 / 196 | Time 264 ms | Train Loss : 4.2737 | Grad Norm : 18.1468 | Learning rate : 5.65e-05
Batch : 25 / 196 | Time 267 ms | Train Loss : 4.4311 | Grad Norm : 11.2798 | Learning rate : 5.64e-05
Batch : 26 / 196 | Time 274 ms | Train Loss : 4.5122 | Grad Norm : 15.3664 | Learning rate : 5.63e-05
Batch : 27 / 196 | Time 276 ms | Train Loss : 4.4205 | Grad Norm : 14.8949 | Learning rate : 5.62e-05
Batch : 28 / 196 | Time 267 ms | Train Loss : 4.4212 | Grad Norm : 14.5627 | Learning rate : 5.61e-05
Batch : 29 / 196 | Time 265 ms | Train Loss : 4.3784 | Grad Norm : 11.6196 | Learning rate : 5.60e-05
Batch : 30 / 196 | Time 264 ms | Train Loss : 4.4521 | Grad Norm : 20.9216 | Learning rate : 5.60e-05
Batch : 31 / 196 | Time 264 ms | Train Loss : 4.5427 | Grad Norm : 13.9445 | Learning rate : 5.59e-05
Batch : 32 / 196 | Time 272 ms | Train Loss : 4.4604 | Grad Norm : 10.6387 | Learning rate : 5.58e-05
Batch : 33 / 196 | Time 267 ms | Train Loss : 4.5305 | Grad Norm : 12.6985 | Learning rate : 5.57e-05
Batch : 34 / 196 | Time 263 ms | Train Loss : 4.3890 | Grad Norm : 14.1963 | Learning rate : 5.56e-05
Batch : 35 / 196 | Time 265 ms | Train Loss : 4.4715 | Grad Norm : 16.4125 | Learning rate : 5.55e-05
Batch : 36 / 196 | Time 259 ms | Train Loss : 4.3983 | Grad Norm : 14.4280 | Learning rate : 5.54e-05
Batch : 37 / 196 | Time 263 ms | Train Loss : 4.3170 | Grad Norm : 9.3337 | Learning rate : 5.53e-05
Batch : 38 / 196 | Time 264 ms | Train Loss : 4.3986 | Grad Norm : 13.3731 | Learning rate : 5.52e-05
Batch : 39 / 196 | Time 268 ms | Train Loss : 4.3796 | Grad Norm : 12.6217 | Learning rate : 5.52e-05
Batch : 40 / 196 | Time 264 ms | Train Loss : 4.3335 | Grad Norm : 9.3819 | Learning rate : 5.51e-05
Batch : 41 / 196 | Time 267 ms | Train Loss : 4.4611 | Grad Norm : 10.8153 | Learning rate : 5.50e-05
Batch : 42 / 196 | Time 264 ms | Train Loss : 4.3650 | Grad Norm : 12.8873 | Learning rate : 5.49e-05
Batch : 43 / 196 | Time 267 ms | Train Loss : 4.4061 | Grad Norm : 13.5419 | Learning rate : 5.48e-05
Batch : 44 / 196 | Time 262 ms | Train Loss : 4.3659 | Grad Norm : 14.7968 | Learning rate : 5.47e-05
Batch : 45 / 196 | Time 264 ms | Train Loss : 4.3219 | Grad Norm : 20.6240 | Learning rate : 5.46e-05
Batch : 46 / 196 | Time 263 ms | Train Loss : 4.5540 | Grad Norm : 18.2608 | Learning rate : 5.45e-05
Batch : 47 / 196 | Time 266 ms | Train Loss : 4.3957 | Grad Norm : 23.9251 | Learning rate : 5.44e-05
Batch : 48 / 196 | Time 266 ms | Train Loss : 4.4197 | Grad Norm : 13.3606 | Learning rate : 5.44e-05
Batch : 49 / 196 | Time 264 ms | Train Loss : 4.3829 | Grad Norm : 17.6693 | Learning rate : 5.43e-05
Batch : 50 / 196 | Time 264 ms | Train Loss : 4.3332 | Grad Norm : 14.0878 | Learning rate : 5.42e-05
Batch : 51 / 196 | Time 264 ms | Train Loss : 4.3969 | Grad Norm : 21.1218 | Learning rate : 5.41e-05
Batch : 52 / 196 | Time 269 ms | Train Loss : 4.4597 | Grad Norm : 17.4000 | Learning rate : 5.40e-05
Batch : 53 / 196 | Time 273 ms | Train Loss : 4.4757 | Grad Norm : 15.4797 | Learning rate : 5.39e-05
Batch : 54 / 196 | Time 264 ms | Train Loss : 4.4149 | Grad Norm : 17.8988 | Learning rate : 5.38e-05
Batch : 55 / 196 | Time 264 ms | Train Loss : 4.4377 | Grad Norm : 17.6944 | Learning rate : 5.37e-05
Batch : 56 / 196 | Time 267 ms | Train Loss : 4.4609 | Grad Norm : 14.5444 | Learning rate : 5.36e-05
Batch : 57 / 196 | Time 266 ms | Train Loss : 4.4395 | Grad Norm : 18.7323 | Learning rate : 5.36e-05
Batch : 58 / 196 | Time 266 ms | Train Loss : 4.4073 | Grad Norm : 10.1677 | Learning rate : 5.35e-05
Batch : 59 / 196 | Time 266 ms | Train Loss : 4.3126 | Grad Norm : 12.8748 | Learning rate : 5.34e-05
Batch : 60 / 196 | Time 265 ms | Train Loss : 4.4126 | Grad Norm : 10.1427 | Learning rate : 5.33e-05
Batch : 61 / 196 | Time 264 ms | Train Loss : 4.3788 | Grad Norm : 12.4729 | Learning rate : 5.32e-05
Batch : 62 / 196 | Time 266 ms | Train Loss : 4.3922 | Grad Norm : 13.5607 | Learning rate : 5.31e-05
Batch : 63 / 196 | Time 267 ms | Train Loss : 4.2799 | Grad Norm : 16.9255 | Learning rate : 5.30e-05
Batch : 64 / 196 | Time 266 ms | Train Loss : 4.4457 | Grad Norm : 13.3047 | Learning rate : 5.29e-05
Batch : 65 / 196 | Time 268 ms | Train Loss : 4.3999 | Grad Norm : 12.0073 | Learning rate : 5.28e-05
Batch : 66 / 196 | Time 270 ms | Train Loss : 4.3685 | Grad Norm : 11.1994 | Learning rate : 5.28e-05
Batch : 67 / 196 | Time 267 ms | Train Loss : 4.4644 | Grad Norm : 12.7431 | Learning rate : 5.27e-05
Batch : 68 / 196 | Time 266 ms | Train Loss : 4.3509 | Grad Norm : 14.3672 | Learning rate : 5.26e-05
Batch : 69 / 196 | Time 269 ms | Train Loss : 4.4723 | Grad Norm : 14.1396 | Learning rate : 5.25e-05
Batch : 70 / 196 | Time 266 ms | Train Loss : 4.3810 | Grad Norm : 10.2476 | Learning rate : 5.24e-05
Batch : 71 / 196 | Time 271 ms | Train Loss : 4.4027 | Grad Norm : 14.8111 | Learning rate : 5.23e-05
Batch : 72 / 196 | Time 267 ms | Train Loss : 4.4685 | Grad Norm : 7.5412 | Learning rate : 5.22e-05
Batch : 73 / 196 | Time 269 ms | Train Loss : 4.3456 | Grad Norm : 10.8539 | Learning rate : 5.21e-05
Batch : 74 / 196 | Time 259 ms | Train Loss : 4.4351 | Grad Norm : 13.8287 | Learning rate : 5.20e-05
Batch : 75 / 196 | Time 268 ms | Train Loss : 4.3595 | Grad Norm : 12.4970 | Learning rate : 5.20e-05
Batch : 76 / 196 | Time 273 ms | Train Loss : 4.3394 | Grad Norm : 10.8910 | Learning rate : 5.19e-05
Batch : 77 / 196 | Time 264 ms | Train Loss : 4.2776 | Grad Norm : 15.6732 | Learning rate : 5.18e-05
Batch : 78 / 196 | Time 265 ms | Train Loss : 4.4362 | Grad Norm : 12.3288 | Learning rate : 5.17e-05
Batch : 79 / 196 | Time 262 ms | Train Loss : 4.4893 | Grad Norm : 12.7734 | Learning rate : 5.16e-05
Batch : 80 / 196 | Time 263 ms | Train Loss : 4.3880 | Grad Norm : 9.8541 | Learning rate : 5.15e-05
Batch : 81 / 196 | Time 261 ms | Train Loss : 4.4112 | Grad Norm : 11.9221 | Learning rate : 5.14e-05
Batch : 82 / 196 | Time 272 ms | Train Loss : 4.3103 | Grad Norm : 13.5726 | Learning rate : 5.13e-05
Batch : 83 / 196 | Time 263 ms | Train Loss : 4.4112 | Grad Norm : 12.3322 | Learning rate : 5.12e-05
Batch : 84 / 196 | Time 266 ms | Train Loss : 4.4348 | Grad Norm : 15.5946 | Learning rate : 5.12e-05
Batch : 85 / 196 | Time 265 ms | Train Loss : 4.4746 | Grad Norm : 19.3807 | Learning rate : 5.11e-05
Batch : 86 / 196 | Time 265 ms | Train Loss : 4.4120 | Grad Norm : 11.2951 | Learning rate : 5.10e-05
Batch : 87 / 196 | Time 265 ms | Train Loss : 4.3913 | Grad Norm : 13.8063 | Learning rate : 5.09e-05
Batch : 88 / 196 | Time 266 ms | Train Loss : 4.4384 | Grad Norm : 10.5672 | Learning rate : 5.08e-05
Batch : 89 / 196 | Time 267 ms | Train Loss : 4.3823 | Grad Norm : 15.6163 | Learning rate : 5.07e-05
Batch : 90 / 196 | Time 266 ms | Train Loss : 4.3143 | Grad Norm : 15.1937 | Learning rate : 5.06e-05
Batch : 91 / 196 | Time 271 ms | Train Loss : 4.4021 | Grad Norm : 10.7788 | Learning rate : 5.05e-05
Batch : 92 / 196 | Time 266 ms | Train Loss : 4.4773 | Grad Norm : 18.4428 | Learning rate : 5.04e-05
Batch : 93 / 196 | Time 264 ms | Train Loss : 4.4702 | Grad Norm : 16.1435 | Learning rate : 5.04e-05
Batch : 94 / 196 | Time 269 ms | Train Loss : 4.3454 | Grad Norm : 12.2985 | Learning rate : 5.03e-05
Batch : 95 / 196 | Time 270 ms | Train Loss : 4.3469 | Grad Norm : 17.3799 | Learning rate : 5.02e-05
Batch : 96 / 196 | Time 268 ms | Train Loss : 4.4695 | Grad Norm : 14.8520 | Learning rate : 5.01e-05
Batch : 97 / 196 | Time 273 ms | Train Loss : 4.3412 | Grad Norm : 23.3389 | Learning rate : 5.00e-05
Batch : 98 / 196 | Time 265 ms | Train Loss : 4.3760 | Grad Norm : 11.5900 | Learning rate : 4.99e-05
Batch : 99 / 196 | Time 267 ms | Train Loss : 4.4404 | Grad Norm : 10.6325 | Learning rate : 4.98e-05
Batch : 100 / 196 | Time 265 ms | Train Loss : 4.5573 | Grad Norm : 20.4078 | Learning rate : 4.97e-05
Batch : 101 / 196 | Time 267 ms | Train Loss : 4.3484 | Grad Norm : 15.6197 | Learning rate : 4.96e-05
Batch : 102 / 196 | Time 266 ms | Train Loss : 4.4106 | Grad Norm : 11.6591 | Learning rate : 4.96e-05
Batch : 103 / 196 | Time 277 ms | Train Loss : 4.3662 | Grad Norm : 17.2965 | Learning rate : 4.95e-05
Batch : 104 / 196 | Time 264 ms | Train Loss : 4.4525 | Grad Norm : 18.4244 | Learning rate : 4.94e-05
Batch : 105 / 196 | Time 271 ms | Train Loss : 4.4033 | Grad Norm : 12.0563 | Learning rate : 4.93e-05
Batch : 106 / 196 | Time 265 ms | Train Loss : 4.3619 | Grad Norm : 16.7809 | Learning rate : 4.92e-05
Batch : 107 / 196 | Time 274 ms | Train Loss : 4.4565 | Grad Norm : 15.0433 | Learning rate : 4.91e-05
Batch : 108 / 196 | Time 278 ms | Train Loss : 4.3970 | Grad Norm : 14.8955 | Learning rate : 4.90e-05
Batch : 109 / 196 | Time 268 ms | Train Loss : 4.4060 | Grad Norm : 15.7071 | Learning rate : 4.89e-05
Batch : 110 / 196 | Time 264 ms | Train Loss : 4.3724 | Grad Norm : 17.5504 | Learning rate : 4.88e-05
Batch : 111 / 196 | Time 268 ms | Train Loss : 4.4294 | Grad Norm : 13.7924 | Learning rate : 4.88e-05
Batch : 112 / 196 | Time 273 ms | Train Loss : 4.4680 | Grad Norm : 10.9201 | Learning rate : 4.87e-05
Batch : 113 / 196 | Time 264 ms | Train Loss : 4.3736 | Grad Norm : 17.3549 | Learning rate : 4.86e-05
Batch : 114 / 196 | Time 267 ms | Train Loss : 4.3716 | Grad Norm : 22.1081 | Learning rate : 4.85e-05
Batch : 115 / 196 | Time 268 ms | Train Loss : 4.4616 | Grad Norm : 13.1601 | Learning rate : 4.84e-05
Batch : 116 / 196 | Time 265 ms | Train Loss : 4.2930 | Grad Norm : 16.5006 | Learning rate : 4.83e-05
Batch : 117 / 196 | Time 267 ms | Train Loss : 4.4596 | Grad Norm : 17.4038 | Learning rate : 4.82e-05
Batch : 118 / 196 | Time 275 ms | Train Loss : 4.3461 | Grad Norm : 13.3345 | Learning rate : 4.81e-05
Batch : 119 / 196 | Time 266 ms | Train Loss : 4.3721 | Grad Norm : 12.2420 | Learning rate : 4.80e-05
Batch : 120 / 196 | Time 264 ms | Train Loss : 4.4317 | Grad Norm : 13.1871 | Learning rate : 4.80e-05
Batch : 121 / 196 | Time 265 ms | Train Loss : 4.4084 | Grad Norm : 16.7865 | Learning rate : 4.79e-05
Batch : 122 / 196 | Time 278 ms | Train Loss : 4.3348 | Grad Norm : 14.3239 | Learning rate : 4.78e-05
Batch : 123 / 196 | Time 271 ms | Train Loss : 4.3041 | Grad Norm : 10.6997 | Learning rate : 4.77e-05
Batch : 124 / 196 | Time 268 ms | Train Loss : 4.4353 | Grad Norm : 11.5949 | Learning rate : 4.76e-05
Batch : 125 / 196 | Time 265 ms | Train Loss : 4.3272 | Grad Norm : 17.7781 | Learning rate : 4.75e-05
Batch : 126 / 196 | Time 268 ms | Train Loss : 4.3937 | Grad Norm : 20.3811 | Learning rate : 4.74e-05
Batch : 127 / 196 | Time 264 ms | Train Loss : 4.3938 | Grad Norm : 12.6159 | Learning rate : 4.73e-05
Batch : 128 / 196 | Time 266 ms | Train Loss : 4.3516 | Grad Norm : 18.5011 | Learning rate : 4.72e-05
Batch : 129 / 196 | Time 264 ms | Train Loss : 4.3800 | Grad Norm : 10.7926 | Learning rate : 4.72e-05
Batch : 130 / 196 | Time 264 ms | Train Loss : 4.4503 | Grad Norm : 13.7787 | Learning rate : 4.71e-05
Batch : 131 / 196 | Time 266 ms | Train Loss : 4.4670 | Grad Norm : 11.8791 | Learning rate : 4.70e-05
Batch : 132 / 196 | Time 264 ms | Train Loss : 4.2583 | Grad Norm : 10.8725 | Learning rate : 4.69e-05
Batch : 133 / 196 | Time 270 ms | Train Loss : 4.3940 | Grad Norm : 11.3117 | Learning rate : 4.68e-05
Batch : 134 / 196 | Time 264 ms | Train Loss : 4.3428 | Grad Norm : 15.0505 | Learning rate : 4.67e-05
Batch : 135 / 196 | Time 272 ms | Train Loss : 4.3396 | Grad Norm : 16.9876 | Learning rate : 4.66e-05
Batch : 136 / 196 | Time 271 ms | Train Loss : 4.4505 | Grad Norm : 22.9970 | Learning rate : 4.65e-05
Batch : 137 / 196 | Time 273 ms | Train Loss : 4.4075 | Grad Norm : 16.6954 | Learning rate : 4.64e-05
Batch : 138 / 196 | Time 265 ms | Train Loss : 4.4205 | Grad Norm : 21.2231 | Learning rate : 4.64e-05
Batch : 139 / 196 | Time 272 ms | Train Loss : 4.4002 | Grad Norm : 18.9293 | Learning rate : 4.63e-05
Batch : 140 / 196 | Time 268 ms | Train Loss : 4.3833 | Grad Norm : 17.9917 | Learning rate : 4.62e-05
Batch : 141 / 196 | Time 265 ms | Train Loss : 4.3849 | Grad Norm : 13.8259 | Learning rate : 4.61e-05
Batch : 142 / 196 | Time 267 ms | Train Loss : 4.3589 | Grad Norm : 15.0723 | Learning rate : 4.60e-05
Batch : 143 / 196 | Time 269 ms | Train Loss : 4.3194 | Grad Norm : 14.1477 | Learning rate : 4.59e-05
Batch : 144 / 196 | Time 264 ms | Train Loss : 4.3157 | Grad Norm : 15.0565 | Learning rate : 4.58e-05
Batch : 145 / 196 | Time 267 ms | Train Loss : 4.3537 | Grad Norm : 16.7772 | Learning rate : 4.57e-05
Batch : 146 / 196 | Time 268 ms | Train Loss : 4.3333 | Grad Norm : 11.1984 | Learning rate : 4.56e-05
Batch : 147 / 196 | Time 268 ms | Train Loss : 4.3816 | Grad Norm : 12.0030 | Learning rate : 4.56e-05
Batch : 148 / 196 | Time 269 ms | Train Loss : 4.3377 | Grad Norm : 15.2877 | Learning rate : 4.55e-05
Batch : 149 / 196 | Time 263 ms | Train Loss : 4.3643 | Grad Norm : 13.3851 | Learning rate : 4.54e-05
Batch : 150 / 196 | Time 268 ms | Train Loss : 4.4304 | Grad Norm : 18.9671 | Learning rate : 4.53e-05
Batch : 151 / 196 | Time 263 ms | Train Loss : 4.3366 | Grad Norm : 11.6520 | Learning rate : 4.52e-05
Batch : 152 / 196 | Time 263 ms | Train Loss : 4.4291 | Grad Norm : 15.3664 | Learning rate : 4.51e-05
Batch : 153 / 196 | Time 265 ms | Train Loss : 4.3546 | Grad Norm : 13.2769 | Learning rate : 4.50e-05
Batch : 154 / 196 | Time 269 ms | Train Loss : 4.3749 | Grad Norm : 19.5818 | Learning rate : 4.49e-05
Batch : 155 / 196 | Time 264 ms | Train Loss : 4.4643 | Grad Norm : 20.8876 | Learning rate : 4.48e-05
Batch : 156 / 196 | Time 266 ms | Train Loss : 4.3181 | Grad Norm : 13.4558 | Learning rate : 4.48e-05
Batch : 157 / 196 | Time 272 ms | Train Loss : 4.4141 | Grad Norm : 16.1234 | Learning rate : 4.47e-05
Batch : 158 / 196 | Time 264 ms | Train Loss : 4.3877 | Grad Norm : 15.0801 | Learning rate : 4.46e-05
Batch : 159 / 196 | Time 275 ms | Train Loss : 4.3656 | Grad Norm : 15.2216 | Learning rate : 4.45e-05
Batch : 160 / 196 | Time 266 ms | Train Loss : 4.3094 | Grad Norm : 17.3081 | Learning rate : 4.44e-05
Batch : 161 / 196 | Time 264 ms | Train Loss : 4.3943 | Grad Norm : 15.7681 | Learning rate : 4.43e-05
Batch : 162 / 196 | Time 265 ms | Train Loss : 4.4278 | Grad Norm : 9.7749 | Learning rate : 4.42e-05
Batch : 163 / 196 | Time 264 ms | Train Loss : 4.4156 | Grad Norm : 11.5998 | Learning rate : 4.41e-05
Batch : 164 / 196 | Time 266 ms | Train Loss : 4.3719 | Grad Norm : 12.9395 | Learning rate : 4.40e-05
Batch : 165 / 196 | Time 265 ms | Train Loss : 4.4031 | Grad Norm : 10.3998 | Learning rate : 4.40e-05
Batch : 166 / 196 | Time 264 ms | Train Loss : 4.3700 | Grad Norm : 21.0512 | Learning rate : 4.39e-05
Batch : 167 / 196 | Time 269 ms | Train Loss : 4.4634 | Grad Norm : 14.8642 | Learning rate : 4.38e-05
Batch : 168 / 196 | Time 265 ms | Train Loss : 4.3680 | Grad Norm : 17.5233 | Learning rate : 4.37e-05
Batch : 169 / 196 | Time 264 ms | Train Loss : 4.3765 | Grad Norm : 11.0341 | Learning rate : 4.36e-05
Batch : 170 / 196 | Time 265 ms | Train Loss : 4.4134 | Grad Norm : 23.3206 | Learning rate : 4.35e-05
Batch : 171 / 196 | Time 265 ms | Train Loss : 4.4037 | Grad Norm : 19.7097 | Learning rate : 4.34e-05
Batch : 172 / 196 | Time 264 ms | Train Loss : 4.3986 | Grad Norm : 17.0441 | Learning rate : 4.33e-05
Batch : 173 / 196 | Time 263 ms | Train Loss : 4.3397 | Grad Norm : 14.4970 | Learning rate : 4.33e-05
Batch : 174 / 196 | Time 265 ms | Train Loss : 4.3357 | Grad Norm : 14.2711 | Learning rate : 4.32e-05
Batch : 175 / 196 | Time 266 ms | Train Loss : 4.4312 | Grad Norm : 14.4527 | Learning rate : 4.31e-05
Batch : 176 / 196 | Time 264 ms | Train Loss : 4.2835 | Grad Norm : 12.9977 | Learning rate : 4.30e-05
Batch : 177 / 196 | Time 263 ms | Train Loss : 4.4246 | Grad Norm : 16.2724 | Learning rate : 4.29e-05
Batch : 178 / 196 | Time 264 ms | Train Loss : 4.4280 | Grad Norm : 13.2467 | Learning rate : 4.28e-05
Batch : 179 / 196 | Time 265 ms | Train Loss : 4.4215 | Grad Norm : 15.4583 | Learning rate : 4.27e-05
Batch : 180 / 196 | Time 265 ms | Train Loss : 4.4733 | Grad Norm : 25.0303 | Learning rate : 4.26e-05
Batch : 181 / 196 | Time 258 ms | Train Loss : 4.3594 | Grad Norm : 11.8020 | Learning rate : 4.25e-05
Batch : 182 / 196 | Time 264 ms | Train Loss : 4.5372 | Grad Norm : 12.8704 | Learning rate : 4.25e-05
Batch : 183 / 196 | Time 267 ms | Train Loss : 4.3316 | Grad Norm : 12.9515 | Learning rate : 4.24e-05
Batch : 184 / 196 | Time 264 ms | Train Loss : 4.4576 | Grad Norm : 14.9311 | Learning rate : 4.23e-05
Batch : 185 / 196 | Time 268 ms | Train Loss : 4.3376 | Grad Norm : 8.8302 | Learning rate : 4.22e-05
Batch : 186 / 196 | Time 266 ms | Train Loss : 4.3503 | Grad Norm : 19.7184 | Learning rate : 4.21e-05
Batch : 187 / 196 | Time 265 ms | Train Loss : 4.2706 | Grad Norm : 14.5106 | Learning rate : 4.20e-05
Batch : 188 / 196 | Time 269 ms | Train Loss : 4.2394 | Grad Norm : 12.3685 | Learning rate : 4.19e-05
Batch : 189 / 196 | Time 264 ms | Train Loss : 4.3952 | Grad Norm : 14.6886 | Learning rate : 4.18e-05
Batch : 190 / 196 | Time 264 ms | Train Loss : 4.4022 | Grad Norm : 22.7228 | Learning rate : 4.18e-05
Batch : 191 / 196 | Time 264 ms | Train Loss : 4.4028 | Grad Norm : 20.1520 | Learning rate : 4.17e-05
Batch : 192 / 196 | Time 262 ms | Train Loss : 4.4459 | Grad Norm : 11.2703 | Learning rate : 4.16e-05
Batch : 193 / 196 | Time 267 ms | Train Loss : 4.3758 | Grad Norm : 20.9049 | Learning rate : 4.15e-05
Batch : 194 / 196 | Time 269 ms | Train Loss : 4.4369 | Grad Norm : 21.7556 | Learning rate : 4.14e-05
Batch : 195 / 196 | Time 112 ms | Train Loss : 3.1931 | Grad Norm : 24.2030 | Learning rate : 4.13e-05
Epoch : 5 | Training Loss : 3.1931| Accuracy on test set : 0.4924
 Batch : 0 / 196 | Time 279 ms | Train Loss : 4.3405 | Grad Norm : 8.8158 | Learning rate : 4.12e-05
Batch : 1 / 196 | Time 270 ms | Train Loss : 4.3908 | Grad Norm : 15.1340 | Learning rate : 4.11e-05
Batch : 2 / 196 | Time 267 ms | Train Loss : 4.3111 | Grad Norm : 16.6271 | Learning rate : 4.11e-05
Batch : 3 / 196 | Time 263 ms | Train Loss : 4.2042 | Grad Norm : 15.2193 | Learning rate : 4.10e-05
Batch : 4 / 196 | Time 264 ms | Train Loss : 4.3585 | Grad Norm : 16.4036 | Learning rate : 4.09e-05
Batch : 5 / 196 | Time 265 ms | Train Loss : 4.2930 | Grad Norm : 16.7452 | Learning rate : 4.08e-05
Batch : 6 / 196 | Time 259 ms | Train Loss : 4.3321 | Grad Norm : 19.8777 | Learning rate : 4.07e-05
Batch : 7 / 196 | Time 266 ms | Train Loss : 4.3522 | Grad Norm : 16.0832 | Learning rate : 4.06e-05
Batch : 8 / 196 | Time 268 ms | Train Loss : 4.5234 | Grad Norm : 17.8920 | Learning rate : 4.05e-05
Batch : 9 / 196 | Time 265 ms | Train Loss : 4.3543 | Grad Norm : 17.9344 | Learning rate : 4.04e-05
Batch : 10 / 196 | Time 265 ms | Train Loss : 4.2273 | Grad Norm : 13.9527 | Learning rate : 4.04e-05
Batch : 11 / 196 | Time 264 ms | Train Loss : 4.3356 | Grad Norm : 10.4026 | Learning rate : 4.03e-05
Batch : 12 / 196 | Time 270 ms | Train Loss : 4.3855 | Grad Norm : 12.6336 | Learning rate : 4.02e-05
Batch : 13 / 196 | Time 264 ms | Train Loss : 4.3339 | Grad Norm : 16.2043 | Learning rate : 4.01e-05
Batch : 14 / 196 | Time 266 ms | Train Loss : 4.3156 | Grad Norm : 15.0219 | Learning rate : 4.00e-05
Batch : 15 / 196 | Time 266 ms | Train Loss : 4.3676 | Grad Norm : 16.9807 | Learning rate : 3.99e-05
Batch : 16 / 196 | Time 267 ms | Train Loss : 4.4698 | Grad Norm : 14.5057 | Learning rate : 3.98e-05
Batch : 17 / 196 | Time 263 ms | Train Loss : 4.3460 | Grad Norm : 9.6083 | Learning rate : 3.97e-05
Batch : 18 / 196 | Time 270 ms | Train Loss : 4.2275 | Grad Norm : 11.8777 | Learning rate : 3.97e-05
Batch : 19 / 196 | Time 266 ms | Train Loss : 4.3774 | Grad Norm : 12.3380 | Learning rate : 3.96e-05
Batch : 20 / 196 | Time 263 ms | Train Loss : 4.3885 | Grad Norm : 13.9320 | Learning rate : 3.95e-05
Batch : 21 / 196 | Time 264 ms | Train Loss : 4.3576 | Grad Norm : 17.9326 | Learning rate : 3.94e-05
Batch : 22 / 196 | Time 265 ms | Train Loss : 4.3963 | Grad Norm : 20.3498 | Learning rate : 3.93e-05
Batch : 23 / 196 | Time 266 ms | Train Loss : 4.2050 | Grad Norm : 16.8312 | Learning rate : 3.92e-05
Batch : 24 / 196 | Time 262 ms | Train Loss : 4.4057 | Grad Norm : 8.5168 | Learning rate : 3.91e-05
Batch : 25 / 196 | Time 264 ms | Train Loss : 4.1884 | Grad Norm : 14.2530 | Learning rate : 3.90e-05
Batch : 26 / 196 | Time 264 ms | Train Loss : 4.3003 | Grad Norm : 13.0980 | Learning rate : 3.90e-05
Batch : 27 / 196 | Time 264 ms | Train Loss : 4.2884 | Grad Norm : 10.2858 | Learning rate : 3.89e-05
Batch : 28 / 196 | Time 263 ms | Train Loss : 4.2628 | Grad Norm : 12.4483 | Learning rate : 3.88e-05
Batch : 29 / 196 | Time 266 ms | Train Loss : 4.2607 | Grad Norm : 12.1898 | Learning rate : 3.87e-05
Batch : 30 / 196 | Time 264 ms | Train Loss : 4.2298 | Grad Norm : 13.6797 | Learning rate : 3.86e-05
Batch : 31 / 196 | Time 265 ms | Train Loss : 4.3865 | Grad Norm : 16.5409 | Learning rate : 3.85e-05
Batch : 32 / 196 | Time 264 ms | Train Loss : 4.3724 | Grad Norm : 16.5520 | Learning rate : 3.84e-05
Batch : 33 / 196 | Time 266 ms | Train Loss : 4.3869 | Grad Norm : 14.9589 | Learning rate : 3.84e-05
Batch : 34 / 196 | Time 266 ms | Train Loss : 4.2795 | Grad Norm : 19.7615 | Learning rate : 3.83e-05
Batch : 35 / 196 | Time 266 ms | Train Loss : 4.5436 | Grad Norm : 12.4073 | Learning rate : 3.82e-05
Batch : 36 / 196 | Time 264 ms | Train Loss : 4.3687 | Grad Norm : 14.2453 | Learning rate : 3.81e-05
Batch : 37 / 196 | Time 265 ms | Train Loss : 4.3827 | Grad Norm : 11.3178 | Learning rate : 3.80e-05
Batch : 38 / 196 | Time 260 ms | Train Loss : 4.3125 | Grad Norm : 9.8082 | Learning rate : 3.79e-05
Batch : 39 / 196 | Time 270 ms | Train Loss : 4.4184 | Grad Norm : 16.4790 | Learning rate : 3.78e-05
Batch : 40 / 196 | Time 266 ms | Train Loss : 4.3483 | Grad Norm : 13.0906 | Learning rate : 3.77e-05
Batch : 41 / 196 | Time 266 ms | Train Loss : 4.2032 | Grad Norm : 14.5968 | Learning rate : 3.77e-05
Batch : 42 / 196 | Time 267 ms | Train Loss : 4.3931 | Grad Norm : 21.1988 | Learning rate : 3.76e-05
Batch : 43 / 196 | Time 265 ms | Train Loss : 4.4490 | Grad Norm : 18.3012 | Learning rate : 3.75e-05
Batch : 44 / 196 | Time 267 ms | Train Loss : 4.4713 | Grad Norm : 14.1202 | Learning rate : 3.74e-05
Batch : 45 / 196 | Time 264 ms | Train Loss : 4.3835 | Grad Norm : 20.0668 | Learning rate : 3.73e-05
Batch : 46 / 196 | Time 270 ms | Train Loss : 4.3738 | Grad Norm : 18.4459 | Learning rate : 3.72e-05
Batch : 47 / 196 | Time 264 ms | Train Loss : 4.2663 | Grad Norm : 9.6170 | Learning rate : 3.71e-05
Batch : 48 / 196 | Time 267 ms | Train Loss : 4.3912 | Grad Norm : 16.1331 | Learning rate : 3.71e-05
Batch : 49 / 196 | Time 266 ms | Train Loss : 4.3362 | Grad Norm : 15.9367 | Learning rate : 3.70e-05
Batch : 50 / 196 | Time 271 ms | Train Loss : 4.2410 | Grad Norm : 13.5624 | Learning rate : 3.69e-05
Batch : 51 / 196 | Time 265 ms | Train Loss : 4.3664 | Grad Norm : 11.9129 | Learning rate : 3.68e-05
Batch : 52 / 196 | Time 266 ms | Train Loss : 4.2708 | Grad Norm : 12.9952 | Learning rate : 3.67e-05
Batch : 53 / 196 | Time 266 ms | Train Loss : 4.3470 | Grad Norm : 17.7336 | Learning rate : 3.66e-05
Batch : 54 / 196 | Time 265 ms | Train Loss : 4.3172 | Grad Norm : 19.5006 | Learning rate : 3.65e-05
Batch : 55 / 196 | Time 268 ms | Train Loss : 4.3674 | Grad Norm : 18.0756 | Learning rate : 3.65e-05
Batch : 56 / 196 | Time 266 ms | Train Loss : 4.2354 | Grad Norm : 13.3127 | Learning rate : 3.64e-05
Batch : 57 / 196 | Time 264 ms | Train Loss : 4.5042 | Grad Norm : 13.8418 | Learning rate : 3.63e-05
Batch : 58 / 196 | Time 265 ms | Train Loss : 4.2978 | Grad Norm : 21.2779 | Learning rate : 3.62e-05
Batch : 59 / 196 | Time 268 ms | Train Loss : 4.3351 | Grad Norm : 23.6082 | Learning rate : 3.61e-05
Batch : 60 / 196 | Time 267 ms | Train Loss : 4.3229 | Grad Norm : 18.8140 | Learning rate : 3.60e-05
Batch : 61 / 196 | Time 264 ms | Train Loss : 4.3329 | Grad Norm : 18.8527 | Learning rate : 3.59e-05
Batch : 62 / 196 | Time 266 ms | Train Loss : 4.4069 | Grad Norm : 21.3592 | Learning rate : 3.59e-05
Batch : 63 / 196 | Time 265 ms | Train Loss : 4.3635 | Grad Norm : 18.6068 | Learning rate : 3.58e-05
Batch : 64 / 196 | Time 267 ms | Train Loss : 4.3811 | Grad Norm : 14.0929 | Learning rate : 3.57e-05
Batch : 65 / 196 | Time 266 ms | Train Loss : 4.4303 | Grad Norm : 16.6132 | Learning rate : 3.56e-05
Batch : 66 / 196 | Time 274 ms | Train Loss : 4.3395 | Grad Norm : 16.7385 | Learning rate : 3.55e-05
Batch : 67 / 196 | Time 265 ms | Train Loss : 4.3655 | Grad Norm : 17.4869 | Learning rate : 3.54e-05
Batch : 68 / 196 | Time 277 ms | Train Loss : 4.2126 | Grad Norm : 12.7962 | Learning rate : 3.53e-05
Batch : 69 / 196 | Time 264 ms | Train Loss : 4.2704 | Grad Norm : 11.9855 | Learning rate : 3.53e-05
Batch : 70 / 196 | Time 264 ms | Train Loss : 4.3285 | Grad Norm : 14.9117 | Learning rate : 3.52e-05
Batch : 71 / 196 | Time 268 ms | Train Loss : 4.2788 | Grad Norm : 15.4216 | Learning rate : 3.51e-05
Batch : 72 / 196 | Time 268 ms | Train Loss : 4.2865 | Grad Norm : 12.9985 | Learning rate : 3.50e-05
Batch : 73 / 196 | Time 264 ms | Train Loss : 4.3187 | Grad Norm : 16.0852 | Learning rate : 3.49e-05
Batch : 74 / 196 | Time 274 ms | Train Loss : 4.2310 | Grad Norm : 20.0384 | Learning rate : 3.48e-05
Batch : 75 / 196 | Time 263 ms | Train Loss : 4.3404 | Grad Norm : 24.9112 | Learning rate : 3.48e-05
Batch : 76 / 196 | Time 265 ms | Train Loss : 4.3921 | Grad Norm : 19.0318 | Learning rate : 3.47e-05
Batch : 77 / 196 | Time 265 ms | Train Loss : 4.2773 | Grad Norm : 17.8008 | Learning rate : 3.46e-05
Batch : 78 / 196 | Time 265 ms | Train Loss : 4.3939 | Grad Norm : 17.9656 | Learning rate : 3.45e-05
Batch : 79 / 196 | Time 260 ms | Train Loss : 4.3760 | Grad Norm : 16.5561 | Learning rate : 3.44e-05
Batch : 80 / 196 | Time 264 ms | Train Loss : 4.2229 | Grad Norm : 12.5703 | Learning rate : 3.43e-05
Batch : 81 / 196 | Time 264 ms | Train Loss : 4.3314 | Grad Norm : 12.0688 | Learning rate : 3.42e-05
Batch : 82 / 196 | Time 265 ms | Train Loss : 4.3047 | Grad Norm : 14.7741 | Learning rate : 3.42e-05
Batch : 83 / 196 | Time 264 ms | Train Loss : 4.3134 | Grad Norm : 19.4378 | Learning rate : 3.41e-05
Batch : 84 / 196 | Time 267 ms | Train Loss : 4.4033 | Grad Norm : 26.8652 | Learning rate : 3.40e-05
Batch : 85 / 196 | Time 265 ms | Train Loss : 4.3507 | Grad Norm : 13.7021 | Learning rate : 3.39e-05
Batch : 86 / 196 | Time 264 ms | Train Loss : 4.3845 | Grad Norm : 12.4198 | Learning rate : 3.38e-05
Batch : 87 / 196 | Time 264 ms | Train Loss : 4.3341 | Grad Norm : 14.4826 | Learning rate : 3.37e-05
Batch : 88 / 196 | Time 270 ms | Train Loss : 4.2854 | Grad Norm : 13.0911 | Learning rate : 3.37e-05
Batch : 89 / 196 | Time 267 ms | Train Loss : 4.3035 | Grad Norm : 18.5158 | Learning rate : 3.36e-05
Batch : 90 / 196 | Time 264 ms | Train Loss : 4.3945 | Grad Norm : 14.9251 | Learning rate : 3.35e-05
Batch : 91 / 196 | Time 265 ms | Train Loss : 4.3019 | Grad Norm : 12.4690 | Learning rate : 3.34e-05
Batch : 92 / 196 | Time 267 ms | Train Loss : 4.3385 | Grad Norm : 9.3325 | Learning rate : 3.33e-05
Batch : 93 / 196 | Time 265 ms | Train Loss : 4.2601 | Grad Norm : 10.3653 | Learning rate : 3.32e-05
Batch : 94 / 196 | Time 269 ms | Train Loss : 4.3901 | Grad Norm : 12.8425 | Learning rate : 3.32e-05
Batch : 95 / 196 | Time 269 ms | Train Loss : 4.2797 | Grad Norm : 15.8705 | Learning rate : 3.31e-05
Batch : 96 / 196 | Time 268 ms | Train Loss : 4.3026 | Grad Norm : 16.5382 | Learning rate : 3.30e-05
Batch : 97 / 196 | Time 265 ms | Train Loss : 4.2468 | Grad Norm : 12.5855 | Learning rate : 3.29e-05
Batch : 98 / 196 | Time 267 ms | Train Loss : 4.3908 | Grad Norm : 15.9492 | Learning rate : 3.28e-05
Batch : 99 / 196 | Time 264 ms | Train Loss : 4.5010 | Grad Norm : 10.7463 | Learning rate : 3.27e-05
Batch : 100 / 196 | Time 266 ms | Train Loss : 4.2631 | Grad Norm : 12.6646 | Learning rate : 3.26e-05
Batch : 101 / 196 | Time 265 ms | Train Loss : 4.2655 | Grad Norm : 11.5821 | Learning rate : 3.26e-05
Batch : 102 / 196 | Time 268 ms | Train Loss : 4.2284 | Grad Norm : 9.7567 | Learning rate : 3.25e-05
Batch : 103 / 196 | Time 272 ms | Train Loss : 4.3623 | Grad Norm : 14.3019 | Learning rate : 3.24e-05
Batch : 104 / 196 | Time 265 ms | Train Loss : 4.3440 | Grad Norm : 11.5130 | Learning rate : 3.23e-05
Batch : 105 / 196 | Time 265 ms | Train Loss : 4.3822 | Grad Norm : 17.7837 | Learning rate : 3.22e-05
Batch : 106 / 196 | Time 269 ms | Train Loss : 4.3697 | Grad Norm : 17.5925 | Learning rate : 3.21e-05
Batch : 107 / 196 | Time 270 ms | Train Loss : 4.4707 | Grad Norm : 12.3664 | Learning rate : 3.21e-05
Batch : 108 / 196 | Time 264 ms | Train Loss : 4.2934 | Grad Norm : 17.3100 | Learning rate : 3.20e-05
Batch : 109 / 196 | Time 268 ms | Train Loss : 4.2280 | Grad Norm : 10.7422 | Learning rate : 3.19e-05
Batch : 110 / 196 | Time 266 ms | Train Loss : 4.2570 | Grad Norm : 16.6545 | Learning rate : 3.18e-05
Batch : 111 / 196 | Time 271 ms | Train Loss : 4.2725 | Grad Norm : 10.7012 | Learning rate : 3.17e-05
Batch : 112 / 196 | Time 268 ms | Train Loss : 4.3769 | Grad Norm : 14.0956 | Learning rate : 3.17e-05
Batch : 113 / 196 | Time 263 ms | Train Loss : 4.3001 | Grad Norm : 13.6514 | Learning rate : 3.16e-05
Batch : 114 / 196 | Time 268 ms | Train Loss : 4.3410 | Grad Norm : 9.3245 | Learning rate : 3.15e-05
Batch : 115 / 196 | Time 266 ms | Train Loss : 4.2417 | Grad Norm : 10.3740 | Learning rate : 3.14e-05
Batch : 116 / 196 | Time 276 ms | Train Loss : 4.3611 | Grad Norm : 14.5207 | Learning rate : 3.13e-05
Batch : 117 / 196 | Time 265 ms | Train Loss : 4.2888 | Grad Norm : 14.6412 | Learning rate : 3.12e-05
Batch : 118 / 196 | Time 267 ms | Train Loss : 4.4036 | Grad Norm : 15.0936 | Learning rate : 3.12e-05
Batch : 119 / 196 | Time 269 ms | Train Loss : 4.4849 | Grad Norm : 15.3501 | Learning rate : 3.11e-05
Batch : 120 / 196 | Time 266 ms | Train Loss : 4.2921 | Grad Norm : 18.0792 | Learning rate : 3.10e-05
Batch : 121 / 196 | Time 267 ms | Train Loss : 4.3921 | Grad Norm : 21.8594 | Learning rate : 3.09e-05
Batch : 122 / 196 | Time 267 ms | Train Loss : 4.2448 | Grad Norm : 14.7891 | Learning rate : 3.08e-05
Batch : 123 / 196 | Time 273 ms | Train Loss : 4.4459 | Grad Norm : 12.3849 | Learning rate : 3.07e-05
Batch : 124 / 196 | Time 267 ms | Train Loss : 4.2488 | Grad Norm : 12.5336 | Learning rate : 3.07e-05
Batch : 125 / 196 | Time 264 ms | Train Loss : 4.3104 | Grad Norm : 17.5042 | Learning rate : 3.06e-05
Batch : 126 / 196 | Time 265 ms | Train Loss : 4.3301 | Grad Norm : 14.4711 | Learning rate : 3.05e-05
Batch : 127 / 196 | Time 266 ms | Train Loss : 4.4314 | Grad Norm : 15.1643 | Learning rate : 3.04e-05
Batch : 128 / 196 | Time 264 ms | Train Loss : 4.2918 | Grad Norm : 15.2570 | Learning rate : 3.03e-05
Batch : 129 / 196 | Time 265 ms | Train Loss : 4.2485 | Grad Norm : 13.4475 | Learning rate : 3.03e-05
Batch : 130 / 196 | Time 266 ms | Train Loss : 4.2849 | Grad Norm : 14.6249 | Learning rate : 3.02e-05
Batch : 131 / 196 | Time 267 ms | Train Loss : 4.2297 | Grad Norm : 13.0990 | Learning rate : 3.01e-05
Batch : 132 / 196 | Time 270 ms | Train Loss : 4.3199 | Grad Norm : 16.8787 | Learning rate : 3.00e-05
Batch : 133 / 196 | Time 266 ms | Train Loss : 4.2777 | Grad Norm : 11.4667 | Learning rate : 2.99e-05
Batch : 134 / 196 | Time 266 ms | Train Loss : 4.3892 | Grad Norm : 12.5022 | Learning rate : 2.98e-05
Batch : 135 / 196 | Time 271 ms | Train Loss : 4.3803 | Grad Norm : 14.7174 | Learning rate : 2.98e-05
Batch : 136 / 196 | Time 264 ms | Train Loss : 4.2895 | Grad Norm : 10.7117 | Learning rate : 2.97e-05
Batch : 137 / 196 | Time 265 ms | Train Loss : 4.2030 | Grad Norm : 10.4408 | Learning rate : 2.96e-05
Batch : 138 / 196 | Time 264 ms | Train Loss : 4.3202 | Grad Norm : 16.6939 | Learning rate : 2.95e-05
Batch : 139 / 196 | Time 263 ms | Train Loss : 4.3118 | Grad Norm : 12.5476 | Learning rate : 2.94e-05
Batch : 140 / 196 | Time 262 ms | Train Loss : 4.3460 | Grad Norm : 12.1347 | Learning rate : 2.94e-05
Batch : 141 / 196 | Time 266 ms | Train Loss : 4.2526 | Grad Norm : 12.9012 | Learning rate : 2.93e-05
Batch : 142 / 196 | Time 268 ms | Train Loss : 4.3031 | Grad Norm : 9.7083 | Learning rate : 2.92e-05
Batch : 143 / 196 | Time 264 ms | Train Loss : 4.3949 | Grad Norm : 30.4270 | Learning rate : 2.91e-05
Batch : 144 / 196 | Time 263 ms | Train Loss : 4.2276 | Grad Norm : 22.5468 | Learning rate : 2.90e-05
Batch : 145 / 196 | Time 264 ms | Train Loss : 4.3030 | Grad Norm : 11.7626 | Learning rate : 2.89e-05
Batch : 146 / 196 | Time 269 ms | Train Loss : 4.3829 | Grad Norm : 13.9883 | Learning rate : 2.89e-05
Batch : 147 / 196 | Time 265 ms | Train Loss : 4.3651 | Grad Norm : 15.4152 | Learning rate : 2.88e-05
Batch : 148 / 196 | Time 262 ms | Train Loss : 4.3581 | Grad Norm : 22.8114 | Learning rate : 2.87e-05
Batch : 149 / 196 | Time 267 ms | Train Loss : 4.2636 | Grad Norm : 21.5205 | Learning rate : 2.86e-05
Batch : 150 / 196 | Time 270 ms | Train Loss : 4.2763 | Grad Norm : 22.4834 | Learning rate : 2.85e-05
Batch : 151 / 196 | Time 270 ms | Train Loss : 4.2717 | Grad Norm : 21.6872 | Learning rate : 2.85e-05
Batch : 152 / 196 | Time 267 ms | Train Loss : 4.3934 | Grad Norm : 15.7725 | Learning rate : 2.84e-05
Batch : 153 / 196 | Time 266 ms | Train Loss : 4.4184 | Grad Norm : 14.7225 | Learning rate : 2.83e-05
Batch : 154 / 196 | Time 271 ms | Train Loss : 4.3813 | Grad Norm : 15.8037 | Learning rate : 2.82e-05
Batch : 155 / 196 | Time 264 ms | Train Loss : 4.3103 | Grad Norm : 19.2427 | Learning rate : 2.81e-05
Batch : 156 / 196 | Time 265 ms | Train Loss : 4.2631 | Grad Norm : 11.2040 | Learning rate : 2.81e-05
Batch : 157 / 196 | Time 271 ms | Train Loss : 4.2747 | Grad Norm : 12.4125 | Learning rate : 2.80e-05
Batch : 158 / 196 | Time 271 ms | Train Loss : 4.3642 | Grad Norm : 12.5021 | Learning rate : 2.79e-05
Batch : 159 / 196 | Time 266 ms | Train Loss : 4.4640 | Grad Norm : 22.7370 | Learning rate : 2.78e-05
Batch : 160 / 196 | Time 269 ms | Train Loss : 4.3065 | Grad Norm : 13.8423 | Learning rate : 2.77e-05
Batch : 161 / 196 | Time 271 ms | Train Loss : 4.3008 | Grad Norm : 10.3347 | Learning rate : 2.77e-05
Batch : 162 / 196 | Time 270 ms | Train Loss : 4.3517 | Grad Norm : 11.7991 | Learning rate : 2.76e-05
Batch : 163 / 196 | Time 270 ms | Train Loss : 4.2703 | Grad Norm : 21.4020 | Learning rate : 2.75e-05
Batch : 164 / 196 | Time 266 ms | Train Loss : 4.2748 | Grad Norm : 17.4735 | Learning rate : 2.74e-05
Batch : 165 / 196 | Time 268 ms | Train Loss : 4.3581 | Grad Norm : 16.4862 | Learning rate : 2.73e-05
Batch : 166 / 196 | Time 265 ms | Train Loss : 4.2679 | Grad Norm : 14.3027 | Learning rate : 2.73e-05
Batch : 167 / 196 | Time 264 ms | Train Loss : 4.3948 | Grad Norm : 21.1005 | Learning rate : 2.72e-05
Batch : 168 / 196 | Time 265 ms | Train Loss : 4.3617 | Grad Norm : 19.5396 | Learning rate : 2.71e-05
Batch : 169 / 196 | Time 268 ms | Train Loss : 4.3045 | Grad Norm : 11.1999 | Learning rate : 2.70e-05
Batch : 170 / 196 | Time 266 ms | Train Loss : 4.2608 | Grad Norm : 14.1206 | Learning rate : 2.70e-05
Batch : 171 / 196 | Time 268 ms | Train Loss : 4.2870 | Grad Norm : 11.4936 | Learning rate : 2.69e-05
Batch : 172 / 196 | Time 268 ms | Train Loss : 4.2941 | Grad Norm : 11.5973 | Learning rate : 2.68e-05
Batch : 173 / 196 | Time 270 ms | Train Loss : 4.2807 | Grad Norm : 12.9513 | Learning rate : 2.67e-05
Batch : 174 / 196 | Time 265 ms | Train Loss : 4.3787 | Grad Norm : 12.4039 | Learning rate : 2.66e-05
Batch : 175 / 196 | Time 263 ms | Train Loss : 4.1922 | Grad Norm : 10.6003 | Learning rate : 2.66e-05
Batch : 176 / 196 | Time 268 ms | Train Loss : 4.3301 | Grad Norm : 19.5363 | Learning rate : 2.65e-05
Batch : 177 / 196 | Time 267 ms | Train Loss : 4.3826 | Grad Norm : 17.7658 | Learning rate : 2.64e-05
Batch : 178 / 196 | Time 265 ms | Train Loss : 4.4035 | Grad Norm : 10.8059 | Learning rate : 2.63e-05
Batch : 179 / 196 | Time 271 ms | Train Loss : 4.3236 | Grad Norm : 15.7110 | Learning rate : 2.62e-05
Batch : 180 / 196 | Time 266 ms | Train Loss : 4.2547 | Grad Norm : 16.8349 | Learning rate : 2.62e-05
Batch : 181 / 196 | Time 278 ms | Train Loss : 4.3372 | Grad Norm : 14.3037 | Learning rate : 2.61e-05
Batch : 182 / 196 | Time 266 ms | Train Loss : 4.1559 | Grad Norm : 11.7243 | Learning rate : 2.60e-05
Batch : 183 / 196 | Time 266 ms | Train Loss : 4.3899 | Grad Norm : 13.5272 | Learning rate : 2.59e-05
Batch : 184 / 196 | Time 265 ms | Train Loss : 4.3722 | Grad Norm : 20.6150 | Learning rate : 2.59e-05
Batch : 185 / 196 | Time 263 ms | Train Loss : 4.2282 | Grad Norm : 12.8994 | Learning rate : 2.58e-05
Batch : 186 / 196 | Time 269 ms | Train Loss : 4.3711 | Grad Norm : 12.6909 | Learning rate : 2.57e-05
Batch : 187 / 196 | Time 260 ms | Train Loss : 4.3368 | Grad Norm : 18.6879 | Learning rate : 2.56e-05
Batch : 188 / 196 | Time 274 ms | Train Loss : 4.2586 | Grad Norm : 16.7233 | Learning rate : 2.55e-05
Batch : 189 / 196 | Time 268 ms | Train Loss : 4.2458 | Grad Norm : 13.8441 | Learning rate : 2.55e-05
Batch : 190 / 196 | Time 262 ms | Train Loss : 4.4990 | Grad Norm : 21.9777 | Learning rate : 2.54e-05
Batch : 191 / 196 | Time 265 ms | Train Loss : 4.3436 | Grad Norm : 16.2452 | Learning rate : 2.53e-05
Batch : 192 / 196 | Time 270 ms | Train Loss : 4.2747 | Grad Norm : 12.6082 | Learning rate : 2.52e-05
Batch : 193 / 196 | Time 266 ms | Train Loss : 4.3800 | Grad Norm : 18.9993 | Learning rate : 2.52e-05
Batch : 194 / 196 | Time 272 ms | Train Loss : 4.3385 | Grad Norm : 17.7086 | Learning rate : 2.51e-05
Batch : 195 / 196 | Time 110 ms | Train Loss : 3.1491 | Grad Norm : 16.6618 | Learning rate : 2.50e-05
Epoch : 6 | Training Loss : 3.1491| Accuracy on test set : 0.5208
 Batch : 0 / 196 | Time 274 ms | Train Loss : 4.2885 | Grad Norm : 18.9364 | Learning rate : 2.49e-05
Batch : 1 / 196 | Time 268 ms | Train Loss : 4.2409 | Grad Norm : 10.6160 | Learning rate : 2.48e-05
Batch : 2 / 196 | Time 267 ms | Train Loss : 4.2436 | Grad Norm : 16.8094 | Learning rate : 2.48e-05
Batch : 3 / 196 | Time 268 ms | Train Loss : 4.3843 | Grad Norm : 14.6756 | Learning rate : 2.47e-05
Batch : 4 / 196 | Time 265 ms | Train Loss : 4.3602 | Grad Norm : 17.2579 | Learning rate : 2.46e-05
Batch : 5 / 196 | Time 265 ms | Train Loss : 4.2729 | Grad Norm : 18.9107 | Learning rate : 2.45e-05
Batch : 6 / 196 | Time 265 ms | Train Loss : 4.3245 | Grad Norm : 16.7960 | Learning rate : 2.45e-05
Batch : 7 / 196 | Time 273 ms | Train Loss : 4.2899 | Grad Norm : 13.3583 | Learning rate : 2.44e-05
Batch : 8 / 196 | Time 265 ms | Train Loss : 4.2699 | Grad Norm : 19.8185 | Learning rate : 2.43e-05
Batch : 9 / 196 | Time 264 ms | Train Loss : 4.2487 | Grad Norm : 16.1889 | Learning rate : 2.42e-05
Batch : 10 / 196 | Time 263 ms | Train Loss : 4.2827 | Grad Norm : 11.2972 | Learning rate : 2.42e-05
Batch : 11 / 196 | Time 266 ms | Train Loss : 4.2369 | Grad Norm : 18.4514 | Learning rate : 2.41e-05
Batch : 12 / 196 | Time 268 ms | Train Loss : 4.2724 | Grad Norm : 21.3350 | Learning rate : 2.40e-05
Batch : 13 / 196 | Time 273 ms | Train Loss : 4.2738 | Grad Norm : 17.4657 | Learning rate : 2.39e-05
Batch : 14 / 196 | Time 273 ms | Train Loss : 4.2385 | Grad Norm : 21.0500 | Learning rate : 2.39e-05
Batch : 15 / 196 | Time 265 ms | Train Loss : 4.3740 | Grad Norm : 22.3694 | Learning rate : 2.38e-05
Batch : 16 / 196 | Time 269 ms | Train Loss : 4.2616 | Grad Norm : 20.4174 | Learning rate : 2.37e-05
Batch : 17 / 196 | Time 268 ms | Train Loss : 4.2524 | Grad Norm : 13.1950 | Learning rate : 2.36e-05
Batch : 18 / 196 | Time 266 ms | Train Loss : 4.4992 | Grad Norm : 17.0031 | Learning rate : 2.35e-05
Batch : 19 / 196 | Time 264 ms | Train Loss : 4.3220 | Grad Norm : 18.9750 | Learning rate : 2.35e-05
Batch : 20 / 196 | Time 266 ms | Train Loss : 4.2347 | Grad Norm : 20.4403 | Learning rate : 2.34e-05
Batch : 21 / 196 | Time 264 ms | Train Loss : 4.2920 | Grad Norm : 12.6799 | Learning rate : 2.33e-05
Batch : 22 / 196 | Time 266 ms | Train Loss : 4.3040 | Grad Norm : 18.3093 | Learning rate : 2.32e-05
Batch : 23 / 196 | Time 271 ms | Train Loss : 4.2344 | Grad Norm : 16.7031 | Learning rate : 2.32e-05
Batch : 24 / 196 | Time 270 ms | Train Loss : 4.2752 | Grad Norm : 18.5727 | Learning rate : 2.31e-05
Batch : 25 / 196 | Time 265 ms | Train Loss : 4.2580 | Grad Norm : 13.9901 | Learning rate : 2.30e-05
Batch : 26 / 196 | Time 269 ms | Train Loss : 4.3000 | Grad Norm : 17.5842 | Learning rate : 2.29e-05
Batch : 27 / 196 | Time 266 ms | Train Loss : 4.2539 | Grad Norm : 16.7931 | Learning rate : 2.29e-05
Batch : 28 / 196 | Time 265 ms | Train Loss : 4.2542 | Grad Norm : 17.3832 | Learning rate : 2.28e-05
Batch : 29 / 196 | Time 269 ms | Train Loss : 4.3387 | Grad Norm : 16.2980 | Learning rate : 2.27e-05
Batch : 30 / 196 | Time 264 ms | Train Loss : 4.3237 | Grad Norm : 15.0887 | Learning rate : 2.26e-05
Batch : 31 / 196 | Time 260 ms | Train Loss : 4.4328 | Grad Norm : 12.7211 | Learning rate : 2.26e-05
Batch : 32 / 196 | Time 266 ms | Train Loss : 4.2057 | Grad Norm : 14.4837 | Learning rate : 2.25e-05
Batch : 33 / 196 | Time 271 ms | Train Loss : 4.2268 | Grad Norm : 18.5236 | Learning rate : 2.24e-05
Batch : 34 / 196 | Time 263 ms | Train Loss : 4.1509 | Grad Norm : 12.3462 | Learning rate : 2.24e-05
Batch : 35 / 196 | Time 266 ms | Train Loss : 4.2735 | Grad Norm : 13.4047 | Learning rate : 2.23e-05
Batch : 36 / 196 | Time 269 ms | Train Loss : 4.3036 | Grad Norm : 11.7703 | Learning rate : 2.22e-05
Batch : 37 / 196 | Time 264 ms | Train Loss : 4.2106 | Grad Norm : 20.0234 | Learning rate : 2.21e-05
Batch : 38 / 196 | Time 265 ms | Train Loss : 4.2805 | Grad Norm : 17.6157 | Learning rate : 2.21e-05
Batch : 39 / 196 | Time 264 ms | Train Loss : 4.2218 | Grad Norm : 16.9812 | Learning rate : 2.20e-05
Batch : 40 / 196 | Time 269 ms | Train Loss : 4.2882 | Grad Norm : 19.4948 | Learning rate : 2.19e-05
Batch : 41 / 196 | Time 264 ms | Train Loss : 4.3104 | Grad Norm : 16.3412 | Learning rate : 2.18e-05
Batch : 42 / 196 | Time 263 ms | Train Loss : 4.2107 | Grad Norm : 16.7824 | Learning rate : 2.18e-05
Batch : 43 / 196 | Time 267 ms | Train Loss : 4.2825 | Grad Norm : 22.4358 | Learning rate : 2.17e-05
Batch : 44 / 196 | Time 269 ms | Train Loss : 4.1867 | Grad Norm : 17.9348 | Learning rate : 2.16e-05
Batch : 45 / 196 | Time 265 ms | Train Loss : 4.2523 | Grad Norm : 18.8081 | Learning rate : 2.15e-05
Batch : 46 / 196 | Time 266 ms | Train Loss : 4.2818 | Grad Norm : 10.7716 | Learning rate : 2.15e-05
Batch : 47 / 196 | Time 269 ms | Train Loss : 4.2239 | Grad Norm : 19.8730 | Learning rate : 2.14e-05
Batch : 48 / 196 | Time 272 ms | Train Loss : 4.1989 | Grad Norm : 20.4768 | Learning rate : 2.13e-05
Batch : 49 / 196 | Time 265 ms | Train Loss : 4.3752 | Grad Norm : 21.3177 | Learning rate : 2.12e-05
Batch : 50 / 196 | Time 267 ms | Train Loss : 4.1935 | Grad Norm : 16.2896 | Learning rate : 2.12e-05
Batch : 51 / 196 | Time 274 ms | Train Loss : 4.3239 | Grad Norm : 21.8471 | Learning rate : 2.11e-05
Batch : 52 / 196 | Time 265 ms | Train Loss : 4.2504 | Grad Norm : 18.7912 | Learning rate : 2.10e-05
Batch : 53 / 196 | Time 271 ms | Train Loss : 4.3087 | Grad Norm : 18.9942 | Learning rate : 2.10e-05
Batch : 54 / 196 | Time 270 ms | Train Loss : 4.2493 | Grad Norm : 16.7556 | Learning rate : 2.09e-05
Batch : 55 / 196 | Time 265 ms | Train Loss : 4.2223 | Grad Norm : 18.7036 | Learning rate : 2.08e-05
Batch : 56 / 196 | Time 266 ms | Train Loss : 4.2815 | Grad Norm : 20.5884 | Learning rate : 2.07e-05
Batch : 57 / 196 | Time 274 ms | Train Loss : 4.3157 | Grad Norm : 12.4106 | Learning rate : 2.07e-05
Batch : 58 / 196 | Time 268 ms | Train Loss : 4.3188 | Grad Norm : 20.1943 | Learning rate : 2.06e-05
Batch : 59 / 196 | Time 265 ms | Train Loss : 4.2654 | Grad Norm : 16.6456 | Learning rate : 2.05e-05
Batch : 60 / 196 | Time 264 ms | Train Loss : 4.3116 | Grad Norm : 17.6993 | Learning rate : 2.05e-05
Batch : 61 / 196 | Time 269 ms | Train Loss : 4.3252 | Grad Norm : 14.6705 | Learning rate : 2.04e-05
Batch : 62 / 196 | Time 264 ms | Train Loss : 4.2872 | Grad Norm : 13.5232 | Learning rate : 2.03e-05
Batch : 63 / 196 | Time 265 ms | Train Loss : 4.3177 | Grad Norm : 20.3266 | Learning rate : 2.02e-05
Batch : 64 / 196 | Time 264 ms | Train Loss : 4.2521 | Grad Norm : 15.6305 | Learning rate : 2.02e-05
Batch : 65 / 196 | Time 264 ms | Train Loss : 4.2119 | Grad Norm : 13.5822 | Learning rate : 2.01e-05
Batch : 66 / 196 | Time 266 ms | Train Loss : 4.2250 | Grad Norm : 13.0795 | Learning rate : 2.00e-05
Batch : 67 / 196 | Time 265 ms | Train Loss : 4.3107 | Grad Norm : 14.4407 | Learning rate : 2.00e-05
Batch : 68 / 196 | Time 264 ms | Train Loss : 4.3176 | Grad Norm : 10.7662 | Learning rate : 1.99e-05
Batch : 69 / 196 | Time 266 ms | Train Loss : 4.2953 | Grad Norm : 19.7366 | Learning rate : 1.98e-05
Batch : 70 / 196 | Time 265 ms | Train Loss : 4.1193 | Grad Norm : 12.5642 | Learning rate : 1.97e-05
Batch : 71 / 196 | Time 270 ms | Train Loss : 4.3335 | Grad Norm : 15.5352 | Learning rate : 1.97e-05
Batch : 72 / 196 | Time 263 ms | Train Loss : 4.3362 | Grad Norm : 12.2924 | Learning rate : 1.96e-05
Batch : 73 / 196 | Time 270 ms | Train Loss : 4.1888 | Grad Norm : 18.4290 | Learning rate : 1.95e-05
Batch : 74 / 196 | Time 265 ms | Train Loss : 4.2967 | Grad Norm : 11.7781 | Learning rate : 1.95e-05
Batch : 75 / 196 | Time 265 ms | Train Loss : 4.2418 | Grad Norm : 12.9584 | Learning rate : 1.94e-05
Batch : 76 / 196 | Time 272 ms | Train Loss : 4.2815 | Grad Norm : 15.5785 | Learning rate : 1.93e-05
Batch : 77 / 196 | Time 266 ms | Train Loss : 4.2348 | Grad Norm : 12.2990 | Learning rate : 1.92e-05
Batch : 78 / 196 | Time 265 ms | Train Loss : 4.2295 | Grad Norm : 15.9492 | Learning rate : 1.92e-05
Batch : 79 / 196 | Time 264 ms | Train Loss : 4.3366 | Grad Norm : 14.6332 | Learning rate : 1.91e-05
Batch : 80 / 196 | Time 264 ms | Train Loss : 4.3767 | Grad Norm : 12.3254 | Learning rate : 1.90e-05
Batch : 81 / 196 | Time 263 ms | Train Loss : 4.2445 | Grad Norm : 13.9720 | Learning rate : 1.90e-05
Batch : 82 / 196 | Time 260 ms | Train Loss : 4.3579 | Grad Norm : 13.4543 | Learning rate : 1.89e-05
Batch : 83 / 196 | Time 269 ms | Train Loss : 4.2642 | Grad Norm : 15.1286 | Learning rate : 1.88e-05
Batch : 84 / 196 | Time 265 ms | Train Loss : 4.3545 | Grad Norm : 13.5250 | Learning rate : 1.88e-05
Batch : 85 / 196 | Time 260 ms | Train Loss : 4.2807 | Grad Norm : 15.9309 | Learning rate : 1.87e-05
Batch : 86 / 196 | Time 264 ms | Train Loss : 4.1219 | Grad Norm : 13.8423 | Learning rate : 1.86e-05
Batch : 87 / 196 | Time 268 ms | Train Loss : 4.2606 | Grad Norm : 18.2305 | Learning rate : 1.85e-05
Batch : 88 / 196 | Time 265 ms | Train Loss : 4.2209 | Grad Norm : 10.3249 | Learning rate : 1.85e-05
Batch : 89 / 196 | Time 266 ms | Train Loss : 4.2328 | Grad Norm : 10.7718 | Learning rate : 1.84e-05
Batch : 90 / 196 | Time 264 ms | Train Loss : 4.2085 | Grad Norm : 22.0679 | Learning rate : 1.83e-05
Batch : 91 / 196 | Time 267 ms | Train Loss : 4.3224 | Grad Norm : 22.0673 | Learning rate : 1.83e-05
Batch : 92 / 196 | Time 269 ms | Train Loss : 4.2180 | Grad Norm : 16.7195 | Learning rate : 1.82e-05
Batch : 93 / 196 | Time 265 ms | Train Loss : 4.2957 | Grad Norm : 16.3969 | Learning rate : 1.81e-05
Batch : 94 / 196 | Time 264 ms | Train Loss : 4.2527 | Grad Norm : 23.2753 | Learning rate : 1.81e-05
Batch : 95 / 196 | Time 270 ms | Train Loss : 4.3109 | Grad Norm : 25.9404 | Learning rate : 1.80e-05
Batch : 96 / 196 | Time 264 ms | Train Loss : 4.2685 | Grad Norm : 20.2796 | Learning rate : 1.79e-05
Batch : 97 / 196 | Time 267 ms | Train Loss : 4.3396 | Grad Norm : 20.5001 | Learning rate : 1.79e-05
Batch : 98 / 196 | Time 264 ms | Train Loss : 4.2109 | Grad Norm : 13.1613 | Learning rate : 1.78e-05
Batch : 99 / 196 | Time 263 ms | Train Loss : 4.2738 | Grad Norm : 13.9409 | Learning rate : 1.77e-05
Batch : 100 / 196 | Time 270 ms | Train Loss : 4.2927 | Grad Norm : 19.3530 | Learning rate : 1.77e-05
Batch : 101 / 196 | Time 265 ms | Train Loss : 4.2842 | Grad Norm : 16.4390 | Learning rate : 1.76e-05
Batch : 102 / 196 | Time 266 ms | Train Loss : 4.3334 | Grad Norm : 14.7652 | Learning rate : 1.75e-05
Batch : 103 / 196 | Time 264 ms | Train Loss : 4.3127 | Grad Norm : 18.5554 | Learning rate : 1.75e-05
Batch : 104 / 196 | Time 260 ms | Train Loss : 4.1814 | Grad Norm : 16.3225 | Learning rate : 1.74e-05
Batch : 105 / 196 | Time 265 ms | Train Loss : 4.2602 | Grad Norm : 18.8914 | Learning rate : 1.73e-05
Batch : 106 / 196 | Time 265 ms | Train Loss : 4.2238 | Grad Norm : 20.1666 | Learning rate : 1.73e-05
Batch : 107 / 196 | Time 266 ms | Train Loss : 4.2325 | Grad Norm : 16.0076 | Learning rate : 1.72e-05
Batch : 108 / 196 | Time 265 ms | Train Loss : 4.1671 | Grad Norm : 12.5221 | Learning rate : 1.71e-05
Batch : 109 / 196 | Time 265 ms | Train Loss : 4.3132 | Grad Norm : 14.1978 | Learning rate : 1.70e-05
Batch : 110 / 196 | Time 271 ms | Train Loss : 4.2720 | Grad Norm : 16.1980 | Learning rate : 1.70e-05
Batch : 111 / 196 | Time 263 ms | Train Loss : 4.3377 | Grad Norm : 13.2776 | Learning rate : 1.69e-05
Batch : 112 / 196 | Time 263 ms | Train Loss : 4.2306 | Grad Norm : 16.4495 | Learning rate : 1.68e-05
Batch : 113 / 196 | Time 266 ms | Train Loss : 4.2257 | Grad Norm : 16.0513 | Learning rate : 1.68e-05
Batch : 114 / 196 | Time 266 ms | Train Loss : 4.2406 | Grad Norm : 17.4557 | Learning rate : 1.67e-05
Batch : 115 / 196 | Time 263 ms | Train Loss : 4.3184 | Grad Norm : 19.2262 | Learning rate : 1.66e-05
Batch : 116 / 196 | Time 265 ms | Train Loss : 4.2830 | Grad Norm : 18.1797 | Learning rate : 1.66e-05
Batch : 117 / 196 | Time 265 ms | Train Loss : 4.2733 | Grad Norm : 16.3466 | Learning rate : 1.65e-05
Batch : 118 / 196 | Time 265 ms | Train Loss : 4.2339 | Grad Norm : 13.3812 | Learning rate : 1.65e-05
Batch : 119 / 196 | Time 267 ms | Train Loss : 4.2185 | Grad Norm : 11.0385 | Learning rate : 1.64e-05
Batch : 120 / 196 | Time 267 ms | Train Loss : 4.2232 | Grad Norm : 18.4287 | Learning rate : 1.63e-05
Batch : 121 / 196 | Time 264 ms | Train Loss : 4.2701 | Grad Norm : 16.8008 | Learning rate : 1.63e-05
Batch : 122 / 196 | Time 266 ms | Train Loss : 4.2971 | Grad Norm : 13.4548 | Learning rate : 1.62e-05
Batch : 123 / 196 | Time 270 ms | Train Loss : 4.1329 | Grad Norm : 14.7320 | Learning rate : 1.61e-05
Batch : 124 / 196 | Time 268 ms | Train Loss : 4.4083 | Grad Norm : 28.7974 | Learning rate : 1.61e-05
Batch : 125 / 196 | Time 263 ms | Train Loss : 4.2687 | Grad Norm : 15.8454 | Learning rate : 1.60e-05
Batch : 126 / 196 | Time 270 ms | Train Loss : 4.3307 | Grad Norm : 20.2485 | Learning rate : 1.59e-05
Batch : 127 / 196 | Time 272 ms | Train Loss : 4.3251 | Grad Norm : 22.1477 | Learning rate : 1.59e-05
Batch : 128 / 196 | Time 266 ms | Train Loss : 4.2628 | Grad Norm : 11.1755 | Learning rate : 1.58e-05
Batch : 129 / 196 | Time 265 ms | Train Loss : 4.2112 | Grad Norm : 20.6492 | Learning rate : 1.57e-05
Batch : 130 / 196 | Time 264 ms | Train Loss : 4.3203 | Grad Norm : 27.8509 | Learning rate : 1.57e-05
Batch : 131 / 196 | Time 269 ms | Train Loss : 4.1195 | Grad Norm : 14.1724 | Learning rate : 1.56e-05
Batch : 132 / 196 | Time 267 ms | Train Loss : 4.2337 | Grad Norm : 13.0912 | Learning rate : 1.55e-05
Batch : 133 / 196 | Time 270 ms | Train Loss : 4.2963 | Grad Norm : 13.9928 | Learning rate : 1.55e-05
Batch : 134 / 196 | Time 265 ms | Train Loss : 4.1740 | Grad Norm : 17.8450 | Learning rate : 1.54e-05
Batch : 135 / 196 | Time 265 ms | Train Loss : 4.2490 | Grad Norm : 18.5169 | Learning rate : 1.53e-05
Batch : 136 / 196 | Time 264 ms | Train Loss : 4.2566 | Grad Norm : 20.5309 | Learning rate : 1.53e-05
Batch : 137 / 196 | Time 265 ms | Train Loss : 4.3075 | Grad Norm : 20.1155 | Learning rate : 1.52e-05
Batch : 138 / 196 | Time 272 ms | Train Loss : 4.2894 | Grad Norm : 13.1408 | Learning rate : 1.52e-05
Batch : 139 / 196 | Time 265 ms | Train Loss : 4.2479 | Grad Norm : 18.7148 | Learning rate : 1.51e-05
Batch : 140 / 196 | Time 265 ms | Train Loss : 4.2165 | Grad Norm : 15.6399 | Learning rate : 1.50e-05
Batch : 141 / 196 | Time 270 ms | Train Loss : 4.3825 | Grad Norm : 17.1682 | Learning rate : 1.50e-05
Batch : 142 / 196 | Time 267 ms | Train Loss : 4.2761 | Grad Norm : 13.0946 | Learning rate : 1.49e-05
Batch : 143 / 196 | Time 264 ms | Train Loss : 4.2440 | Grad Norm : 11.4850 | Learning rate : 1.48e-05
Batch : 144 / 196 | Time 265 ms | Train Loss : 4.2045 | Grad Norm : 18.2759 | Learning rate : 1.48e-05
Batch : 145 / 196 | Time 265 ms | Train Loss : 4.2420 | Grad Norm : 28.8312 | Learning rate : 1.47e-05
Batch : 146 / 196 | Time 272 ms | Train Loss : 4.3124 | Grad Norm : 16.2120 | Learning rate : 1.46e-05
Batch : 147 / 196 | Time 271 ms | Train Loss : 4.2883 | Grad Norm : 16.3785 | Learning rate : 1.46e-05
Batch : 148 / 196 | Time 266 ms | Train Loss : 4.4028 | Grad Norm : 13.4425 | Learning rate : 1.45e-05
Batch : 149 / 196 | Time 264 ms | Train Loss : 4.1796 | Grad Norm : 13.7454 | Learning rate : 1.45e-05
Batch : 150 / 196 | Time 266 ms | Train Loss : 4.3402 | Grad Norm : 16.4895 | Learning rate : 1.44e-05
Batch : 151 / 196 | Time 271 ms | Train Loss : 4.2867 | Grad Norm : 14.5358 | Learning rate : 1.43e-05
Batch : 152 / 196 | Time 267 ms | Train Loss : 4.4046 | Grad Norm : 15.8255 | Learning rate : 1.43e-05
Batch : 153 / 196 | Time 269 ms | Train Loss : 4.3828 | Grad Norm : 20.1671 | Learning rate : 1.42e-05
Batch : 154 / 196 | Time 272 ms | Train Loss : 4.3535 | Grad Norm : 15.3637 | Learning rate : 1.41e-05
Batch : 155 / 196 | Time 269 ms | Train Loss : 4.2871 | Grad Norm : 11.5557 | Learning rate : 1.41e-05
Batch : 156 / 196 | Time 265 ms | Train Loss : 4.3311 | Grad Norm : 13.5416 | Learning rate : 1.40e-05
Batch : 157 / 196 | Time 264 ms | Train Loss : 4.2811 | Grad Norm : 12.4145 | Learning rate : 1.40e-05
Batch : 158 / 196 | Time 265 ms | Train Loss : 4.3145 | Grad Norm : 23.4174 | Learning rate : 1.39e-05
Batch : 159 / 196 | Time 264 ms | Train Loss : 4.2620 | Grad Norm : 19.0194 | Learning rate : 1.38e-05
Batch : 160 / 196 | Time 276 ms | Train Loss : 4.2251 | Grad Norm : 11.9852 | Learning rate : 1.38e-05
Batch : 161 / 196 | Time 267 ms | Train Loss : 4.2400 | Grad Norm : 14.5729 | Learning rate : 1.37e-05
Batch : 162 / 196 | Time 264 ms | Train Loss : 4.3179 | Grad Norm : 18.7102 | Learning rate : 1.37e-05
Batch : 163 / 196 | Time 267 ms | Train Loss : 4.1798 | Grad Norm : 11.8399 | Learning rate : 1.36e-05
Batch : 164 / 196 | Time 266 ms | Train Loss : 4.1596 | Grad Norm : 11.8664 | Learning rate : 1.35e-05
Batch : 165 / 196 | Time 265 ms | Train Loss : 4.1550 | Grad Norm : 16.0006 | Learning rate : 1.35e-05
Batch : 166 / 196 | Time 270 ms | Train Loss : 4.2752 | Grad Norm : 18.2144 | Learning rate : 1.34e-05
Batch : 167 / 196 | Time 266 ms | Train Loss : 4.2670 | Grad Norm : 10.8228 | Learning rate : 1.33e-05
Batch : 168 / 196 | Time 264 ms | Train Loss : 4.1198 | Grad Norm : 10.9913 | Learning rate : 1.33e-05
Batch : 169 / 196 | Time 269 ms | Train Loss : 4.2396 | Grad Norm : 14.4608 | Learning rate : 1.32e-05
Batch : 170 / 196 | Time 265 ms | Train Loss : 4.2168 | Grad Norm : 13.7868 | Learning rate : 1.32e-05
Batch : 171 / 196 | Time 264 ms | Train Loss : 4.4954 | Grad Norm : 19.2320 | Learning rate : 1.31e-05
Batch : 172 / 196 | Time 270 ms | Train Loss : 4.1744 | Grad Norm : 18.6438 | Learning rate : 1.30e-05
Batch : 173 / 196 | Time 266 ms | Train Loss : 4.1710 | Grad Norm : 13.1581 | Learning rate : 1.30e-05
Batch : 174 / 196 | Time 264 ms | Train Loss : 4.2703 | Grad Norm : 12.3170 | Learning rate : 1.29e-05
Batch : 175 / 196 | Time 273 ms | Train Loss : 4.2187 | Grad Norm : 16.1348 | Learning rate : 1.29e-05
Batch : 176 / 196 | Time 266 ms | Train Loss : 4.2578 | Grad Norm : 12.0250 | Learning rate : 1.28e-05
Batch : 177 / 196 | Time 265 ms | Train Loss : 4.2548 | Grad Norm : 14.2665 | Learning rate : 1.27e-05
Batch : 178 / 196 | Time 264 ms | Train Loss : 4.3723 | Grad Norm : 19.4007 | Learning rate : 1.27e-05
Batch : 179 / 196 | Time 266 ms | Train Loss : 4.2048 | Grad Norm : 13.3518 | Learning rate : 1.26e-05
Batch : 180 / 196 | Time 267 ms | Train Loss : 4.2538 | Grad Norm : 11.1187 | Learning rate : 1.26e-05
Batch : 181 / 196 | Time 266 ms | Train Loss : 4.2331 | Grad Norm : 21.5598 | Learning rate : 1.25e-05
Batch : 182 / 196 | Time 265 ms | Train Loss : 4.2471 | Grad Norm : 9.3606 | Learning rate : 1.25e-05
Batch : 183 / 196 | Time 260 ms | Train Loss : 4.1755 | Grad Norm : 14.2602 | Learning rate : 1.24e-05
Batch : 184 / 196 | Time 271 ms | Train Loss : 4.2419 | Grad Norm : 13.6684 | Learning rate : 1.23e-05
Batch : 185 / 196 | Time 266 ms | Train Loss : 4.2769 | Grad Norm : 13.3998 | Learning rate : 1.23e-05
Batch : 186 / 196 | Time 259 ms | Train Loss : 4.2906 | Grad Norm : 11.9964 | Learning rate : 1.22e-05
Batch : 187 / 196 | Time 269 ms | Train Loss : 4.2261 | Grad Norm : 12.4128 | Learning rate : 1.22e-05
Batch : 188 / 196 | Time 268 ms | Train Loss : 4.2116 | Grad Norm : 15.1808 | Learning rate : 1.21e-05
Batch : 189 / 196 | Time 263 ms | Train Loss : 4.2977 | Grad Norm : 13.2518 | Learning rate : 1.20e-05
Batch : 190 / 196 | Time 268 ms | Train Loss : 4.1396 | Grad Norm : 10.6246 | Learning rate : 1.20e-05
Batch : 191 / 196 | Time 269 ms | Train Loss : 4.3021 | Grad Norm : 10.2201 | Learning rate : 1.19e-05
Batch : 192 / 196 | Time 266 ms | Train Loss : 4.3366 | Grad Norm : 15.6459 | Learning rate : 1.19e-05
Batch : 193 / 196 | Time 270 ms | Train Loss : 4.3448 | Grad Norm : 15.2421 | Learning rate : 1.18e-05
Batch : 194 / 196 | Time 269 ms | Train Loss : 4.2734 | Grad Norm : 15.4679 | Learning rate : 1.18e-05
Batch : 195 / 196 | Time 112 ms | Train Loss : 3.0970 | Grad Norm : 28.3640 | Learning rate : 1.17e-05
Epoch : 7 | Training Loss : 3.0970| Accuracy on test set : 0.5346
 Batch : 0 / 196 | Time 292 ms | Train Loss : 4.1515 | Grad Norm : 12.0522 | Learning rate : 1.16e-05
Batch : 1 / 196 | Time 264 ms | Train Loss : 4.1763 | Grad Norm : 12.3796 | Learning rate : 1.16e-05
Batch : 2 / 196 | Time 264 ms | Train Loss : 4.3328 | Grad Norm : 18.7061 | Learning rate : 1.15e-05
Batch : 3 / 196 | Time 262 ms | Train Loss : 4.3210 | Grad Norm : 14.8858 | Learning rate : 1.15e-05
Batch : 4 / 196 | Time 265 ms | Train Loss : 4.2785 | Grad Norm : 13.8806 | Learning rate : 1.14e-05
Batch : 5 / 196 | Time 265 ms | Train Loss : 4.1986 | Grad Norm : 18.9394 | Learning rate : 1.14e-05
Batch : 6 / 196 | Time 264 ms | Train Loss : 4.1624 | Grad Norm : 13.4406 | Learning rate : 1.13e-05
Batch : 7 / 196 | Time 271 ms | Train Loss : 4.2340 | Grad Norm : 13.6948 | Learning rate : 1.12e-05
Batch : 8 / 196 | Time 265 ms | Train Loss : 4.2674 | Grad Norm : 12.1183 | Learning rate : 1.12e-05
Batch : 9 / 196 | Time 269 ms | Train Loss : 4.1567 | Grad Norm : 10.6330 | Learning rate : 1.11e-05
Batch : 10 / 196 | Time 268 ms | Train Loss : 4.2326 | Grad Norm : 13.9009 | Learning rate : 1.11e-05
Batch : 11 / 196 | Time 266 ms | Train Loss : 4.0997 | Grad Norm : 14.4429 | Learning rate : 1.10e-05
Batch : 12 / 196 | Time 262 ms | Train Loss : 4.1762 | Grad Norm : 10.3571 | Learning rate : 1.10e-05
Batch : 13 / 196 | Time 269 ms | Train Loss : 4.2191 | Grad Norm : 10.8429 | Learning rate : 1.09e-05
Batch : 14 / 196 | Time 264 ms | Train Loss : 4.2029 | Grad Norm : 12.8184 | Learning rate : 1.09e-05
Batch : 15 / 196 | Time 265 ms | Train Loss : 4.1924 | Grad Norm : 17.3985 | Learning rate : 1.08e-05
Batch : 16 / 196 | Time 264 ms | Train Loss : 4.3867 | Grad Norm : 17.3551 | Learning rate : 1.07e-05
Batch : 17 / 196 | Time 265 ms | Train Loss : 4.2786 | Grad Norm : 17.6010 | Learning rate : 1.07e-05
Batch : 18 / 196 | Time 263 ms | Train Loss : 4.2012 | Grad Norm : 16.4961 | Learning rate : 1.06e-05
Batch : 19 / 196 | Time 268 ms | Train Loss : 4.1795 | Grad Norm : 13.8968 | Learning rate : 1.06e-05
Batch : 20 / 196 | Time 266 ms | Train Loss : 4.3114 | Grad Norm : 15.8734 | Learning rate : 1.05e-05
Batch : 21 / 196 | Time 264 ms | Train Loss : 4.2833 | Grad Norm : 13.5762 | Learning rate : 1.05e-05
Batch : 22 / 196 | Time 263 ms | Train Loss : 4.2026 | Grad Norm : 18.3989 | Learning rate : 1.04e-05
Batch : 23 / 196 | Time 263 ms | Train Loss : 4.1821 | Grad Norm : 11.0735 | Learning rate : 1.04e-05
Batch : 24 / 196 | Time 263 ms | Train Loss : 4.2724 | Grad Norm : 17.8861 | Learning rate : 1.03e-05
Batch : 25 / 196 | Time 268 ms | Train Loss : 4.2601 | Grad Norm : 15.4620 | Learning rate : 1.03e-05
Batch : 26 / 196 | Time 264 ms | Train Loss : 4.2160 | Grad Norm : 17.8574 | Learning rate : 1.02e-05
Batch : 27 / 196 | Time 263 ms | Train Loss : 4.1765 | Grad Norm : 14.5255 | Learning rate : 1.01e-05
Batch : 28 / 196 | Time 262 ms | Train Loss : 4.2624 | Grad Norm : 11.9414 | Learning rate : 1.01e-05
Batch : 29 / 196 | Time 265 ms | Train Loss : 4.2295 | Grad Norm : 10.7570 | Learning rate : 1.00e-05
Batch : 30 / 196 | Time 267 ms | Train Loss : 4.1040 | Grad Norm : 14.7947 | Learning rate : 9.98e-06
Batch : 31 / 196 | Time 266 ms | Train Loss : 4.2660 | Grad Norm : 12.4563 | Learning rate : 9.93e-06
Batch : 32 / 196 | Time 264 ms | Train Loss : 4.3370 | Grad Norm : 16.9999 | Learning rate : 9.88e-06
Batch : 33 / 196 | Time 263 ms | Train Loss : 4.1553 | Grad Norm : 13.4366 | Learning rate : 9.82e-06
Batch : 34 / 196 | Time 264 ms | Train Loss : 4.2456 | Grad Norm : 16.2509 | Learning rate : 9.77e-06
Batch : 35 / 196 | Time 262 ms | Train Loss : 4.2069 | Grad Norm : 9.5787 | Learning rate : 9.72e-06
Batch : 36 / 196 | Time 265 ms | Train Loss : 4.3009 | Grad Norm : 17.3226 | Learning rate : 9.66e-06
Batch : 37 / 196 | Time 264 ms | Train Loss : 4.1311 | Grad Norm : 16.3449 | Learning rate : 9.61e-06
Batch : 38 / 196 | Time 264 ms | Train Loss : 4.1331 | Grad Norm : 14.3422 | Learning rate : 9.56e-06
Batch : 39 / 196 | Time 268 ms | Train Loss : 4.3387 | Grad Norm : 17.8416 | Learning rate : 9.51e-06
Batch : 40 / 196 | Time 265 ms | Train Loss : 4.2979 | Grad Norm : 14.7549 | Learning rate : 9.46e-06
Batch : 41 / 196 | Time 265 ms | Train Loss : 4.2936 | Grad Norm : 13.1733 | Learning rate : 9.40e-06
Batch : 42 / 196 | Time 266 ms | Train Loss : 4.2169 | Grad Norm : 17.0998 | Learning rate : 9.35e-06
Batch : 43 / 196 | Time 264 ms | Train Loss : 4.2764 | Grad Norm : 12.7419 | Learning rate : 9.30e-06
Batch : 44 / 196 | Time 265 ms | Train Loss : 4.1001 | Grad Norm : 11.8502 | Learning rate : 9.25e-06
Batch : 45 / 196 | Time 267 ms | Train Loss : 4.3146 | Grad Norm : 15.4652 | Learning rate : 9.20e-06
Batch : 46 / 196 | Time 266 ms | Train Loss : 4.2111 | Grad Norm : 18.1585 | Learning rate : 9.14e-06
Batch : 47 / 196 | Time 266 ms | Train Loss : 4.1936 | Grad Norm : 13.1862 | Learning rate : 9.09e-06
Batch : 48 / 196 | Time 265 ms | Train Loss : 4.1476 | Grad Norm : 13.3335 | Learning rate : 9.04e-06
Batch : 49 / 196 | Time 263 ms | Train Loss : 4.2718 | Grad Norm : 13.9963 | Learning rate : 8.99e-06
Batch : 50 / 196 | Time 267 ms | Train Loss : 4.2858 | Grad Norm : 15.5040 | Learning rate : 8.94e-06
Batch : 51 / 196 | Time 264 ms | Train Loss : 4.2404 | Grad Norm : 13.8119 | Learning rate : 8.89e-06
Batch : 52 / 196 | Time 271 ms | Train Loss : 4.1785 | Grad Norm : 12.7796 | Learning rate : 8.84e-06
Batch : 53 / 196 | Time 267 ms | Train Loss : 4.1758 | Grad Norm : 13.4411 | Learning rate : 8.79e-06
Batch : 54 / 196 | Time 264 ms | Train Loss : 4.2053 | Grad Norm : 12.4593 | Learning rate : 8.74e-06
Batch : 55 / 196 | Time 264 ms | Train Loss : 4.2441 | Grad Norm : 12.5629 | Learning rate : 8.69e-06
Batch : 56 / 196 | Time 263 ms | Train Loss : 4.2485 | Grad Norm : 19.9124 | Learning rate : 8.64e-06
Batch : 57 / 196 | Time 263 ms | Train Loss : 4.2924 | Grad Norm : 13.2512 | Learning rate : 8.59e-06
Batch : 58 / 196 | Time 263 ms | Train Loss : 4.2661 | Grad Norm : 12.9183 | Learning rate : 8.54e-06
Batch : 59 / 196 | Time 263 ms | Train Loss : 4.2657 | Grad Norm : 14.2067 | Learning rate : 8.49e-06
Batch : 60 / 196 | Time 266 ms | Train Loss : 4.1779 | Grad Norm : 13.3641 | Learning rate : 8.44e-06
Batch : 61 / 196 | Time 264 ms | Train Loss : 4.2843 | Grad Norm : 14.6918 | Learning rate : 8.39e-06
Batch : 62 / 196 | Time 264 ms | Train Loss : 4.3384 | Grad Norm : 14.8050 | Learning rate : 8.34e-06
Batch : 63 / 196 | Time 263 ms | Train Loss : 4.1186 | Grad Norm : 12.8929 | Learning rate : 8.29e-06
Batch : 64 / 196 | Time 266 ms | Train Loss : 4.2251 | Grad Norm : 12.8202 | Learning rate : 8.24e-06
Batch : 65 / 196 | Time 267 ms | Train Loss : 4.2157 | Grad Norm : 14.6139 | Learning rate : 8.19e-06
Batch : 66 / 196 | Time 267 ms | Train Loss : 4.2495 | Grad Norm : 19.6682 | Learning rate : 8.14e-06
Batch : 67 / 196 | Time 265 ms | Train Loss : 4.2162 | Grad Norm : 15.7404 | Learning rate : 8.10e-06
Batch : 68 / 196 | Time 263 ms | Train Loss : 4.1261 | Grad Norm : 14.4292 | Learning rate : 8.05e-06
Batch : 69 / 196 | Time 264 ms | Train Loss : 4.2346 | Grad Norm : 18.8042 | Learning rate : 8.00e-06
Batch : 70 / 196 | Time 276 ms | Train Loss : 4.2522 | Grad Norm : 13.8133 | Learning rate : 7.95e-06
Batch : 71 / 196 | Time 264 ms | Train Loss : 4.2477 | Grad Norm : 14.7794 | Learning rate : 7.90e-06
Batch : 72 / 196 | Time 264 ms | Train Loss : 4.2120 | Grad Norm : 16.5728 | Learning rate : 7.85e-06
Batch : 73 / 196 | Time 264 ms | Train Loss : 4.2263 | Grad Norm : 16.2046 | Learning rate : 7.81e-06
Batch : 74 / 196 | Time 266 ms | Train Loss : 4.2948 | Grad Norm : 16.1720 | Learning rate : 7.76e-06
Batch : 75 / 196 | Time 264 ms | Train Loss : 4.1510 | Grad Norm : 12.5422 | Learning rate : 7.71e-06
Batch : 76 / 196 | Time 268 ms | Train Loss : 4.2163 | Grad Norm : 15.7146 | Learning rate : 7.66e-06
Batch : 77 / 196 | Time 267 ms | Train Loss : 4.2440 | Grad Norm : 16.1103 | Learning rate : 7.62e-06
Batch : 78 / 196 | Time 264 ms | Train Loss : 4.2044 | Grad Norm : 16.0047 | Learning rate : 7.57e-06
Batch : 79 / 196 | Time 263 ms | Train Loss : 4.1690 | Grad Norm : 15.0929 | Learning rate : 7.52e-06
Batch : 80 / 196 | Time 267 ms | Train Loss : 4.3210 | Grad Norm : 18.6580 | Learning rate : 7.48e-06
Batch : 81 / 196 | Time 263 ms | Train Loss : 4.1891 | Grad Norm : 15.5028 | Learning rate : 7.43e-06
Batch : 82 / 196 | Time 268 ms | Train Loss : 4.2393 | Grad Norm : 11.0540 | Learning rate : 7.38e-06
Batch : 83 / 196 | Time 266 ms | Train Loss : 4.3227 | Grad Norm : 13.8531 | Learning rate : 7.34e-06
Batch : 84 / 196 | Time 263 ms | Train Loss : 4.2168 | Grad Norm : 14.9914 | Learning rate : 7.29e-06
Batch : 85 / 196 | Time 266 ms | Train Loss : 4.2144 | Grad Norm : 13.5616 | Learning rate : 7.24e-06
Batch : 86 / 196 | Time 266 ms | Train Loss : 4.2532 | Grad Norm : 15.7438 | Learning rate : 7.20e-06
Batch : 87 / 196 | Time 264 ms | Train Loss : 4.1203 | Grad Norm : 13.8624 | Learning rate : 7.15e-06
Batch : 88 / 196 | Time 271 ms | Train Loss : 4.2430 | Grad Norm : 16.9946 | Learning rate : 7.10e-06
Batch : 89 / 196 | Time 264 ms | Train Loss : 4.1620 | Grad Norm : 13.2395 | Learning rate : 7.06e-06
Batch : 90 / 196 | Time 264 ms | Train Loss : 4.2487 | Grad Norm : 12.3770 | Learning rate : 7.01e-06
Batch : 91 / 196 | Time 266 ms | Train Loss : 4.1794 | Grad Norm : 16.3699 | Learning rate : 6.97e-06
Batch : 92 / 196 | Time 262 ms | Train Loss : 4.2011 | Grad Norm : 16.2991 | Learning rate : 6.92e-06
Batch : 93 / 196 | Time 264 ms | Train Loss : 4.2903 | Grad Norm : 17.3058 | Learning rate : 6.88e-06
Batch : 94 / 196 | Time 264 ms | Train Loss : 4.2079 | Grad Norm : 17.3500 | Learning rate : 6.83e-06
Batch : 95 / 196 | Time 263 ms | Train Loss : 4.2284 | Grad Norm : 11.3787 | Learning rate : 6.79e-06
Batch : 96 / 196 | Time 263 ms | Train Loss : 4.2305 | Grad Norm : 16.3111 | Learning rate : 6.74e-06
Batch : 97 / 196 | Time 265 ms | Train Loss : 4.2784 | Grad Norm : 18.8695 | Learning rate : 6.70e-06
Batch : 98 / 196 | Time 264 ms | Train Loss : 4.2489 | Grad Norm : 16.8648 | Learning rate : 6.65e-06
Batch : 99 / 196 | Time 265 ms | Train Loss : 4.1806 | Grad Norm : 11.2901 | Learning rate : 6.61e-06
Batch : 100 / 196 | Time 266 ms | Train Loss : 4.2845 | Grad Norm : 14.0417 | Learning rate : 6.57e-06
Batch : 101 / 196 | Time 263 ms | Train Loss : 4.2726 | Grad Norm : 16.9442 | Learning rate : 6.52e-06
Batch : 102 / 196 | Time 264 ms | Train Loss : 4.1434 | Grad Norm : 12.2880 | Learning rate : 6.48e-06
Batch : 103 / 196 | Time 265 ms | Train Loss : 4.1648 | Grad Norm : 15.1513 | Learning rate : 6.43e-06
Batch : 104 / 196 | Time 266 ms | Train Loss : 4.1576 | Grad Norm : 12.2919 | Learning rate : 6.39e-06
Batch : 105 / 196 | Time 263 ms | Train Loss : 4.2128 | Grad Norm : 14.0022 | Learning rate : 6.35e-06
Batch : 106 / 196 | Time 263 ms | Train Loss : 4.1397 | Grad Norm : 12.5616 | Learning rate : 6.30e-06
Batch : 107 / 196 | Time 264 ms | Train Loss : 4.1763 | Grad Norm : 11.8632 | Learning rate : 6.26e-06
Batch : 108 / 196 | Time 264 ms | Train Loss : 4.2866 | Grad Norm : 14.8188 | Learning rate : 6.22e-06
Batch : 109 / 196 | Time 263 ms | Train Loss : 4.2561 | Grad Norm : 13.4868 | Learning rate : 6.17e-06
Batch : 110 / 196 | Time 262 ms | Train Loss : 4.2267 | Grad Norm : 10.7424 | Learning rate : 6.13e-06
Batch : 111 / 196 | Time 265 ms | Train Loss : 4.2265 | Grad Norm : 16.6421 | Learning rate : 6.09e-06
Batch : 112 / 196 | Time 270 ms | Train Loss : 4.3015 | Grad Norm : 19.1848 | Learning rate : 6.05e-06
Batch : 113 / 196 | Time 264 ms | Train Loss : 4.1592 | Grad Norm : 15.8632 | Learning rate : 6.00e-06
Batch : 114 / 196 | Time 263 ms | Train Loss : 4.1785 | Grad Norm : 21.7216 | Learning rate : 5.96e-06
Batch : 115 / 196 | Time 263 ms | Train Loss : 4.2477 | Grad Norm : 22.1415 | Learning rate : 5.92e-06
Batch : 116 / 196 | Time 263 ms | Train Loss : 4.3455 | Grad Norm : 15.0242 | Learning rate : 5.88e-06
Batch : 117 / 196 | Time 264 ms | Train Loss : 4.2353 | Grad Norm : 18.5278 | Learning rate : 5.84e-06
Batch : 118 / 196 | Time 264 ms | Train Loss : 4.1057 | Grad Norm : 13.4527 | Learning rate : 5.79e-06
Batch : 119 / 196 | Time 263 ms | Train Loss : 4.3141 | Grad Norm : 15.7454 | Learning rate : 5.75e-06
Batch : 120 / 196 | Time 265 ms | Train Loss : 4.1545 | Grad Norm : 13.3335 | Learning rate : 5.71e-06
Batch : 121 / 196 | Time 264 ms | Train Loss : 4.2099 | Grad Norm : 13.6964 | Learning rate : 5.67e-06
Batch : 122 / 196 | Time 263 ms | Train Loss : 4.2883 | Grad Norm : 16.2449 | Learning rate : 5.63e-06
Batch : 123 / 196 | Time 264 ms | Train Loss : 4.2689 | Grad Norm : 18.7603 | Learning rate : 5.59e-06
Batch : 124 / 196 | Time 267 ms | Train Loss : 4.2049 | Grad Norm : 16.9980 | Learning rate : 5.55e-06
Batch : 125 / 196 | Time 265 ms | Train Loss : 4.2254 | Grad Norm : 18.0868 | Learning rate : 5.51e-06
Batch : 126 / 196 | Time 264 ms | Train Loss : 4.2910 | Grad Norm : 22.7892 | Learning rate : 5.47e-06
Batch : 127 / 196 | Time 263 ms | Train Loss : 4.1857 | Grad Norm : 12.1052 | Learning rate : 5.43e-06
Batch : 128 / 196 | Time 264 ms | Train Loss : 4.2064 | Grad Norm : 11.3580 | Learning rate : 5.39e-06
Batch : 129 / 196 | Time 265 ms | Train Loss : 4.1960 | Grad Norm : 17.5007 | Learning rate : 5.35e-06
Batch : 130 / 196 | Time 263 ms | Train Loss : 4.2664 | Grad Norm : 18.1658 | Learning rate : 5.31e-06
Batch : 131 / 196 | Time 265 ms | Train Loss : 4.2870 | Grad Norm : 17.5515 | Learning rate : 5.27e-06
Batch : 132 / 196 | Time 267 ms | Train Loss : 4.3088 | Grad Norm : 11.9641 | Learning rate : 5.23e-06
Batch : 133 / 196 | Time 266 ms | Train Loss : 4.3513 | Grad Norm : 11.4357 | Learning rate : 5.19e-06
Batch : 134 / 196 | Time 272 ms | Train Loss : 4.1006 | Grad Norm : 15.3137 | Learning rate : 5.15e-06
Batch : 135 / 196 | Time 264 ms | Train Loss : 4.2971 | Grad Norm : 13.5235 | Learning rate : 5.11e-06
Batch : 136 / 196 | Time 263 ms | Train Loss : 4.2414 | Grad Norm : 14.6351 | Learning rate : 5.07e-06
Batch : 137 / 196 | Time 264 ms | Train Loss : 4.2303 | Grad Norm : 20.1382 | Learning rate : 5.03e-06
Batch : 138 / 196 | Time 267 ms | Train Loss : 4.2118 | Grad Norm : 14.6728 | Learning rate : 4.99e-06
Batch : 139 / 196 | Time 264 ms | Train Loss : 4.2312 | Grad Norm : 18.6101 | Learning rate : 4.95e-06
Batch : 140 / 196 | Time 268 ms | Train Loss : 4.1554 | Grad Norm : 13.0605 | Learning rate : 4.91e-06
Batch : 141 / 196 | Time 265 ms | Train Loss : 4.2032 | Grad Norm : 20.7145 | Learning rate : 4.87e-06
